study_content_id,first_category,second_category,title,body
1,Operating System,운영체제,운영 체제란 무엇인가?,"> **운영 체제(OS, Operating System)**
>
> : 하드웨어를 관리하고, 컴퓨터 시스템의 자원들을 효율적으로 관리하며, 응용 프로그램과 하드웨어 간의 인터페이스로서 다른 응용 프로그램이 유용한 작업을 할 수 있도록 환경을 제공해 준다.
>
> 즉, 운영 체제는 **사용자가 컴퓨터를 편리하고 효과적으로 사용할 수 있도록 환경을 제공하는 시스템 소프트웨어**라고 할 수 있다.
>
> (*종류로는 Windows, Linux, UNIX, MS-DOS 등이 있으며, 시스템의 역할 구분에 따라 각각 용이점이 있다.*)"
2,Operating System,운영체제,운영체제의 역할,"##### 1. 프로세스 관리

- 프로세스, 스레드
- 스케줄링
- 동기화
- IPC 통신

##### 2. 저장장치 관리

- 메모리 관리
- 가상 메모리
- 파일 시스템

##### 3. 네트워킹

- TCP/IP
- 기타 프로토콜

##### 4. 사용자 관리

- 계정 관리
- 접근권한 관리

##### 5. 디바이스 드라이버

- 순차접근 장치
- 임의접근 장치
- 네트워크 장치"
3,Operating System,운영체제,1. 프로세스 관리,"운영체제에서 작동하는 응용 프로그램을 관리하는 기능이다.

어떤 의미에서는 프로세서(CPU)를 관리하는 것이라고 볼 수도 있다. 현재 CPU를 점유해야 할 프로세스를 결정하고, 실제로 CPU를 프로세스에 할당하며, 이 프로세스 간 공유 자원 접근과 통신 등을 관리하게 된다."
4,Operating System,운영체제,2. 저장장치 관리,"1차 저장장치에 해당하는 메인 메모리와 2차 저장장치에 해당하는 하드디스크, NAND 등을 관리하는 기능이다.

- 1차 저장장치(Main Memory)
  - 프로세스에 할당하는 메모리 영역의 할당과 해제
  - 각 메모리 영역 간의 침범 방지
  - 메인 메모리의 효율적 활용을 위한 가상 메모리 기능
- 2차 저장장치(HDD, NAND Flash Memory 등)
  - 파일 형식의 데이터 저장
  - 이런 파일 데이터 관리를 위한 파일 시스템을 OS에서 관리
  - `FAT, NTFS, EXT2, JFS, XFS` 등 많은 파일 시스템이 개발되어 사용 중"
5,Operating System,운영체제,3. 네트워킹,"네트워킹은 컴퓨터 활용의 핵심과도 같아졌다.

TCP/IP 기반의 인터넷에 연결하거나, 응용 프로그램이 네트워크를 사용하려면 **운영체제에서 네트워크 프로토콜을 지원**해야 한다. 현재 상용 OS들은 다양하고 많은 네트워크 프로토콜을 지원한다.

이처럼 운영체제는 사용자와 컴퓨터 하드웨어 사이에 위치해서, 하드웨어를 운영 및 관리하고 명령어를 제어하여 응용 프로그램 및 하드웨어를 소프트웨어적으로 제어 및 관리를 해야 한다."
6,Operating System,운영체제,4. 사용자 관리,"우리가 사용하는 PC는 오직 한 사람만의 것일까? 아니다.

하나의 PC로도 여러 사람이 사용하는 경우가 많다. 그래서 운영체제는 한 컴퓨터를 여러 사람이 사용하는 환경도 지원해야 한다. 가족들이 각자의 계정을 만들어 PC를 사용한다면, 이는 하나의 컴퓨터를 여러 명이 사용한다고 말할 수 있다.

따라서, 운영체제는 각 계정을 관리할 수 있는 기능이 필요하다. 사용자별로 프라이버시와 보안을 위해 개인 파일에 대해선 다른 사용자가 접근할 수 없도록 해야 한다. 이 밖에도 파일이나 시스템 자원에 접근 권한을 지정할 수 있도록 지원하는 것이 사용자 관리 기능이다."
7,Operating System,운영체제,5. 디바이스 드라이버,"운영체제는 시스템의 자원, 하드웨어를 관리한다. 시스템에는 여러 하드웨어가 붙어있는데, 이들을 운영체제에서 인식하고 관리하게 만들어 응용 프로그램이 하드웨어를 사용할 수 있게 만들어야 한다.

따라서, 운영체제 안에 하드웨어를 추상화 해주는 계층이 필요하다. 이 계층이 바로 디바이스 드라이버라고 불린다. 하드웨어의 종류가 많은 만큼, 운영체제 내부의 디바이스 드라이버도 많이 존재한다.

이러한 수많은 디바이스 드라이버를 관리하는 기능 또한 운영체제가 맡고 있다."
8,Operating System,운영체제,참고 자료 및 주제와 관련하여 참고하면 좋은 곳 링크,"- 도서 - '도전 임베디드 OS 만들기' *( 이만우 저, 인사이트 출판 )*
- 글 - '운영체제란 무엇인가?' *( https://coding-factory.tistory.com/300 )*"
9,Operating System,프로세스 & 스레드,프로세스,**프로세스** : 메모리상에서 실행 중인 프로그램
10,Operating System,프로세스 & 스레드,스레드,"**스레드** : 프로세스 안에서 실행되는 여러 흐름 단위
기본적으로 프로세스마다 최소 1개의 스레드(메인 스레드)를 소유한다."
11,Operating System,프로세스 & 스레드,프로세스와 스레드의 주소공간 할당,"프로세스는 각각 별도의 주소 공간을 할당받는다. (독립적)

- Code : 코드 자체를 구성하는 메모리 영역 (프로그램 명령)

- Data : 전역 변수, 정적 변수, 배열 등
  - 초기화된 데이터는 Data 영역에 저장
  - 초기화되지 않은 데이터는 BSS 영역에 저장

- Heap : 동적 할당 시 사용 (new(), malloc() 등)

- Stack : 지역 변수, 매개 변수, 리턴 값 (임시 메모리 영역)


스레드는 Stack만 따로 할당받고 나머지 영역은 공유한다.

- 스레드는 독립적인 동작을 수행하기 위해 존재 = 독립적으로 함수를 호출할 수 있어야 함
- 함수의 매개 변수, 지역 변수 등을 저장하는 Stack 영역은 독립적으로 할당받아야 함


하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드가 같이 생성된다.

<br>

**프로세스는 자신만의 고유 공간 및 자원을 할당받아 사용**하는 데 반해,

**스레드는 다른 스레드와 공간 및 자원을 공유하면서 사용**하는 차이가 존재한다."
12,Operating System,프로세스 & 스레드,멀티프로세스,"> 하나의 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 병렬적으로 작업을 처리하도록 하는 것

<br>

**장점** : 안전성 (메모리 침범 문제를 OS 차원에서 해결)

**단점** : 각각 독립된 메모리를 갖고 있어 작업량이 많을수록 오버헤드 발생, Context Switching으로 인한 성능 저하

<br>

***Context Switching* 이란?**

> 프로세스의 상태 정보를 저장하고 복원하는 일련의 과정
> - 동작 중인 프로세스가 대기하면서 해당 프로세스 상태를 보관
> - 대기하고 있던 다음 순번의 프로세스가 동작하면서 이전에 보관했던 프로세스 상태를 복구
>
> 문제점: 프로세스는 독립된 메모리 영역을 할당받으므로, 캐시 메모리 초기화와 같은 무거운 작업이 진행되면 오버헤드가 발생할 수 있음"
13,Operating System,프로세스 & 스레드,멀티스레드,"> 하나의 프로그램을 여러 개의 스레드로 구성하여 각 스레드가 하나의 작업을 처리하도록 하는 것

<br>

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해 준다.

<br>

**장점** : 독립적인 프로세스에 비해 공유 메모리만큼의 시간과 자원 손실 감소, 전역 변수와 정적 변수 공유 가능

**단점** : 안전성 (공유 메모리를 갖기 때문에 하나의 스레드가 데이터 공간을 망가뜨리면, 모든 스레드 작동 불능)

<br>

멀티스레드의 안전성에 대한 단점은 Critical Section 기법을 통해 대비한다.

> 하나의 스레드가 공유 데이터값을 변경하는 시점에 다른 스레드가 그 값을 읽으려 할 때 발생하는 문제를 해결하기 위한 동기화 과정
>
> ```
> 상호 배제, 진행, 한정된 대기를 충족해야 함
> ```"
14,Operating System,프로세스의 주소 공간,프로세스의 주소 공간이란?,"> 프로그램이 CPU에 의해 실행됨 → 프로세스가 생성되고 메모리에 '**프로세스 주소 공간**'이 할당됨

프로세스 주소 공간에는 코드, 데이터, 스택으로 이루어져 있다.

- **코드 Segment** : 프로그램 소스 코드 저장
- **데이터 Segment** : 전역 변수 저장
- **스택 Segment** : 함수, 지역 변수 저장

<br>

***왜 이렇게 구역을 나눈건가요?***

최대한 데이터를 공유하여 메모리 사용량을 줄여야 합니다. 

Code는 같은 프로그램 자체에서는 모두 같은 내용이기 때문에 따로 관리하여 공유함

Stack과 데이터를 나눈 이유는, 스택 구조의 특성과 전역 변수의 활용성을 위한 것!

```
프로그램의 함수와 지역 변수는, LIFO(가장 나중에 들어간게 먼저 나옴)특성을 가진 스택에서 실행된다. 
따라서 이 함수들 안에서 공통으로 사용하는 '전역 변수'는 따로 지정해주면 메모리를 아낄 수 있다.
```"
15,Operating System,인터럽트 (Interrupt),인터럽트의 정의,"##### 정의

프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것
<br>

지금 수행 중인 일보다 더 중요한 일(ex. 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다.

<br>

외부/내부 인터럽트는 `CPU의 하드웨어 신호에 의해 발생`

소프트웨어 인터럽트는 `명령어의 수행에 의해 발생`"
16,Operating System,인터럽트 (Interrupt),외부 인터럽트,"- ##### 외부 인터럽트

  입출력 장치, 타이밍 장치, 전원 등 외부적인 요인으로 발생

  `전원 이상, 기계 착오, 외부 신호, 입출력`"
17,Operating System,인터럽트 (Interrupt),내부 인터럽트,"- ##### 내부 인터럽트

  Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생

  > 0으로 나누기가 발생, 오버플로우, 명령어를 잘못 사용한 경우 (Exception)"
18,Operating System,인터럽트 (Interrupt),소프트웨어 인터럽트,"- ##### 소프트웨어 인터럽트

  프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)

  > 사용자가 프로그램을 실행시킬 때 발생
  >
  > 소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다."
19,Operating System,인터럽트 (Interrupt),인터럽트 발생 처리 과정,"주 프로그램이 실행되다가 인터럽트가 발생했다.

현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (잠시 저장하는 이유는, 인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문)

만약 **인터럽트 기능이 없었다면**, 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야 한다. (이를 **폴링(Polling)**이라고 한다)

폴링을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다.

<br>

즉, 컨트롤러가 입력을 받아들이는 방법(우선순위 판별방법)에는 두가지가 있다."
20,Operating System,인터럽트 (Interrupt),폴링 방식,"사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식

인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 맞는 인터럽트 서비스 루틴을 수행한다. (하드웨어에 비해 속도 느림)"
21,Operating System,인터럽트 (Interrupt),인터럽트 방식,"MCU 자체가 하드웨어적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식

  - Daisy Chain
  - 병렬 우선순위 부여 

<br>

인터럽트 방식은 하드웨어로 지원을 받아야 하는 제약이 있지만, 폴링에 비해 신속하게 대응하는 것이 가능하다. 따라서 **'실시간 대응'**이 필요할 때는 필수적인 기능이다.

<br>

즉, 인터럽트는 **발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법**이다."
22,Operating System,시스템 콜 (System Call),시스템 콜이란?,"fork( ), exec( ), wait( )와 같은 것들은 Process 생성과 제어를 위한 System call임.

- fork, exec는 새로운 Process 생성과 관련이 되어 있다.
- wait는 Process (Parent)가 만든 다른 Process(child) 가 끝날 때까지 기다리는 명령어임."
23,Operating System,시스템 콜 (System Call),Fork,"> 새로운 Process를 생성할 때 사용.
>
> 그러나, 이상한 방식임.

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(int argc, char *argv[]) {
    printf(""pid : %d"", (int) getpid()); // pid : 29146
    
    int rc = fork();					// 주목
    
    if (rc < 0) {					    // (1) fork 실패
        exit(1);
    }
    else if (rc == 0) {					// (2) child 인 경우 (fork 값이 0)
        printf(""child (pid : %d)"", (int) getpid());
    }
    else {								// (3) parent case
        printf(""parent of %d (pid : %d)"", rc, (int)getpid());
    }
}
```

> pid : 29146
>
> parent of 29147 (pid : 29146)
>
> child (pid : 29147)

을 출력함 (parent와 child의 순서는 non-deterministic함. 즉, 확신할 수 없음. scheduler가 결정하는 일임.)

[해석]

PID :  프로세스 식별자. UNIX 시스템에서는 PID는 프로세스에게 명령을 할 때 사용함.

Fork()가 실행되는 순간. 프로세스가 하나 더 생기는데, 이 때 생긴 프로세스(Child)는 fork를 만든 프로세스(Parent)와 (almost) 동일한 복사본을 갖게 된다. **<u>이 때 OS는 위와 똑같은 2개의 프로그램이 동작한다고 생각하고, fork()가 return될 차례라고 생각한다.</u>** 그 때문에 새로 생성된 Process (child)는 main에서 시작하지 않고, if 문부터 시작하게 된다.

그러나, 차이점이 있었다. 바로 child와 parent의 fork() 값이 다르다는 점이다.
 따라서, 완전히 동일한 복사본이라 할 수 없다. 

> Parent의 fork()값 => child의 pid 값
>
> Child의 fork()값 => 0

Parent와 child의 fork 값이 다르다는 점은 매우 유용한 방식이다.

그러나! Scheduler가 부모를 먼저 수행할지 아닐지 확신할 수 없다. 따라서 아래와 같이 출력될 수 있다.

> pid : 29146
>
> child (pid : 29147)
>
> parent of 29147 (pid : 29146)"
24,Operating System,시스템 콜 (System Call),Wait,"> child 프로세스가 종료될 때까지 기다리는 작업

위의 예시에 int wc = wait(NULL)만 추가함.

```C
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf(""pid : %d"", (int) getpid()); // pid : 29146
    
    int rc = fork();					// 주목
    
    if (rc < 0) {					    // (1) fork 실패
        exit(1);
    }
    else if (rc == 0) {					// (2) child 인 경우 (fork 값이 0)
        printf(""child (pid : %d)"", (int) getpid());
    }
    else {								// (3) parent case
        int wc = wait(NULL)				// 추가된 부분
        printf(""parent of %d (wc : %d / pid : %d)"", wc, rc, (int)getpid());
    }
}
```

> pid : 29146
>
> child (pid : 29147)
>
> parent of 29147 (wc : 29147 / pid : 29146)

wait를 통해서, child의 실행이 끝날 때까지 기다려줌. parent가 먼저 실행되더라도, wait ()는 child가 끝나기 전에는 return하지 않으므로, 반드시 child가 먼저 실행됨."
25,Operating System,시스템 콜 (System Call),Exec,"단순 fork는 동일한 프로세스의 내용을 여러 번 동작할 때 사용함.

child에서는 parent와 다른 동작을 하고 싶을 때는 exec를 사용할 수 있음.

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf(""pid : %d"", (int) getpid()); // pid : 29146
    
    int rc = fork();					// 주목
    
    if (rc < 0) {					    // (1) fork 실패
        exit(1);
    }
    else if (rc == 0) {					// (2) child 인 경우 (fork 값이 0)
        printf(""child (pid : %d)"", (int) getpid());
        char *myargs[3];
        myargs[0] = strdup(""wc"");		// 내가 실행할 파일 이름
        myargs[1] = strdup(""p3.c"");		// 실행할 파일에 넘겨줄 argument
        myargs[2] = NULL;				// end of array
        execvp(myarges[0], myargs);		// wc 파일 실행.
        printf(""this shouldn't print out"") // 실행되지 않음.
    }
    else {								// (3) parent case
        int wc = wait(NULL)				// 추가된 부분
        printf(""parent of %d (wc : %d / pid : %d)"", wc, rc, (int)getpid());
    }
}
```

exec가 실행되면, 

execvp( 실행 파일, 전달 인자 ) 함수는, code segment 영역에 실행 파일의 코드를 읽어와서 덮어 씌운다.

씌운 이후에는,  heap, stack, 다른 메모리 영역이 초기화되고, OS는 그냥 실행한다. 즉, 새로운 Process를 생성하지 않고, 현재 프로그램에 wc라는 파일을 실행한다. 그로인해서, execvp() 이후의 부분은 실행되지 않는다."
26,Operating System,PCB 와 Context Switching,Process Management,"CPU가 프로세스가 여러개일 때, CPU 스케줄링을 통해 관리하는 것을 말함

이때, CPU는 각 프로세스들이 누군지 알아야 관리가 가능함

프로세스들의 특징을 갖고있는 것이 바로 `Process Metadata`

- Process Metadata
  - Process ID
  - Process State
  - Process Priority
  - CPU Registers
  - Owner
  - CPU Usage
  - Memeory Usage

이 메타데이터는 프로세스가 생성되면 `PCB(Process Control Block)`이라는 곳에 저장됨"
27,Operating System,PCB 와 Context Switching,PCB(Process Control Block),"> 프로세스 메타데이터들을 저장해 놓는 곳, 한 PCB 안에는 한 프로세스의 정보가 담김

```
프로그램 실행 → 프로세스 생성 → 프로세스 주소 공간에 (코드, 데이터, 스택) 생성 
→ 이 프로세스의 메타데이터들이 PCB에 저장
```"
28,Operating System,PCB 와 Context Switching,PCB가 왜 필요한가요?,"> CPU에서는 프로세스의 상태에 따라 교체작업이 이루어진다. (interrupt가 발생해서 할당받은 프로세스가 waiting 상태가 되고 다른 프로세스를 running으로 바꿔 올릴 때)
>
> 이때, **앞으로 다시 수행할 대기 중인 프로세스에 관한 저장 값을 PCB에 저장해두는 것**이다."
29,Operating System,PCB 와 Context Switching,PCB는 어떻게 관리되나요?,"> Linked List 방식으로 관리함
>
> PCB List Head에 PCB들이 생성될 때마다 붙게 된다. 주소값으로 연결이 이루어져 있는 연결리스트이기 때문에 삽입 삭제가 용이함.
>
> 즉, 프로세스가 생성되면 해당 PCB가 생성되고 프로세스 완료시 제거됨

<br>

<br>

이렇게 수행 중인 프로세스를 변경할 때, CPU의 레지스터 정보가 변경되는 것을 `Context Switching`이라고 한다."
30,Operating System,PCB 와 Context Switching,Context Switching,"> CPU가 이전의 프로세스 상태를 PCB에 보관하고, 또 다른 프로세스의 정보를 PCB에 읽어 레지스터에 적재하는 과정

보통 인터럽트가 발생하거나, 실행 중인 CPU 사용 허가시간을 모두 소모하거나, 입출력을 위해 대기해야 하는 경우에 Context Switching이 발생

`즉, 프로세스가 Ready → Running, Running → Ready, Running → Waiting처럼 상태 변경 시 발생!` "
31,Operating System,PCB 와 Context Switching,Context Switching의 OverHead란?,"overhead는 과부하라는 뜻으로 보통 안좋은 말로 많이 쓰인다.

하지만 프로세스 작업 중에는 OverHead를 감수해야 하는 상황이 있다.

```
프로세스를 수행하다가 입출력 이벤트가 발생해서 대기 상태로 전환시킴
이때, CPU를 그냥 놀게 놔두는 것보다 다른 프로세스를 수행시키는 것이 효율적
```

즉, CPU에 계속 프로세스를 수행시키도록 하기 위해서 다른 프로세스를 실행시키고 Context Switching 하는 것

CPU가 놀지 않도록 만들고, 사용자에게 빠르게 일처리를 제공해주기 위한 것이다."
32,Operating System,IPC(Inter Process Communication),IPC란?,"프로세스는 독립적으로 실행된다. 즉, 독립 되어있다는 것은 다른 프로세스에게 영향을 받지 않는다고 말할 수 있다. (스레드는 프로세스 안에서 자원을 공유하므로 영향을 받는다)

이런 독립적 구조를 가진 **프로세스 간의 통신**을 해야 하는 상황이 있을 것이다. 이를 가능하도록 해주는 것이 바로 IPC 통신이다.

<br>

프로세스는 커널이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있게 된다.

***커널이란?***

> 운영체제의 핵심적인 부분으로, 다른 모든 부분에 여러 기본적인 서비스를 제공해줌

<br>

IPC 설비 종류도 여러가지가 있다. 필요에 따라 IPC 설비를 선택해서 사용해야 한다."
33,Operating System,IPC(Inter Process Communication),IPC 종류 - 1. 익명 PIPE,"> 파이프는 두 개의 프로세스를 연결하는데 하나의 프로세스는 데이터를 쓰기만 하고, 다른 하나는 데이터를 읽기만 할 수 있다.
>
> **한쪽 방향으로만 통신이 가능한 반이중 통신**이라고도 부른다.
>
> 따라서 양쪽으로 모두 송/수신을 하고 싶으면 2개의 파이프를 만들어야 한다.
>
> 매우 간단하게 사용할 수 있는 장점이 있고, 단순한 데이터 흐름을 가질 땐 파이프를 사용하는 것이 효율적이다. 단점으로는 전이중 통신을 위해 2개를 만들어야 할 때는 구현이 복잡해지게 된다."
34,Operating System,IPC(Inter Process Communication),IPC 종류 - 2. Named PIPE (FIFO),"> 익명 파이프는 통신할 프로세스를 명확히 알 수 있는 경우에 사용한다. (부모-자식 프로세스 간 통신처럼)
>
> Named 파이프는 전혀 모르는 상태의 프로세스들 사이 통신에 사용한다.
>
> 즉, 익명 파이프의 확장된 상태로 **부모 프로세스와 무관한 다른 프로세스도 통신이 가능한 것** (통신을 위해 이름있는 파일을 사용)
>
> 하지만, Named 파이프 역시 읽기/쓰기 동시에 불가능함. 따라서 전이중 통신을 위해서는 익명 파이프처럼 2개를 만들어야 가능"
35,Operating System,IPC(Inter Process Communication),IPC 종류 - 3. Message Queue,"> 입출력 방식은 Named 파이프와 동일함
>
> 다른점은 메시지 큐는 파이프처럼 데이터의 흐름이 아니라 메모리 공간이다.
>
> 사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다."
36,Operating System,IPC(Inter Process Communication),IPC 종류 - 4. 공유 메모리,"> 파이프, 메시지 큐가 통신을 이용한 설비라면, **공유 메모리는 데이터 자체를 공유하도록 지원하는 설비**다.
> 
> 프로세스의 메모리 영역은 독립적으로 가지며 다른 프로세스가 접근하지 못하도록 반드시 보호돼야한다. 하지만 다른 프로세스가 데이터를 사용하도록 해야하는 상황도 필요할 것이다. 파이프를 이용해 통신을 통해 데이터 전달도 가능하지만, 스레드처럼 메모리를 공유하도록 해준다면 더욱 편할 것이다.
> 
>
> 공유 메모리는 **프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용**해준다.
>
> 프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간을 할당해주고 이후 모든 프로세스는 해당 메모리 영역에 접근할 수 있게 된다.
>
> - **중개자 없이 곧바로 메모리에 접근할 수 있어서 IPC 중에 가장 빠르게 작동함**"
37,Operating System,IPC(Inter Process Communication),IPC 종류 - 5. 메모리 맵,"> 공유 메모리처럼 메모리를 공유해준다. 메모리 맵은 **열린 파일을 메모리에 맵핑시켜서 공유**하는 방식이다. (즉 공유 매개체가 파일+메모리)
>
> 주로 파일로 대용량 데이터를 공유해야 할 때 사용한다."
38,Operating System,IPC(Inter Process Communication),IPC 종류 - 6. 소켓,"> 네트워크 소켓 통신을 통해 데이터를 공유한다.
>
> 클라이언트와 서버가 소켓을 통해서 통신하는 구조로, 원격에서 프로세스 간 데이터를 공유할 때 사용한다.
>
> 서버(bind, listen, accept), 클라이언트(connect)"
39,Operating System,IPC(Inter Process Communication),정리,이러한 IPC 통신에서 프로세스 간 데이터를 동기화하고 보호하기 위해 세마포어와 뮤텍스를 사용한다. (공유된 자원에 한번에 하나의 프로세스만 접근시킬 때)
40,Operating System,CPU Scheduling,1. 스케쥴링,"> CPU 를 잘 사용하기 위해 프로세스를 잘 배정하기

- 조건 : 오버헤드 ↓ / 사용률 ↑ / 기아 현상 ↓
- 목표
    1. `Batch System`: 가능하면 많은 일을 수행. 시간(time) 보단 처리량(throughout)이 중요
    2. `Interactive System`: 빠른 응답 시간. 적은 대기 시간.
    3. `Real-time System`: 기한(deadline) 맞추기."
41,Operating System,CPU Scheduling,2. 선점 / 비선점 스케쥴링,"- 선점 (preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우 (처리시간 예측 어려움)
- 비선점 (nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리시간 예측 용이함)"
42,Operating System,CPU Scheduling,3. 프로세스 상태,"- 선점 스케줄링 : `Interrupt`, `I/O or Event Completion`, `I/O or Event Wait`, `Exit`
- 비선점 스케줄링 : `I/O or Event Wait`, `Exit`

---

**프로세스의 상태 전이**

✓ **승인 (Admitted)** : 프로세스 생성이 가능하여 승인됨.

✓ **스케줄러 디스패치 (Scheduler Dispatch)** : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것.

✓ **인터럽트 (Interrupt)** : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것.

✓ **입출력 또는 이벤트 대기 (I/O or Event wait)** : 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것.

✓ **입출력 또는 이벤트 완료 (I/O or Event Completion)** : 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것."
43,Operating System,CPU Scheduling,4. CPU 스케쥴링의 종류,"- 비선점 스케줄링
    1. FCFS (First Come First Served)
        - 큐에 도착한 순서대로 CPU 할당
        - 실행 시간이 짧은 게 뒤로 가면 평균 대기 시간이 길어짐
    2. SJF (Shortest Job First)
        - 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
        - FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리
    3. HRN (Hightest Response-ratio Next)
        - 우선순위를 계산하여 점유 불평등을 보완한 방법(SJF의 단점 보완)
        - 우선순위 = (대기시간 + 실행시간) / (실행시간)

- 선점 스케줄링
    1. Priority Scheduling
        - 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리
        - 우선 순위가 낮은 프로세스가 무한정 기다리는 Starvation 이 생길 수 있음
        - Aging 방법으로 Starvation 문제 해결 가능
    2. Round Robin
        - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 `Time Quantum` 만큼 CPU를 할당 받음
            - `Time Quantum` or `Time Slice` : 실행의 최소 단위 시간
        - 할당 시간(`Time Quantum`)이 크면 FCFS와 같게 되고, 작으면 문맥 교환 (Context Switching) 잦아져서 오버헤드 증가
    3. Multilevel-Queue (다단계 큐)
        - 작업들을 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 기법
        - 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐마다 다른 `Time Quantum`을 설정 해주는 방식 사용
        - 우선순위가 높은 큐는 작은 `Time Quantum` 할당. 우선순위가 낮은 큐는 큰 `Time Quantum` 할당.
    4. Multilevel-Feedback-Queue (다단계 피드백 큐)
        - 다단계 큐에서 자신의 `Time Quantum`을 다 채운 프로세스는 밑으로 내려가고 자신의 `Time Quantum`을 다 채우지 못한 프로세스는 원래 큐 그대로
            - Time Quantum을 다 채운 프로세스는 CPU burst 프로세스로 판단하기 때문
        - 짧은 작업에 유리, 입출력 위주(Interrupt가 잦은) 작업에 우선권을 줌
        - 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌"
44,Operating System,CPU Scheduling,5. CPU 스케쥴링 척도,"1. Response Time
    - 작업이 처음 실행되기까지 걸린 시간
2. Turnaround Time
    - 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때 까지 걸린 시간"
45,Operating System,"데드락 (DeadLock, 교착 상태)","데드락 (DeadLock, 교착 상태) 이란?","> 두 개 이상의 프로세스나 스레드가 서로 자원을 얻지 못해서 다음 처리를 하지 못하는 상태
>
> 무한히 다음 자원을 기다리게 되는 상태를 말한다.
>
> 시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생한다.

> _(마치, 외나무 다리의 양 끝에서 서로가 비켜주기를 기다리고만 있는 것과 같다.)_

<br>

- 데드락이 일어나는 경우

프로세스1과 2가 자원1, 2를 모두 얻어야 한다고 가정해보자

t1 : 프로세스1이 자원1을 얻음 / 프로세스2가 자원2를 얻음

t2 : 프로세스1은 자원2를 기다림 / 프로세스2는 자원1을 기다림

<br>

현재 서로 원하는 자원이 상대방에 할당되어 있어서 두 프로세스는 무한정 wait 상태에 빠짐

→ 이것이 바로 **DeadLock**!!!!!!

<br>

(주로 발생하는 경우)

> 멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생
>
> 한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 이때 프로세스는 대기 상태로 들어감
>
> 대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때 '교착 상태' 발생"
46,Operating System,"데드락 (DeadLock, 교착 상태)",데드락 (DeadLock) 발생 조건,"> 4가지 모두 성립해야 데드락 발생
>
> (하나라도 성립하지 않으면 데드락 문제 해결 가능)

1. ##### 상호 배제(Mutual exclusion)

   > 자원은 한번에 한 프로세스만 사용할 수 있음

2. ##### 점유 대기(Hold and wait)

   > 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함

3. ##### 비선점(No preemption)

   > 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음

4. ##### 순환 대기(Circular wait)

   > 프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함"
47,Operating System,"데드락 (DeadLock, 교착 상태)",데드락 (DeadLock) 처리,"1. 교착 상태를 예방 & 회피
2. 교착 상태를 탐지 & 회복"
48,Operating System,"데드락 (DeadLock, 교착 상태)",1. 교착 상태를 예방 & 회피,"1. ##### 예방(prevention)

   교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비 엄청 심함)

   > - 상호배제 부정 : 여러 프로세스가 공유 자원 사용
   > - 점유대기 부정 : 프로세스 실행전 모든 자원을 할당
   > - 비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납
   > - 순환대기 부정 : 자원에 고유번호 할당 후 순서대로 자원 요구

2. ##### 회피(avoidance)

   교착 상태 발생 시 피해나가는 방법

   > 은행원 알고리즘(Banker's Algorithm)
   >
   > - 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래함
   > - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태 회피
   > - 안정 상태면 자원 할당, 아니면 다른 프로세스들이 자원 해지까지 대기

   > 자원 할당 그래프 알고리즘(Resource-Allocation Graph Algorithm)
   >
   > - 자원과 프로세스에 대해 요청 간선과 할당 간선을 적용하여 교착 상태를 회피하는 알고리즘
   > - 프로세스가 자원을 요구 시 요청 간선을 할당 간선으로 변경 했을 시 사이클이 생성 되는지 확인한다
   > - 사이클이 생성된다 하여 무조건 교착상태인 것은 아니다
   >   > - 자원에 하나의 인스턴스만 존재 시 **교착 상태**로 판별한다
   >   > - 자원에 여러 인스턴스가 존재 시 **교착 상태 가능성**으로 판별한다
   > - 사이클을 생성하지 않으면 자원을 할당한다"
49,Operating System,"데드락 (DeadLock, 교착 상태)",2. 교착 상태를 탐지 & 회복,"교착 상태가 되도록 허용한 다음 회복시키는 방법

1. ##### 탐지(Detection)

   자원 할당 그래프를 통해 교착 상태를 탐지함

   자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함

2. ##### 회복(Recovery)

   교착 상태 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법

   > ##### 프로세스 종료 방법
   >
   > - 교착 상태의 프로세스를 모두 중지
   > - 교착 상태가 제거될 때까지 하나씩 프로세스 중지
   >
   > ##### 자원 선점 방법
   >
   > - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴)
   > - 우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점"
50,Operating System,"데드락 (DeadLock, 교착 상태)",주요 질문,"1. 데드락(교착 상태)가 뭔가요? 발생 조건에 대해 말해보세요.

2. 회피 기법인 은행원 알고리즘이 뭔지 설명해보세요.

3. 기아상태를 설명하는 식사하는 철학자 문제에 대해 설명해보세요.

   > 교착 상태 해결책
   >
   > 1. n명이 앉을 수 있는 테이블에서 철학자를 n-1명만 앉힘
   > 2. 한 철학자가 젓가락 두개를 모두 집을 수 있는 상황에서만 젓가락 집도록 허용
   > 3. 누군가는 왼쪽 젓가락을 먼저 집지 않고 오른쪽 젓가락을 먼저 집도록 허용"
51,Operating System,경쟁 상태 (Race Condition),경쟁 상태란?,"공유 자원에 대해 여러 프로세스가 동시에 접근할 때, 결과값에 영향을 줄 수 있는 상태

> 동시 접근 시 자료의 일관성을 해치는 결과가 나타남"
52,Operating System,경쟁 상태 (Race Condition),경쟁 상태가 발생하는 경우,"1. ##### 커널 작업을 수행하는 중에 인터럽트 발생

   - 문제점 : 커널모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우
   - 해결법 : 커널모드에서 작업을 수행하는 동안, 인터럽트를 disable 시켜 CPU 제어권을 가져가지 못하도록 한다.

2. ##### 프로세스가 'System Call'을 하여 커널 모드로 진입하여 작업을 수행하는 도중 문맥 교환이 발생할 때

   - 문제점 : 프로세스1이 커널모드에서 데이터를 조작하는 도중, 시간이 초과되어 CPU 제어권이 프로세스2로 넘어가 같은 데이터를 조작하는 경우 ( 프로세스2가 작업에 반영되지 않음 )
   - 해결법 : 프로세스가 커널모드에서 작업을 하는 경우 시간이 초과되어도 CPU 제어권이 다른 프로세스에게 넘어가지 않도록 함

3. ##### 멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 때

   - 문제점 : 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우
   - 해결법 : 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 하는 방법"
53,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),세마포어 (Semaphore),"공유된 자원에 여러 프로세스가 동시에 접근하면서 문제가 발생할 수 있다. 이때 공유된 자원의 데이터는 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 둬야 한다.

이를 위해 나온 것이 바로 **'세마포어'**

**세마포어** : 멀티프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법"
54,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),임계 구역(Critical Section),"> 여러 프로세스가 데이터를 공유하며 수행될 때, **각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분**

공유 데이터를 여러 프로세스가 동시에 접근할 때 잘못된 결과를 만들 수 있기 때문에, 한 프로세스가 임계 구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야 한다."
55,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),"세마포어 P, V 연산","P : 임계 구역 들어가기 전에 수행 ( 프로세스 진입 여부를 자원의 개수(S)를 통해 결정)

V : 임계 구역에서 나올 때 수행 ( 자원 반납 알림, 대기 중인 프로세스를 깨우는 신호 )

<br>

##### 구현 방법

```sql
P(S);

// --- 임계 구역 ---

V(S);
```

<br>

```sql
procedure P(S)   --> 최초 S값은 1임
    while S=0 do wait  --> S가 0면 1이 될때까지 기다려야 함
    S := S-1   --> S를 0로 만들어 다른 프로세스가 들어 오지 못하도록 함
end P

--- 임계 구역 ---

procedure V(S) --> 현재상태는 S가 0임
    S := S+1   --> S를 1로 원위치시켜 해제하는 과정
end V
```

이를 통해, 한 프로세스가 P 혹은 V를 수행하고 있는 동안 프로세스가 인터럽트 당하지 않게 된다. P와 V를 사용하여 임계 구역에 대한 상호배제 구현이 가능하게 되었다.

***예시***

> 최초 S 값은 1이고, 현재 해당 구역을 수행할 프로세스 A, B가 있다고 가정하자

1. 먼저 도착한 A가 P(S)를 실행하여 S를 0으로 만들고 임계구역에 들어감
2. 그 뒤에 도착한 B가 P(S)를 실행하지만 S가 0이므로 대기 상태
3. A가 임계구역 수행을 마치고 V(S)를 실행하면 S는 다시 1이 됨
4. B는 이제 P(S)에서 while문을 빠져나올 수 있고, 임계구역으로 들어가 수행함"
56,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),뮤텍스,"임계 구역을 가진 스레드들의 실행시간이 서로 겹치지 않고 각각 단독으로 실행되게 하는 기술

> 상호 배제(**Mut**ual **Ex**clusion)의 약자임

해당 접근을 조율하기 위해 lock과 unlock을 사용한다.

- lock : 현재 임계 구역에 들어갈 권한을 얻어옴 ( 만약 다른 프로세스/스레드가 임계 구역 수행 중이면 종료할 때까지 대기 )
- unlock : 현재 임계 구역을 모두 사용했음을 알림. ( 대기 중인 다른 프로세스/스레드가 임계 구역에 진입할 수 있음 )

<br>

뮤텍스는 상태가 0, 1로 **이진 세마포어**로 부르기도 함"
57,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),뮤텍스 알고리즘 - Dekker 알고리즘,"1. ##### 데커(Dekker) 알고리즘

   flag와 turn 변수를 통해 임계 구역에 들어갈 프로세스/스레드를 결정하는 방식

   - flag : 프로세스 중 누가 임계영역에 진입할 것인지 나타내는 변수
   - turn : 누가 임계구역에 들어갈 차례인지 나타내는 변수

   ```java
   while(true) {
       flag[i] = true; // 프로세스 i가 임계 구역 진입 시도
       while(flag[j]) { // 프로세스 j가 현재 임계 구역에 있는지 확인
           if(turn == j) { // j가 임계 구역 사용 중이면
               flag[i] = false; // 프로세스 i 진입 취소
               while(turn == j); // turn이 j에서 변경될 때까지 대기
               flag[i] = true; // j turn이 끝나면 다시 진입 시도
           }
       }
   }
   
   // ------- 임계 구역 ---------
   
   turn = j; // 임계 구역 사용 끝나면 turn을 넘김
   flag[i] = false; // flag 값을 false로 바꿔 임계 구역 사용 완료를 알림
   ```"
58,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),뮤텍스 알고리즘 - Peterson 알고리즘,"2. ##### 피터슨(Peterson) 알고리즘

   데커와 유사하지만, 상대방 프로세스/스레드에게 진입 기회를 양보하는 것에 차이가 있음

   ```java
   while(true) {
       flag[i] = true; // 프로세스 i가 임계 구역 진입 시도
       turn = j; // 다른 프로세스에게 진입 기회 양보
       while(flag[j] && turn == j) { // 다른 프로세스가 진입 시도하면 대기
       }
   }
   
   // ------- 임계 구역 ---------
   
   flag[i] = false; // flag 값을 false로 바꿔 임계 구역 사용 완료를 알림
   ```"
59,Operating System,세마포어(Semaphore) & 뮤텍스(Mutex),뮤텍스 알고리즘 - Bakery 알고리즘,"3. ##### 제과점(Bakery) 알고리즘

   여러 프로세스/스레드에 대한 처리가 가능한 알고리즘. 가장 작은 수의 번호표를 가지고 있는 프로세스가 임계 구역에 진입한다.

   ```java
   while(true) {
       
       isReady[i] = true; // 번호표 받을 준비
       number[i] = max(number[0~n-1]) + 1; // 현재 실행 중인 프로세스 중에 가장 큰 번호 배정 
       isReady[i] = false; // 번호표 수령 완료
       
       for(j = 0; j < n; j++) { // 모든 프로세스 번호표 비교
           while(isReady[j]); // 비교 프로세스가 번호표 받을 때까지 대기
           while(number[j] && number[j] < number[i] && j < i);
           
           // 프로세스 j가 번호표 가지고 있어야 함
           // 프로세스 j의 번호표 < 프로세스 i의 번호표
       }
   
       // ------- 임계 구역 ---------
   
       number[i] = 0; // 임계 구역 사용 종료
   }
   ```"
60,Operating System,페이징과 세그먼테이션,기법을 쓰는 이유,> 다중 프로그래밍 시스템에 여러 프로세스를 수용하기 위해 주기억장치를 동적 분할하는 메모리 관리 작업이 필요해서
61,Operating System,페이징과 세그먼테이션,메모리 관리 기법,"1. 연속 메모리 관리

   > 프로그램 전체가 하나의 커다란 공간에 연속적으로 할당되어야 함

   - 고정 분할 기법 : 주기억장치가 고정된 파티션으로 분할 (**내부 단편화 발생**)
   - 동적 분할 기법 : 파티션들이 동적 생성되며 자신의 크기와 같은 파티션에 적재 (**외부 단편화 발생**)

   <br>

2. 불연속 메모리 관리

   > 프로그램의 일부가 서로 다른 주소 공간에 할당될 수 있는 기법

   페이지 : 고정 사이즈의 작은 프로세스 조각

   프레임 : 페이지 크기와 같은 주기억장치 메모리 조각

   단편화 : 기억 장치의 빈 공간 or 자료가 여러 조각으로 나뉘는 현상

   세그먼트 : 서로 다른 크기를 가진 논리적 블록이 연속적 공간에 배치되는 것
   <br>

   **고정 크기** : 페이징(Paging)

   **가변 크기** : 세그먼테이션(Segmentation)
   <br>

   - 단순 페이징

     > 각 프로세스는 프레임들과 같은 길이를 가진 균등 페이지로 나뉨
     >
     > 외부 단편화 X
     >
     > 소량의 내부 단편화 존재

   - 단순 세그먼테이션

     > 각 프로세스는 여러 세그먼트들로 나뉨
     >
     > 내부 단편화 X, 메모리 사용 효율 개선, 동적 분할을 통한 오버헤드 감소
     >
     > 외부 단편화 존재

   - 가상 메모리 페이징

     > 단순 페이징과 비교해 프로세스 페이지 전부를 로드시킬 필요X
     >
     > 필요한 페이지가 있으면 나중에 자동으로 불러들어짐
     >
     > 외부 단편화 X
     >
     > 복잡한 메모리 관리로 오버헤드 발생

   - 가상 메모리 세그먼테이션

     > 필요하지 않은 세그먼트들은 로드되지 않음
     >
     > 필요한 세그먼트 있을때 나중에 자동으로 불러들어짐
     >
     > 내부 단편화X
     >
     > 복잡한 메모리 관리로 오버헤드 발생"
62,Operating System,페이지 교체 알고리즘,페이지 교체 알고리즘,"> 페이지 부재 발생 → 새로운 페이지를 할당해야 함 → 현재 할당된 페이지 중 어떤 것 교체할 지 결정하는 방법

<br>

- 좀 더 자세하게 생각해보면?

가상 메모리는 `요구 페이지 기법`을 통해 필요한 페이지만 메모리에 적재하고 사용하지 않는 부분은 그대로 둠

하지만 필요한 페이지만 올려도 메모리는 결국 가득 차게 되고, 올라와있던 페이지가 사용이 다 된 후에도 자리만 차지하고 있을 수 있음

따라서 메모리가 가득 차면, 추가로 페이지를 가져오기 위해서 안쓰는 페이지는 out하고, 해당 공간에 현재 필요한 페이지를 in 시켜야 함

여기서 어떤 페이지를 out 시켜야할 지 정해야 함. (이때 out 되는 페이지를 victim page라고 부름) 

기왕이면 수정이 되지 않는 페이지를 선택해야 좋음
(Why? : 만약 수정되면 메인 메모리에서 내보낼 때, 하드디스크에서 또 수정을 진행해야 하므로 시간이 오래 걸림)

> 이와 같은 상황에서 상황에 맞는 페이지 교체를 진행하기 위해 페이지 교체 알고리즘이 존재하는 것!"
63,Operating System,페이지 교체 알고리즘,Page Reference String,"> CPU는 논리 주소를 통해 특정 주소를 요구함
>
> 메인 메모리에 올라와 있는 주소들은 페이지의 단위로 가져오기 때문에 페이지 번호가 연속되어 나타나게 되면 페이지 결함 발생 X
>
> 따라서 CPU의 주소 요구에 따라 페이지 결함이 일어나지 않는 부분은 생략하여 표시하는 방법이 바로 `Page Reference String`"
64,Operating System,페이지 교체 알고리즘,1. FIFO 알고리즘,"1. ##### FIFO 알고리즘

   > First-in First-out, 메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘

   victim page : out 되는 페이지는, 가장 먼저 메모리에 올라온 페이지

   가장 간단한 방법으로, 특히 초기화 코드에서 적절한 방법임

   `초기화 코드` : 처음 프로세스 실행될 때 최초 초기화를 시키는 역할만 진행하고 다른 역할은 수행하지 않으므로, 메인 메모리에서 빼도 괜찮음

   하지만 처음 프로세스 실행시에는 무조건 필요한 코드이므로, FIFO 알고리즘을 사용하면 초기화를 시켜준 후 가장 먼저 내보내는 것이 가능함"
65,Operating System,페이지 교체 알고리즘,2. OPT 알고리즘,"2. ##### OPT 알고리즘

   > Optimal Page Replacement 알고리즘, 앞으로 가장 사용하지 않을 페이지를 가장 우선적으로 내보냄

   FIFO에 비해 페이지 결함의 횟수를 많이 감소시킬 수 있음

   하지만, 실질적으로 페이지가 앞으로 잘 사용되지 않을 것이라는 보장이 없기 때문에 수행하기 어려운 알고리즘임"
66,Operating System,페이지 교체 알고리즘,3. LRU 알고리즘,"3. ##### LRU 알고리즘

   > Least-Recently-Used, 최근에 사용하지 않은 페이지를 가장 먼저 내려보내는 알고리즘

   최근에 사용하지 않았으면, 나중에도 사용되지 않을 것이라는 아이디어에서 나옴

   OPT의 경우 미래 예측이지만, LRU의 경우는 과거를 보고 판단하므로 실질적으로 사용이 가능한 알고리즘

   (실제로도 최근에 사용하지 않은 페이지는 앞으로도 사용하지 않을 확률이 높다)

   OPT보다는 페이지 결함이 더 일어날 수 있지만, **실제로 사용할 수 있는 페이지 교체 알고리즘에서는 가장 좋은 방법 중 하나임**"
67,Operating System,페이지 교체 알고리즘,교체 방식,"##### 교체 방식

- Global 교체

  > 메모리 상의 모든 프로세스 페이지에 대해 교체하는 방식

- Local 교체

  > 메모리 상의 자기 프로세스 페이지에서만 교체하는 방식



다중 프로그래밍의 경우, 메인 메모리에 다양한 프로세스가 동시에 올라올 수 있음

따라서, 다양한 프로세스의 페이지가 메모리에 존재함

페이지 교체 시, 다양한 페이지 교체 알고리즘을 활용해 victim page를 선정하는데, 선정 기준을 Global로 하느냐, Local로 하느냐에 대한 차이

→ 실제로는 전체를 기준으로 페이지를 교체하는 것이 더 효율적이라고 함. 자기 프로세스 페이지에서만 교체를 하면, 교체를 해야할 때 각각 모두 교체를 진행해야 하므로 비효율적"
68,Operating System,메인 메모리 (Main Memory),메인 메모리란?,"> 메인 메모리는 CPU가 직접 접근할 수 있는 기억 장치
>
> 프로세스가 실행되려면 프로그램이 메모리에 올라와야 함

메모리는 주소가 할당된 일련의 바이트들로 구성되어 있다.

CPU는 레지스터가 지시하는 대로 메모리에 접근하여 다음 수행할 명령어를 가져온다.

명령어 수행 시 메모리에 필요한 데이터가 없으면 메모리로 해당 데이터를 우선 가져와야 한다.

이 역할을 하는 것이 바로 **MMU**이다."
69,Operating System,메인 메모리 (Main Memory),"MMU (Memory Management Unit, 메모리 관리 장치)","> 논리 주소를 물리 주소로 변환해 줌
>
> 메모리 보호나 캐시 관리 등 CPU가 메모리에 접근하는 것을 총관리해 주는 하드웨어

메모리의 공간이 한정적이기 때문에, 사용자에게 더 많은 메모리를 제공하기 위해 '가상 주소'라는 개념이 등장한다.

가상 주소는 프로그램상에서 사용자가 보는 주소 공간이라고 보면 된다.

이 가상 주소에서 실제 데이터가 담겨 있는 곳에 접근하기 위해서 빠른 주소 변환이 필요한데, 이를 MMU가 도와준다.

즉, MMU의 역할은 다음과 같다고 말할 수 있다.

- MMU가 지원되지 않으면, 물리 주소에 직접 접근해야 하기 때문에 부담이 있다.
- MMU는 사용자가 기억 장소를 일일이 할당해야 하는 불편을 없애 준다.
- 프로세스의 크기가 실제 메모리의 용량을 초과해도 실행될 수 있게 해 준다.

또한 메인 메모리 직접 접근은 비효율적이므로, CPU와 메인 메모리 속도를 맞추기 위해 캐시가 존재한다."
70,Operating System,메인 메모리 (Main Memory),MMU의 메모리 보호,"프로세스는 독립적인 메모리 공간을 가져야 하고, 자신의 공간에만 접근해야 한다.

따라서 한 프로세스의 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호한다.

**base와 limit 레지스터를 활용한 메모리 보호 기법**

- base 레지스터: 메모리상의 프로세스 시작 주소를 물리 주소로 저장
- limit 레지스터: 프로세스의 사이즈를 저장

이로써 프로세스의 접근 가능한 합법적인 메모리 영역(x)은 다음과 같다.

```
base <= x < base+limit
```

이 영역 밖에서 접근을 요구하면 trap을 발생시킨다.

안전성을 위해 base와 limit 레지스터는 커널 모드에서만 수정 가능하도록(사용자 모드에서는 직접 변경할 수 없도록) 설계된다."
71,Operating System,메인 메모리 (Main Memory),메모리 과할당 (over allocating),"> 실제 메모리의 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황

페이지 기법과 같은 메모리 관리 기법은 사용자가 눈치채지 못하도록 눈속임을 통해(가상 메모리를 이용해서) 메모리를 할당해 준다. 

다음과 같은 상황에서 사용자를 속이고 과할당한 것을 들킬 수 있다.

1. 프로세스 실행 도중 페이지 폴트 발생
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
3. 메모리의 빈 프레임에 페이지를 올려야 하는데, 모든 메모리가 사용 중이라 빈 프레임이 없음

과할당을 해결하기 위해서는, 빈 프레임을 확보할 수 있어야 한다.

1. 메모리에 올라와 있는 한 프로세스를 종료시켜 빈 프레임을 얻음
2. 프로세스 하나를 swap out하고, 이 공간을 빈 프레임으로 활용

swapping 기법을 통해 공간을 바꿔치기하는 2번 방법과 달리 1번 방법은 사용자에게 페이징 시스템을 들킬 가능성이 매우 높다.

페이징 기법은 시스템 능률을 높이기 위해 OS 스스로 선택한 일이므로 사용자에게 들키지 않고 처리해야 한다.

따라서 2번 해결 방법을 통해 페이지 교체가 이루어져야 한다."
72,Operating System,메인 메모리 (Main Memory),페이지 교체,"> 메모리 과할당이 발생했을 때, 프로세스 하나를 swap out해서 빈 프레임을 확보하는 것

1. 프로세스 실행 도중 페이지 부재 발생

2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음

3. 메모리에 빈 프레임이 있는지 확인

   - 빈 프레임이 있으면, 해당 프레임을 사용
   - 빈 프레임이 없으면, victim 프레임을 선정해 디스크에 기록하고 페이지 테이블 업데이트

4. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고 페이지 테이블 업데이트

페이지 교체가 이루어지면 아무 일이 없던 것처럼 프로세스를 계속 수행시켜 주면서 사용자가 알지 못하도록 해야 한다.

이때 아무 일도 일어나지 않은 것처럼 하려면, 페이지 교체 당시 오버헤드를 최대한 줄여야 한다."
73,Operating System,메인 메모리 (Main Memory),오버헤드를 감소시키는 해결법,"이처럼 빈 프레임이 없는 상황에서 victim 프레임을 비울 때와 원하는 페이지를 프레임으로 올릴 때 두 번의 디스크 접근이 이루어진다.

페이지 교체가 많이 이루어지면, 이처럼 입출력 연산이 많이 발생하게 되면서 오버헤드 문제가 발생한다.

<br>

**방법 1**

비트를 활용해 디스크에 기록하는 횟수를 줄이면서 오버헤드를 최대 절반으로 감소시키는 방법이다.

모든 페이지마다 변경 비트를 두고, victim 페이지가 정해지면 해당 페이지의 변경 비트를 확인한다.

- 변경 비트가 set 상태라면?
    * 메모리상의 페이지 내용이 디스크상의 페이지 내용과 달라졌다는 뜻
    * 페이지가 메모리로 올라온 이후 수정돼서 내려갈 때 디스크에 기록해야 함
- 변경 비트가 clear 상태라면?
    * 메모리상의 페이지 내용이 디스크상의 페이지 내용과 정확히 일치한다는 뜻
    * 페이지가 디스크상의 페이지 내용과 같아서 내려갈 때 기록할 필요가 없음

<br>

**방법 2**

현재 상황에서 페이지 폴트가 발생할 확률을 최대한 줄일 수 있는 교체 알고리즘을 선택한다.

- FIFO
- OPT
- LRU

<br>

### 캐시 메모리

> 메인 메모리에 저장된 내용의 일부를 임시로 저장해 두는 기억 장치
>
> CPU와 메인 메모리의 속도 차이로 인한 성능 저하를 방지하는 방법

CPU가 이미 본 데이터에 재접근할 때, 메모리 참조 및 인출 과정 비용을 줄이기 위해 캐시에 저장해 둔 데이터를 활용한다.

캐시는 플립플롭 소자로 구성된 SRAM으로 이루어져 있어서 DRAM보다 빠르다는 장점이 있다.

- 메인 메모리: DRAM
- 캐시 메모리: SRAM"
74,Operating System,메인 메모리 (Main Memory),CPU와 기억 장치의 상호작용,"- CPU에서 주소 전달 → 캐시 메모리에 명령어가 존재하는지 확인

   * (존재) Hit → 해당 명령어를 CPU로 전송 → 완료

   * (비존재) Miss → 명령어를 포함한 메인 메모리에 접근 → 해당 명령어를 가진 데이터 인출 → 해당 명령어 데이터를 캐시에 저장 → 해당 명령어를 CPU로 전송 → 완료

많이 활용되는 쓸모 있는 데이터가 캐시에 들어 있어야 성능이 높아진다.

따라서 CPU가 어떤 데이터를 원할지 어느 정도 예측할 수 있어야 한다.

적중률을 극대화하기 위해 사용되는 것이 바로 `지역성의 원리`이다.

<br>

##### 지역성

> 기억 장치 내의 데이터에 균일하게 접근하는 것이 아니라 한순간에 특정 부분을 집중적으로 참조하는 특성

지역성의 종류는 시간과 공간으로 나누어진다.

**시간 지역성**: 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성

**공간 지역성**: 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

<br>

### 캐싱 라인

빈번하게 사용되는 데이터들을 캐시에 저장했더라도, 내가 필요한 데이터를 캐시에서 찾을 때 모든 데이터를 순회하는 것은 시간 낭비다.

즉, 캐시에 목적 데이터가 저장되어 있을 때 바로 접근하여 출력할 수 있어야 캐시 활용이 의미 있게 된다.

따라서 캐시에 데이터를 저장할 시 자료 구조를 활용해 묶어서 저장하는데, 이를 `캐싱 라인`이라고 부른다.

캐시에 저장하는 데이터의 메모리 주소를 함께 저장하면서 빠르게 원하는 정보를 찾을 수 있다. (set, map 등 활용)"
75,Operating System,파일 시스템 (File System),파일 시스템이란?,"컴퓨터에서 파일이나 자료를 쉽게 발견할 수 있도록, 유지 및 관리하는 방법이다.

저장매체에는 수많은 파일이 있기 때문에, 이런 파일들을 관리하는 방법을 말한다."
76,Operating System,파일 시스템 (File System),파일 시스템의 특징,"- 커널 영역에서 동작
- 파일 CRUD 기능을 원활히 수행하기 위한 목적

- 계층적 디렉터리 구조를 가짐
- 디스크 파티션 별로 하나씩 둘 수 있음"
77,Operating System,파일 시스템 (File System),파일 시스템의 역할,"- 파일 관리
- 보조 저장소 관리
- 파일 무결성 메커니즘
- 접근 방법 제공"
78,Operating System,파일 시스템 (File System),파일 시스템의 개발 목적,"- 하드디스크와 메인 메모리 속도차를 줄이기 위함
- 파일 관리
- 하드디스크 용량 효율적 이용"
79,Operating System,파일 시스템 (File System),파일 시스템의 구조,"- 메타 영역 : 데이터 영역에 기록된 파일의 이름, 위치, 크기, 시간정보, 삭제유무 등의 파일 정보
- 데이터 영역 : 파일의 데이터"
80,Operating System,파일 시스템 (File System),접근 방법 - 1. 순차 접근,"1. ##### 순차 접근(Sequential Access)

   > 가장 간단한 접근 방법으로, 대부분 연산은 read와 write

   현재 위치를 가리키는 포인터에서 시스템 콜이 발생할 경우 포인터를 앞으로 보내면서 read와 write를 진행. 뒤로 돌아갈 땐 지정한 offset만큼 되감기를 해야 한다. (테이프 모델 기반)"
81,Operating System,파일 시스템 (File System),접근 방법 - 2. 직접 접근,"2. ##### 직접 접근(Direct Access)

   > 특별한 순서없이, 빠르게 레코드를 read, write 가능

   현재 위치를 가리키는 cp 변수만 유지하면 직접 접근 파일을 가지고 순차 파일 기능을 쉽게 구현이 가능하다.

   무작위 파일 블록에 대한 임의 접근을 허용한다. 따라서 순서의 제약이 없음

   대규모 정보를 접근할 때 유용하기 때문에 '데이터베이스'에 활용된다."
82,Operating System,파일 시스템 (File System),접근 방법 - 3. 기타 접근,"3. 기타 접근

   > 직접 접근 파일에 기반하여 색인 구축

   크기가 큰 파일을 입출력 탐색할 수 있게 도와주는 방법임"
83,Operating System,파일 시스템 (File System),데렉터리와 디스크 구조,"- ##### 1단계 디렉터리

  > 가장 간단한 구조

  파일들은 서로 유일한 이름을 가짐. 서로 다른 사용자라도 같은 이름 사용 불가

- ##### 2단계 디렉터리

  > 사용자에게 개별적인 디렉터리 만들어줌

  - UFD : 자신만의 사용자 파일 디렉터리
  - MFD : 사용자의 이름과 계정번호로 색인되어 있는 디렉터리

- ##### 트리 구조 디렉터리

  > 2단계 구조 확장된 다단계 트리 구조

  한 비트를 활용하여, 일반 파일(0)인지 디렉터리 파일(1) 구분

- 그래프 구조 디렉터리

  > 순환이 발생하지 않도록 하위 디렉터리가 아닌 파일에 대한 링크만 허용하거나, 가비지 컬렉션을 이용해 전체 파일 시스템을 순회하고 접근 가능한 모든 것을 표시

  링크가 있으면 우회하여 순환을 피할 수 있음"
84,Computer Architecture,컴퓨터의 구성,컴퓨터의 구성,"컴퓨터 시스템은 크게 하드웨어와 소프트웨어로 나누어진다.

**하드웨어** : 컴퓨터를 구성하는 기계적 장치

**소프트웨어** : 하드웨어의 동작을 지시하고 제어하는 명령어 집합"
85,Computer Architecture,컴퓨터의 구성,하드웨어,"- 중앙처리장치(CPU)
- 기억장치 : RAM, HDD
- 입출력 장치 : 마우스, 프린터"
86,Computer Architecture,컴퓨터의 구성,소프트웨어,"하드웨어는 중앙처리장치(CPU), 기억장치, 입출력장치로 구성되어 있다.

이들은 시스템 버스로 연결되어 있으며, 시스템 버스는 데이터와 명령 제어 신호를 각 장치로 실어나르는 역할을 한다."
87,Computer Architecture,컴퓨터의 구성,중앙처리장치(CPU),"인간으로 따지면 두뇌에 해당하는 부분

주기억장치에서 프로그램 명령어와 데이터를 읽어와 처리하고 명령어의 수행 순서를 제어함
중앙처리장치는 비교와 연산을 담당하는 <strong>산술논리연산장치(ALU)</strong>와 명령어의 해석과 실행을 담당하는 **제어장치**, 속도가 빠른 데이터 기억장소인 **레지스터**로 구성되어있음

개인용 컴퓨터와 같은 소형 컴퓨터에서는 CPU를 마이크로프로세서라고도 부름"
88,Computer Architecture,컴퓨터의 구성,기억장치,"프로그램, 데이터, 연산의 중간 결과를 저장하는 장치

주기억장치와 보조기억장치로 나누어지며, RAM과 ROM도 이곳에 해당함. 실행중인 프로그램과 같은 프로그램에 필요한 데이터를 일시적으로 저장한다.

보조기억장치는 하드디스크 등을 말하며, 주기억장치에 비해 속도는 느리지만 많은 자료를 영구적으로 보관할 수 있는 장점이 있다."
89,Computer Architecture,컴퓨터의 구성, 입출력장치,"입력과 출력 장치로 나누어짐. 

입력 장치는 컴퓨터 내부로 자료를 입력하는 장치 (키보드, 마우스 등)

출력 장치는 컴퓨터에서 외부로 표현하는 장치 (프린터, 모니터, 스피커 등)"
90,Computer Architecture,컴퓨터의 구성,시스템 버스,"> 하드웨어 구성 요소를 물리적으로 연결하는 선

각 구성요소가 다른 구성요소로 데이터를 보낼 수 있도록 통로가 되어줌

용도에 따라 데이터 버스, 주소 버스, 제어 버스로 나누어짐"
91,Computer Architecture,컴퓨터의 구성,데이터 버스,"중앙처리장치와 기타 장치 사이에서 데이터를 전달하는 통로

기억장치와 입출력장치의 명령어와 데이터를 중앙처리장치로 보내거나, 중앙처리장치의 연산 결과를 기억장치와 입출력장치로 보내는 '양방향' 버스임"
92,Computer Architecture,컴퓨터의 구성,주소 버스,"데이터를 정확히 실어나르기 위해서는 기억장치 '주소'를 정해주어야 함.

주소버스는 중앙처리장치가 주기억장치나 입출력장치로 기억장치 주소를 전달하는 통로이기 때문에 '단방향' 버스임"
93,Computer Architecture,컴퓨터의 구성,제어 버스,"주소 버스와 데이터 버스는 모든 장치에 공유되기 때문에 이를 제어할 수단이 필요함

제어 버스는 중앙처리장치가 기억장치나 입출력장치에 제어 신호를 전달하는 통로임

제어 신호 종류 : 기억장치 읽기 및 쓰기, 버스 요청 및 승인, 인터럽트 요청 및 승인, 클락, 리셋 등

제어 버스는 읽기 동작과 쓰기 동작을 모두 수행하기 때문에 '양방향' 버스임

<br>

컴퓨터는 기본적으로 **읽고 처리한 뒤 저장**하는 과정으로 이루어짐

(READ → PROCESS → WRITE)

이 과정을 진행하면서 끊임없이 주기억장치(RAM)과 소통한다. 이때 운영체제가 64bit라면, CPU는 RAM으로부터 데이터를 한번에 64비트씩 읽어온다."
94,Computer Architecture,중앙처리장치(CPU) 작동 원리,연산 장치,"  > 산술연산과 논리연산 수행 (따라서 산술논리연산장치라고도 불림)
  >
  > 연산에 필요한 데이터를 레지스터에서 가져오고, 연산 결과를 다시 레지스터로 보냄"
95,Computer Architecture,중앙처리장치(CPU) 작동 원리,제어 장치,"  > 명령어를 순서대로 실행할 수 있도록 제어하는 장치
  >
  > 주기억장치에서 프로그램 명령어를 꺼내 해독하고, 그 결과에 따라 명령어 실행에 필요한 제어 신호를 기억장치, 연산장치, 입출력장치로 보냄
  >
  > 또한 이들 장치가 보낸 신호를 받아, 다음에 수행할 동작을 결정함"
96,Computer Architecture,중앙처리장치(CPU) 작동 원리,레지스터,"  > 고속 기억장치임
  >
  > 명령어 주소, 코드, 연산에 필요한 데이터, 연산 결과 등을 임시로 저장
  >
  > 용도에 따라 범용 레지스터와 특수목적 레지스터로 구분됨
  >
  > 중앙처리장치 종류에 따라 사용할 수 있는 레지스터 개수와 크기가 다름
  >
  > - 범용 레지스터 : 연산에 필요한 데이터나 연산 결과를 임시로 저장
  > - 특수목적 레지스터 : 특별한 용도로 사용하는 레지스터"
97,Computer Architecture,중앙처리장치(CPU) 작동 원리,특수 목적 레지스터 중 중요한 것들,"- MAR(메모리 주소 레지스터) : 읽기와 쓰기 연산을 수행할 주기억장치 주소 저장
- PC(프로그램 카운터) : 다음에 수행할 명령어 주소 저장
- IR(명령어 레지스터) : 현재 실행 중인 명령어 저장
- MBR(메모리 버퍼 레지스터) : 주기억장치에서 읽어온 데이터 or 저장할 데이터 임시 저장
- AC(누산기) : 연산 결과 임시 저장"
98,Computer Architecture,중앙처리장치(CPU) 작동 원리,CPU의 동작 과정,"1. 주기억장치는 입력장치에서 입력받은 데이터 또는 보조기억장치에 저장된 프로그램 읽어옴
2. CPU는 프로그램을 실행하기 위해 주기억장치에 저장된 프로그램 명령어와 데이터를 읽어와 처리하고 결과를 다시 주기억장치에 저장
3. 주기억장치는 처리 결과를 보조기억장치에 저장하거나 출력장치로 보냄
4. 제어장치는 1~3 과정에서 명령어가 순서대로 실행되도록 각 장치를 제어"
99,Computer Architecture,중앙처리장치(CPU) 작동 원리,명령어 세트란?,"CPU가 실행할 명령어의 집합

> 연산 코드(Operation Code) + 피연산자(Operand)로 이루어짐
>
> 연산 코드 : 실행할 연산
>
> 피연산자 : 필요한 데이터 or 저장 위치



연산 코드는 연산, 제어, 데이터 전달, 입출력 기능을 가짐

피연산자는 주소, 숫자/문자, 논리 데이터 등을 저장



CPU는 프로그램 실행하기 위해 주기억장치에서 명령어를 순차적으로 인출하여 해독하고 실행하는 과정을 반복함

CPU가 주기억장치에서 한번에 하나의 명령어를 인출하여 실행하는데 필요한 일련의 활동을 '명령어 사이클'이라고 말함

명령어 사이클은 인출/실행/간접/인터럽트 사이클로 나누어짐

주기억장치의 지정된 주소에서 하나의 명령어를 가져오고, 실행 사이클에서는 명령어를 실행함. 하나의 명령어 실행이 완료되면 그 다음 명령어에 대한 인출 사이클 시작"
100,Computer Architecture,중앙처리장치(CPU) 작동 원리,인출 사이클 - 인출하기,"> 인출 사이클에서 가장 중요한 부분은 PC(프로그램 카운터) 값 증가

- PC에 저장된 주소를 MAR로 전달

- 저장된 내용을 토대로 주기억장치의 해당 주소에서 명령어 인출
- 인출한 명령어를 MBR에 저장
- 다음 명령어를 인출하기 위해 PC 값 증가시킴
- 메모리 버퍼 레지스터(MBR)에 저장된 내용을 명령어 레지스터(IR)에 전달

```
T0 : MAR ← PC
T1 : MBR ← M[MAR], PC ← PC+1
T2 : IR ← MBR
```"
101,Computer Architecture,중앙처리장치(CPU) 작동 원리,인출 사이클 - 명령어 실행,"> ADD addr 명령어 연산

```
T0 : MAR ← IR(Addr)
T1 : MBR ← M[MAR]
T2 : AC ← AC + MBR
```

이미 인출이 진행되고 명령어만 실행하면 되기 때문에 PC를 증가할 필요x

IR에 MBR의 값이 이미 저장된 상태를 의미함

따라서 AC에 MBR을 더해주기만 하면 됨

> LOAD addr 명령어 연산

```
T0 : MAR ← IR(Addr)
T1 : MBR ← M[MAR]
T2 : AC ← MBR
```

기억장치에 있는 데이터를 AC로 이동하는 명령어

> STA addr 명령어 연산

```
T0 : MAR ← IR(Addr)
T1 : MBR ← AC
T2 : M[MAR] ← MBR
```

AC에 있는 데이터를 기억장치로 저장하는 명령어

> JUMP addr 명령어 연산

```
T0 : PC ← IR(Addr)
```

PC값을 IR의 주소값으로 변경하는 분기 명령어"
102,Computer Architecture,캐시 메모리(Cache Memory),캐시 메모리(Cache Memory),"속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 말한다.

<br>

```
ex1) CPU 코어와 메모리 사이의 병목 현상 완화
ex2) 웹 브라우저 캐시 파일은, 하드디스크와 웹페이지 사이의 병목 현상을 완화
```

<br>

CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시 메모리에 저장한 뒤, 다음에 이용할 때 주기억장치가 아닌 캐시 메모리에서 먼저 가져오면서 속도를 향상시킨다.

속도라는 장점을 얻지만, 용량이 적기도 하고 비용이 비싼 점이 있다.

<br>

CPU에는 이러한 캐시 메모리가 2~3개 정도 사용된다. (L1, L2, L3 캐시 메모리라고 부른다)

속도와 크기에 따라 분류한 것으로, 일반적으로 L1 캐시부터 먼저 사용된다. (CPU에서 가장 빠르게 접근하고, 여기서 데이터를 찾지 못하면 L2로 감)

<br>

***듀얼 코어 프로세서의 캐시 메모리*** : 각 코어마다 독립된 L1 캐시 메모리를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 내장됨

만약 L1 캐시가 128kb면, 64/64로 나누어 64kb에 명령어를 처리하기 직전의 명령어를 임시 저장하고, 나머지 64kb에는 실행 후 명령어를 임시저장한다. (명령어 세트로 구성, I-Cache - D-Cache)

- L1 : CPU 내부에 존재
- L2 : CPU와 RAM 사이에 존재
- L3 : 보통 메인보드에 존재한다고 함

> 캐시 메모리 크기가 작은 이유는, SRAM 가격이 매우 비쌈

<br>

***디스크 캐시*** : 주기억장치(RAM)와 보조기억장치(하드디스크) 사이에 존재하는 캐시"
103,Computer Architecture,캐시 메모리(Cache Memory),캐시 메모리 작동 원리,"- ##### 시간 지역성

  for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음

- ##### 공간 지역성

  A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음

> 이처럼 참조 지역성의 원리가 존재한다.

<br>

캐시에 데이터를 저장할 때는, 이러한 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다.

CPU가 요청한 데이터가 캐시에 있으면 'Cache Hit', 없어서 DRAM에서 가져오면 'Cache Miss'

<br>"
104,Computer Architecture,캐시 메모리(Cache Memory),캐시 미스 경우 3가지,"1. ##### Cold miss

   해당 메모리 주소를 처음 불러서 나는 미스

2. ##### Conflict miss

   캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생)

   ```
   항상 핸드폰과 열쇠를 오른쪽 주머니에 넣고 다니는데, 잠깐 친구가 준 물건을 받느라 손에 들고 있던 핸드폰을 가방에 넣었음. 그 이후 핸드폰을 찾으려 오른쪽 주머니에서 찾는데 없는 상황
   ```

3. ##### Capacity miss

   캐시 메모리의 공간이 부족해서 나는 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제)

<br>

캐시 **크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점**이 생김"
105,Computer Architecture,캐시 메모리(Cache Memory),구조 및 작동 방식,"- ##### Direct Mapped Cache
  가장 기본적인 구조로, DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식

  현재 그림에서는 메모리 공간이 32개(00000~11111)이고, 캐시 메모리 공간은 8개(000~111)인 상황

  ex) 00000, 01000, 10000, 11000인 메모리 주소는 000 캐시 메모리 주소에 맵핑

  이때 000이 '인덱스 필드', 인덱스 제외한 앞의 나머지(00, 01, 10, 11)를 '태그 필드'라고 한다.

  이처럼 캐시메모리는 `인덱스 필드 + 태그 필드 + 데이터 필드`로 구성된다.

  간단하고 빠른 장점이 있지만, **Conflict Miss가 발생하는 것이 단점**이다. 위 사진처럼 같은 색깔의 데이터를 동시에 사용해야 할 때 발생한다.

  <br>

- ##### Fully Associative Cache 

  비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식

  저장할 때는 매우 간단하지만, 찾을 때가 문제

  조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색해야 한다. CAM이라는 특수한 메모리 구조를 사용해야하지만 가격이 매우 비싸다.

  <br>

- ##### Set Associative Cache

  Direct + Fully 방식이다. 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장하는 방식이다. Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형이다.

  > 실제로 위 두가지보다 나중에 나온 방식"
106,Computer Architecture,패리티 비트 & 해밍 코드,패리티 비트,"> 정보 전달 과정에서 오류가 생겼는 지 검사하기 위해 추가하는 비트를 말한다.
>
> 전송하고자 하는 데이터의 각 문자에 1비트를 더하여 전송한다.

<br>

**종류** : 짝수, 홀수

전체 비트에서 (짝수, 홀수)에 맞도록 비트를 정하는 것

<br>

***짝수 패리티일 때 7비트 데이터가 1010001라면?***

> 1이 총 3개이므로, 짝수로 맞춰주기 위해 1을 더해야 함
>
> 답 : 11010001 (맨앞이 패리티비트)"
107,Computer Architecture,패리티 비트 & 해밍 코드,해밍 코드,"> 데이터 전송 시 1비트의 에러를 정정할 수 있는 자기 오류정정 코드를 말한다.
>
> 패리티비트를 보고, 1비트에 대한 오류를 정정할 곳을 찾아 수정할 수 있다.
> (패리티 비트는 오류를 검출하기만 할 뿐 수정하지는 않기 때문에 해밍 코드를 활용)"
108,Computer Architecture,명령어 Cycle,명령어 Cycle,"- PC : 다음 실행할 명령어의 주소를 저장
- MAR : 다음에 읽거나 쓸 기억장소의 주소를 지정
- MBR : 기억장치에 저장될 데이터 혹은 기억장치로부터 읽은 데이터를 임시 저장
- IR : 현재 수행 중인 명령어 저장
- ALU : 산술연산과 논리연산 수행"
109,Computer Architecture,명령어 Cycle,Fetch Cycle,"> 명령어를 주기억장치에서 CPU 명령어 레지스터로 가져와 해독하는 단계

1) PC에 있는 명령어 주소를 MAR로 가져옴 (그 이후 PC는 +1)

2) MAR에 저장된 주소에 해당하는 값을 메모리에서 가져와서 MBR에 저장

(이때 가져온 값은 Data 또는 Opcode(명령어))

3) 만약 Opcode를 가져왔다면, IR에서 Decode하는 단계 거침 (명령어를 해석하여 Data로 만들어야 함)

4) 1~2과정에서 가져온 데이터를 ALU에서 수행 (Excute Cycle). 연산 결과는 MBR을 거쳐 메모리로 다시 저장"
110,Computer Architecture,고정 소수점 & 부동 소수점,고정 소수점(Fixed Point),"   > 소수점이 찍힐 위치를 미리 정해놓고 소수를 표현하는 방식 (정수 + 소수)
   >
   > ```
   > -3.141592는 부호(-)와 정수부(3), 소수부(0.141592) 3가지 요소 필요함
   > ```
   **장점** : 실수를 정수부와 소수부로 표현하여 단순하다.

   **단점** : 표현의 범위가 너무 적어서 활용하기 힘들다. (정수부는 15bit, 소수부는 16bit)"
111,Computer Architecture,고정 소수점 & 부동 소수점,부동 소수점(Floating Point),"   > 실수를 가수부 + 지수부로 표현한다.
   >
   > - 가수 : 실수의 실제값 표현
   > - 지수 : 크기를 표현함. 가수의 어디쯤에 소수점이 있는지 나타냄

   **지수의 값에 따라 소수점이 움직이는 방식**을 활용한 실수 표현 방법이다.

   즉, 소수점의 위치가 고정되어 있지 않는다.

   **장점** : 표현할 수 있는 수의 범위가 넓어진다. (현재 대부분 시스템에서 활용 중)

   **단점** :  오차가 발생할 수 있다. (부동소수점으로 표현할 수 있는 방법이 매우 다양함)"
112,Computer Architecture,고정 소수점 & 부동 소수점,고정 소수점과 부동 소수점의 일반적인 사용 사례.,"**고정 소수점 사용 상황.**
1. 임베디드 시스켐과 마이크로컨트롤러
    - 메모리와 처리 능력이 제한된 환경에서 고정 소수점 연산이 일반적입니다. 이는 부동 소수점 연산을 지원하는 하드웨어가 없거나, 그러한 연산이 배터리 수명이나 다른 자원을 과도하게 소모할 수 있기 때문입니다.

2. 실시간 시스템
    - 예측 가능한 실행 시간이 중요한 실시간 응용 프로그램에서는 고정 소수점 연산이 선호됩니다. 이는 부동 소수점 연산이 가변적인 실행 시간을 가질 수 있기 때문입니다.

3. 비용 민감형 하드웨어
    - 부동 소수점 연산자를 지원하는 비용이 더 들 수 있어, 가격을 낮추기 위해 고정 소수점 연산을 사용하는 경우가 있습니다.

4. 디지털 신호 처리(DSP)
    - 일부 디지털 신호 처리 알고리즘은 정확하게 정의된 범위 내의 값을 사용하기 때문에 고정 소수점 연산으로 충분한 경우가 많습니다.

**부동 소수점 사용 상황.**
1. 과학적 계산
    - 넓은 범위의 값과 높은 정밀도가 요구되는 과학적 및 엔지니어링 계산에는 부동 소수점이 사용됩니다.

2. 3D 그래픽스
    - 3D 모델링과 같은 그래픽 작업에서는 부동 소수점 연산이 광범위하게 사용되며, 높은 정밀도와 다양한 크기의 값을 처리할 수 있어야 합니다.

3. 금융 분석
    - 복잡한 금융 모델링과 위험 평가에서는 높은 수준의 정밀도가 필요할 수 있으며, 부동 소수점 연산이 적합할 수 있습니다.

4. 컴퓨터 시뮬레이션
    - 물리적 시스템의 시뮬레이션은 넓은 범위의 값과 높은 정밀도를 요구하기 때문에, 부동 소수점 연산이 필수적입니다.

**결론.**
- 고정 소수점은 주로 리소스가 제한적이고 높은 정밀도가 필요하지 않은 환경에서 사용됩니다.
- 부동 소수점은 더 넓은 범위와 높은 정밀도를 필요로 하는 복잡한 계산에 적합합니다.
- 현대 프로세서의 경우, 부동 소수점 연산의 속도도 매우 빨라져서 예전만큼 고정 소수점과 부동 소수점 사이의 성능 차이가 크지 않을 수 있습니다."
113,Computer Architecture,ARM 프로세서,ARM 프로세서,"*프로세서란?*

> 메모리에 저장된 명령어들을 실행하는 유한 상태 오토마톤

즉, `진보된 RISC 기기`의 약자로 ARM의 핵심은 RISC이다.

RISC : Reduced Instruction Set Computing (감소된 명령 집합 컴퓨팅)

`단순한 명령 집합을 가진 프로세서`가 `복잡한 명령 집합을 가진 프로세서`보다 훨씬 더 효율적이지 않을까?로 탄생함"
114,Computer Architecture,ARM 프로세서,ARM 구조,"ARM은 칩의 기본 설계 구조만 만들고, 실제 기능 추가와 최적화 부분은 개별 반도체 제조사의 영역으로 맡긴다. 따라서 물리적 설계는 같아도, 명령 집합이 모두 다르기 때문에 서로 다른 칩이 되기도 하는 것이 ARM.

소비자에게는 칩이 논리적 구조인 명령 집합으로 구성되면서, 이런 특성 때문에 물리적 설계 베이스는 같지만 용도에 따라 다양한 제품군을 만날 수 있는 특징이 있다.

아무래도 아키텍처는 논리적인 명령 집합을 물리적으로 표현한 것이므로, 명령어가 많고 복잡해질수록 실제 물리적인 칩 구조도 크고 복잡해진다.

하지만, ARM은 RISC 설계 기반으로 '단순한 명령집합을 가진 프로세서가 복잡한 것보다 효율적'임을 기반하기 때문에 명령 집합과 구조 자체가 단순하다. 따라서 ARM 기반 프로세서가 더 작고, 효율적이며 상대적으로 느린 것이다.

<br>

단순한 명령 집합은, 적은 수의 트랜지스터만 필요하므로 간결한 설계와 더 작은 크기를 가능케 한다. 반도체 기본 부품인 트랜지스터는 전원을 소비해 다이의 크기를 증가시키기 때문에 스마트폰이나 태블릿PC를 위한 프로세서에는 가능한 적은 트랜지스터를 가진 것이 이상적이다.

따라서, 명령 집합의 수가 적기 때문에 트랜지스터 수가 적고 이를 통해 크기가 작고 전원 소모가 낮은 ARM CPU가 스마트폰, 태블릿PC와 같은 모바일 기기에 많이 사용되고 있다."
115,Computer Architecture,ARM 프로세서,ARM의 장점은?,"소비자에 있어 ARM은 '생태계'의 하나라고 생각할 수 있다. ARM을 위해 개발된 프로그램은 오직 ARM 프로세서가 탑재된 기기에서만 실행할 수 있다. (즉, x86 CPU 프로세서 기반 프로그램에서는 ARM 기반 기기에서 실행할 수 없음)

따라서 ARM에서 실행되던 프로그램을 x86 프로세서에서 실행되도록 하려면 (혹은 그 반대로) 프로그램에 수정이 가해져야만 한다.

 <br>

하지만, 하나의 ARM 기기에 동작하는 OS는 다른 ARM 기반 기기에서도 잘 동작한다. 이러한 장점 덕분에 수많은 버전의 안드로이드가 탄생하고 있으며 또한 HP나 블랙베리의 태블릿에도 안드로이드가 탑재될 수 있는 가능성이 생기게 된 것이다.

(하지만 애플사는 iOS 소스코드를 공개하지 않고 있기 때문에 애플 기기는 불가능하다)

ARM을 만드는 기업들은 전력 소모를 줄이고 성능을 높이기 위해 설계를 개선하며 노력하고 있다."
116,Data Structure,Array vs ArrayList vs LinkedList,Array vs ArrayList vs LinkedList,"세 자료구조를 한 문장으로 정의하면 아래와 같이 말할 수 있다.
<br>

- **Array**는 index로 빠르게 값을 찾는 것이 가능함
- **LinkedList**는 데이터의 삽입 및 삭제가 빠름
- **ArrayList**는 데이터를 찾는데 빠르지만, 삽입 및 삭제가 느림

<br>

좀 더 자세히 비교하면?

<br>

우선 배열(Array)는 **선언할 때 크기와 데이터 타입을 지정**해야 한다.

```java
int arr[10];
String arr[5];
```

이처럼, **array**은 메모리 공간에 할당할 사이즈를 미리 정해놓고 사용하는 자료구조다.

따라서 계속 데이터가 늘어날 때, 최대 사이즈를 알 수 없을 때는 사용하기에 부적합하다.

또한 중간에 데이터를 삽입하거나 삭제할 때도 매우 비효율적이다.

4번째 index 값에 새로운 값을 넣어야 한다면? 원래값을 뒤로 밀어내고 해당 index에 덮어씌워야 한다. 기본적으로 사이즈를 정해놓은 배열에서는 해결하기엔 부적합한 점이 많다.

대신, 배열을 사용하면 index가 존재하기 때문에 위치를 바로 알 수 있어 검색에 편한 장점이 있다.

<br>

이를 해결하기 위해 나온 것이 **List**다.

List는 array처럼 **크기를 정해주지 않아도 된다**. 대신 array에서 index가 중요했다면, List에서는 순서가 중요하다.

크기가 정해져있지 않기 때문에, 중간에 데이터를 추가하거나 삭제하더라도 array에서 갖고 있던 문제점을 해결 가능하다. index를 가지고 있으므로 검색도 빠르다.

하지만, 중간에 데이터를 추가 및 삭제할 때 시간이 오래걸리는 단점이 존재한다. (더하거나 뺄때마다 줄줄이 당겨지거나 밀려날 때 진행되는 연산이 추가, 메모리도 낭비..)

<br>

그렇다면 **LinkedList**는?

연결리스트에는 단일, 다중 등 여러가지가 존재한다.

종류가 무엇이든, **한 노드에 연결될 노드의 포인터 위치를 가리키는 방식**으로 되어있다.

> 단일은 뒤에 노드만 가리키고, 다중은 앞뒤 노드를 모두 가리키는 차이

<br>

이런 방식을 활용하면서, 데이터의 중간에 삽입 및 삭제를 하더라도 전체를 돌지 않아도 이전 값과 다음값이 가르켰던 주소값만 수정하여 연결시켜주면 되기 때문에 빠르게 진행할 수 있다.

이렇게만 보면 가장 좋은 방법 같아보이지만, `List의 k번째 값을 찾아라`에서는 비효율적이다.

<br>

array나 arrayList에서 index를 갖고 있기 때문에 검색이 빠르지만, LinkedList는 처음부터 살펴봐야하므로(순차) 검색에 있어서는 시간이 더 걸린다는 단점이 존재한다. 

<br>

따라서 상황에 맞게 자료구조를 잘 선택해서 사용하는 것이 중요하다."
117,Data Structure,B Tree & B+ Tree,B Tree,"데이터베이스, 파일 시스템에서 널리 사용되는 트리 자료구조의 일종이다.

이진 트리를 확장해서, 더 많은 수의 자식을 가질 수 있게 일반화 시킨 것이 B-Tree

<br>

자식 수에 대한 일반화를 진행하면서, 하나의 레벨에 더 저장되는 것 뿐만 아니라 트리의 균형을 자동으로 맞춰주는 로직까지 갖추었다. 단순하고 효율적이며, 레벨로만 따지면 완전히 균형을 맞춘 트리다.

```
대량의 데이터를 처리해야 할 때, 검색 구조의 경우 하나의 노드에 많은 데이터를 가질 수 있다는 점은 상당히 큰 장점이다.

대량의 데이터는 메모리보다 블럭 단위로 입출력하는 하드디스크 or SSD에 저장해야하기 때문!

ex) 한 블럭이 1024 바이트면, 2바이트를 읽으나 1024바이트를 읽으나 똑같은 입출력 비용 발생. 따라서 하나의 노드를 모두 1024바이트로 꽉 채워서 조절할 수 있으면 입출력에 있어서 효율적인 구성을 갖출 수 있다.

→ B-Tree는 이러한 장점을 토대로 많은 데이터베이스 시스템의 인덱스 저장 방법으로 애용하고 있음
```

<br>

##### 규칙

- 노드의 자료수가 N이면, 자식 수는 N+1이어야 함
- 각 노드의 자료는 정렬된 상태여야함
- 루트 노드는 적어도 2개 이상의 자식을 가져야함
- 루트 노드를 제외한 모든 노드는 적어도 M/2개의 자료를 가지고 있어야함
- 외부 노드로 가는 경로의 길이는 모두 같음.
- 입력 자료는 중복 될 수 없음"
118,Data Structure,B Tree & B+ Tree,B+ Tree,"데이터의 빠른 접근을 위한 인덱스 역할만 하는 비단말 노드(not Leaf)가 추가로 있음

(기존의 B-Tree와 데이터의 연결리스트로 구현된 색인구조)

<br>

B-Tree의 변형 구조로, index 부분과 leaf 노드로 구성된 순차 데이터 부분으로 이루어진다. 인덱스 부분의 key 값은 leaf에 있는 key 값을 직접 찾아가는데 사용함.

<br>

##### 장점

> 블럭 사이즈를 더 많이 이용할 수 있음 (key 값에 대한 하드디스크 액세스 주소가 없기 때문)
>
> leaf 노드끼리 연결 리스트로 연결되어 있어서 범위 탐색에 매우 유리함

##### 단점

> B-tree의 경우 최상 케이스에서는 루트에서 끝날 수 있지만, B+tree는 무조건 leaf 노드까지 내려가봐야 함"
119,Data Structure,B Tree & B+ Tree,B-Tree & B+ Tree,"> B-tree는 각 노드에 데이터가 저장됨
>
> B+tree는 index 노드와 leaf 노드로 분리되어 저장됨
>
> (또한, leaf 노드는 서로 연결되어 있어서 임의접근이나 순차접근 모두 성능이 우수함)

<br>

B-tree는 각 노드에서 key와 data 모두 들어갈 수 있고, data는 disk block으로 포인터가 될 수 있음

B+tree는 각 노드에서 key만 들어감. 따라서 data는 모두 leaf 노드에만 존재

B+tree는 add와 delete가 모두 leaf 노드에서만 이루어짐"
120,Data Structure,이진탐색트리 (Binary Search Tree),이진탐색트리 (Binary Search Tree),"***이진탐색트리의 목적은?***

> 이진탐색 + 연결리스트

이진탐색 : **탐색에 소요되는 시간복잡도는 O(logN)**, but 삽입,삭제가 불가능

연결리스트 : **삽입, 삭제의 시간복잡도는 O(1)**, but 탐색하는 시간복잡도가 O(N)

이 두가지를 합하여 장점을 모두 얻는 것이 **'이진탐색트리'**

즉, 효율적인 탐색 능력을 가지고, 자료의 삽입 삭제도 가능하게 만들자
#### 특징

- 각 노드의 자식이 2개 이하
- 각 노드의 왼쪽 자식은 부모보다 작고, 오른쪽 자식은 부모보다 큼
- 중복된 노드가 없어야 함

***중복이 없어야 하는 이유는?***

검색 목적 자료구조인데, 굳이 중복이 많은 경우에 트리를 사용하여 검색 속도를 느리게 할 필요가 없음. (트리에 삽입하는 것보다, 노드에 count 값을 가지게 하여 처리하는 것이 훨씬 효율적)

<br>

이진탐색트리의 순회는 **'중위순회(inorder)' 방식 (왼쪽 - 루트 - 오른쪽)**

중위 순회로 **정렬된 순서**를 읽을 수 있음

<br>

#### BST 핵심연산

- 검색
- 삽입
- 삭제
- 트리 생성
- 트리 삭제

<br>

#### 시간 복잡도

- 균등 트리 : 노드 개수가 N개일 때 O(logN)
- 편향 트리 : 노드 개수가 N개일 때 O(N)

> 삽입, 검색, 삭제 시간복잡도는 **트리의 Depth**에 비례

<br>

#### 삭제의 3가지 Case

1) 자식이 없는 leaf 노드일 때 → 그냥 삭제

2) 자식이 1개인 노드일 때 → 지워진 노드에 자식을 올리기

3) 자식이 2개인 노드일 때 → 오른쪽 자식 노드에서 가장 작은 값 or 왼쪽 자식 노드에서 가장 큰 값 올리기

<br>

편향된 트리(정렬된 상태 값을 트리로 만들면 한쪽으로만 뻗음)는 시간복잡도가 O(N)이므로 트리를 사용할 이유가 사라짐 → 이를 바로 잡도록 도와주는 개선된 트리가 AVL Tree, RedBlack Tree"
121,Data Structure,해시(Hash),해시(Hash),"데이터를 효율적으로 관리하기 위해, 임의의 길이 데이터를 고정된 길이의 데이터로 매핑하는 것

해시 함수를 구현하여 데이터 값을 해시 값으로 매핑한다.

<br>

```
Lee → 해싱함수 → 5
Kim → 해싱함수 → 3
Park → 해싱함수 → 2
...
Chun → 해싱함수 → 5 // Lee와 해싱값 충돌
```

결국 데이터가 많아지면, 다른 데이터가 같은 해시 값으로 충돌나는 현상이 발생함 **'collision' 현상**

**_그래도 해시 테이블을 쓰는 이유는?_**

> 적은 자원으로 많은 데이터를 효율적으로 관리하기 위해
>
> 하드디스크나, 클라우드에 존재하는 무한한 데이터들을 유한한 개수의 해시값으로 매핑하면 작은 메모리로도 프로세스 관리가 가능해짐!

- 언제나 동일한 해시값 리턴, index를 알면 빠른 데이터 검색이 가능해짐
- 해시테이블의 시간복잡도 O(1) - (이진탐색트리는 O(logN))

<br>

##### 충돌 문제 해결

1. **체이닝** : 연결리스트로 노드를 계속 추가해나가는 방식
   (제한 없이 계속 연결 가능, but 메모리 문제)

2. **Open Addressing** : 해시 함수로 얻은 주소가 아닌 다른 주소에 데이터를 저장할 수 있도록 허용 (해당 키 값에 저장되어있으면 다음 주소에 저장)

3. **선형 탐사** : 정해진 고정 폭으로 옮겨 해시값의 중복을 피함
4. **제곱 탐사** : 정해진 고정 폭을 제곱수로 옮겨 해시값의 중복을 피함

<br>

## 해시 버킷 동적 확장

해시 버킷의 크기가 충분히 크다면 해시 충돌 빈도를 낮출 수 있다

하지만 메모리는 한정된 자원이기 때문에 무작정 큰 공간을 할당해 줄 수 없다

때문에 `load factor`가 일정 수준 이상 이라면 (보편적으로는 0.7 ~ 0.8) 해시 버킷의 크기를 확장하는 동적 확장 방식을 사용한다

- **load factor** : 할당된 키의 개수 / 해시 버킷의 크기

해시 버킷이 동적 확장 될 때 `리해싱` 과정을 거치게 된다

- **리해싱(Rehashing)** : 기존 저장되어 있는 값들을 다시 해싱하여 새로운 키를 부여하는 것을 말한다"
122,Data Structure,힙(Heap),힙(Heap),"##### 알아야할 것

> 1.힙의 개념
>
> 2.힙의 삽입 및 삭제

<br>

힙은, 우선순위 큐를 위해 만들어진 자료구조다.

먼저 **우선순위 큐**에 대해서 간략히 알아보자 

<br>

**우선순위 큐** : 우선순위의 개념을 큐에 도입한 자료구조

> 데이터들이 우선순위를 가지고 있음. 우선순위가 높은 데이터가 먼저 나감

스택은 LIFO, 큐는 FIFO

<br>

##### 언제 사용?

> 시뮬레이션 시스템, 작업 스케줄링, 수치해석 계산

우선순위 큐는 배열, 연결리스트, 힙으로 구현 (힙으로 구현이 가장 효율적!)

힙 → 삽입 : O(logn) , 삭제 : O(logn)

<br>

<br>

### 힙(Heap)

---

완전 이진 트리의 일종

> 여러 값 중, 최대값과 최소값을 빠르게 찾아내도록 만들어진 자료구조

반정렬 상태

힙 트리는 중복된 값 허용 (이진 탐색 트리는 중복값 허용X)

<br>

#### 힙 종류

###### 최대 힙(max heap)

  부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리

###### 최소 힙(min heap)

  부모 노드의 키 값이 자식 노드의 키 값보다 작거나 같은 완전 이진 트리

 <img src=""https://t1.daumcdn.net/cfile/tistory/17084F504DA9895214"">

<br>

#### 구현

---

힙을 저장하는 표준적인 자료구조는 `배열`

구현을 쉽게 하기 위해 배열의 첫번째 인덱스인 0은 사용되지 않음

특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않음

(ex. 루트 노드(1)의 오른쪽 노드 번호는 항상 3)

 <br>

##### 부모 노드와 자식 노드 관계

```
왼쪽 자식 index = (부모 index) * 2

오른쪽 자식 index = (부모 index) * 2 + 1

부모 index = (자식 index) / 2
```

<br>

#### 힙의 삽입

1.힙에 새로운 요소가 들어오면, 일단 새로운 노드를 힙의 마지막 노드에 삽입

2.새로운 노드를 부모 노드들과 교환

<br>

###### 최대 힙 삽입 구현

```java
void insert_max_heap(int x) {
    
    maxHeap[++heapSize] = x; 
    // 힙 크기를 하나 증가하고, 마지막 노드에 x를 넣음
    
    for( int i = heapSize; i > 1; i /= 2) {
        
        // 마지막 노드가 자신의 부모 노드보다 크면 swap
        if(maxHeap[i/2] < maxHeap[i]) {
            swap(i/2, i);
        } else {
            break;
        }
        
    }
}
```

부모 노드는 자신의 인덱스의 /2 이므로, 비교하고 자신이 더 크면 swap하는 방식

<br>

#### 힙의 삭제

1.최대 힙에서 최대값은 루트 노드이므로 루트 노드가 삭제됨
(최대 힙에서 삭제 연산은 최대값 요소를 삭제하는 것)

2.삭제된 루트 노드에는 힙의 마지막 노드를 가져옴

3.힙을 재구성

<br>

###### 최대 힙 삭제 구현

```java
int delete_max_heap() {
    
    if(heapSize == 0) // 배열이 비어있으면 리턴
        return 0;
    
    int item = maxHeap[1]; // 루트 노드의 값을 저장
    maxHeap[1] = maxHeap[heapSize]; // 마지막 노드 값을 루트로 이동
    maxHeap[heapSize--] = 0; // 힙 크기를 하나 줄이고 마지막 노드 0 초기화
    
    for(int i = 1; i*2 <= heapSize;) {
        
        // 마지막 노드가 왼쪽 노드와 오른쪽 노드보다 크면 끝
        if(maxHeap[i] > maxHeap[i*2] && maxHeap[i] > maxHeap[i*2+1]) {
            break;
        }
        
        // 왼쪽 노드가 더 큰 경우, swap
        else if (maxHeap[i*2] > maxHeap[i*2+1]) {
            swap(i, i*2);
            i = i*2;
        }
        
        // 오른쪽 노드가 더 큰 경우
        else {
            swap(i, i*2+1);
            i = i*2+1;
        }
    }
    
    return item;
    
}
```"
123,Data Structure,Linked List,Linked List,"연속적인 메모리 위치에 저장되지 않는 선형 데이터 구조

(포인터를 사용해서 연결된다)

각 노드는 **데이터 필드**와 **다음 노드에 대한 참조**를 포함하는 노드로 구성

<br/>

**왜 Linked List를 사용하나?**

> 배열은 비슷한 유형의 선형 데이터를 저장하는데 사용할 수 있지만 제한 사항이 있음
>
> 1) 배열의 크기가 고정되어 있어 미리 요소의 수에 대해 할당을 받아야 함
>
> 2) 새로운 요소를 삽입하는 것은 비용이 많이 듬 (공간을 만들고, 기존 요소 전부 이동)

**장점**

> 1) 동적 크기
>
> 2) 삽입/삭제 용이

**단점**

> 1) 임의로 액세스를 허용할 수 없음. 즉, 첫 번째 노드부터 순차적으로 요소에 액세스 해야함 (이진 검색 수행 불가능)
>
> 2) 포인터의 여분의 메모리 공간이 목록의 각 요소에 필요



노드 구현은 아래와 같이 데이터와 다음 노드에 대한 참조로 나타낼 수 있다

```
// A linked list node 
struct Node 
{ 
  int data; 
  struct Node *next; 
}; 
```



**Single Linked List**

노드 3개를 잇는 코드를 만들어보자

```
      head         second         third 
        |             |             | 
        |             |             | 
    +---+---+     +---+---+     +----+----+ 
    | 1  | o----->| 2 | o-----> |  3 |  # | 
    +---+---+     +---+---+     +----+----+
```

[소스 코드]()



<br/>

<br/>

**노드 추가**

- 앞쪽에 노드 추가

```
void push(struct Node** head_ref, int new_data){
    struct Node* new_node = (struct Node*) malloc(sizeof(struct Node));

    new_node->data = new_data;

    new_node->next = (*head_ref);

    (*head_ref) = new_node;
}
```

</br>

- 특정 노드 다음에 추가

```
void insertAfter(struct Node* prev_node, int new_data){
    if (prev_node == NULL){
        printf(""이전 노드가 NULL이 아니어야 합니다."");
        return;
    }

    struct Node* new_node = (struct Node*) malloc(sizeof(struct Node));

    new_node->data = new_data;
    new_node->next = prev_node->next;

    prev_node->next = new_node;
    
}
```

</br>

- 끝쪽에 노드 추가

```
void append(struct Node** head_ref, int new_data){
    struct Node* new_node = (struct Node*)malloc(sizeof(struct Node));

    struct Node *last = *head_ref;

    new_node->data = new_data;

    new_node->next = NULL;

    if (*head_ref == NULL){
        *head_ref = new_node;
        return;
    }

    while(last->next != NULL){
        last = last->next;
    }

    last->next = new_node;
    return;

}
```"
124,Data Structure,자료구조,배열(Array),"<u>정적으로 필요한만큼만 원소를 저장</u>할 수 있는 공간이 할당

이때 각 원소의 주소는 연속적으로 할당됨

index를 통해 O(1)에 접근이 가능함

삽입 및 삭제는 O(N)

지정된 개수가 초과되면? → **배열 크기를 재할당한 후 복사**해야함"
125,Data Structure,자료구조,리스트(List),"<u>노드(Node)들의 연결</u>로 이루어짐

크기 제한이 없음 ( heap 용량만 충분하면! )

다음 노드에 대한 **참조를 통해 접근** ( O(N) )

삽입과 삭제가 편함 O(1)"
126,Data Structure,자료구조,ArrayList,"동적으로 크기가 조정되는 배열

배열이 가득 차면? → 알아서 그 크기를 2배로 할당하고 복사 수행

재할당에 걸리는 시간은 O(N)이지만, 자주 일어나는 일이 아니므로 접근시간은 O(1)"
127,Data Structure,자료구조,스택(Stack),"LIFO 방식 (나중에 들어온게 먼저 나감)

원소의 삽입 및 삭제가 한쪽 끝에서만 이루어짐 (이 부분을 top이라고 칭함)

함수 호출 시 지역변수, 매개변수 정보를 저장하기 위한 공간을 스택으로 사용함"
128,Data Structure,자료구조,큐(Queue),"FIFO 방식 (먼저 들어온게 먼저 나감)

원소의 삽입 및 삭제가 양쪽 끝에서 일어남 (front, rear)

FIFO 운영체제, 은행 대기열 등에 해당"
129,Data Structure,자료구조,우선순위 큐(Priority Queue),"FIFO 방식이 아닌 <u>데이터를 근거로 한 우선순위를 판단하고, 우선순위가 높은 것부터</u> 나감

구현 방법 3가지 (배열, 연결리스트, 힙)

##### 1.배열

간단하게 구현이 가능

데이터 삽입 및 삭제 과정을 진행 시, O(N)으로 비효율 발생 (**한 칸씩 당기거나 밀어야하기 때문**)

삽입 위치를 찾기 위해 배열의 모든 데이터를 탐색해야 함 (우선순위가 가장 낮을 경우)

##### 2.연결리스트

삽입 및 삭제 O(1)

하지만 삽입 위치를 찾을 때는 배열과 마찬가지로 비효율 발생

##### 3.힙

힙은 위 2가지를 모두 효율적으로 처리가 가능함 (따라서 우선순위 큐는 대부분 힙으로 구현)

힙은 **완전이진트리의 성질을 만족하므로, 1차원 배열로 표현이 가능**함 ( O(1)에 접근이 가능 )

root index에 따라 child index를 계산할 수 있음

```
root index = 0

left index = index * 2 + 1
right index = index * 2 + 2
```

**데이터의 삽입**은 트리의 leaf node(자식이 없는 노드)부터 시작

삽입 후, heapify 과정을 통해 힙의 모든 부모-자식 노드의 우선순위에 맞게 설정됨
(이때, 부모의 우선순위는 자식의 우선순위보다 커야 함)

**데이터의 삭제**는 root node를 삭제함 (우선순위가 가장 큰 것)

삭제 후, 마지막 leaf node를 root node로 옮긴 뒤 heapify 과정 수행"
130,Data Structure,자료구조,트리(Tree),"사이클이 없는 무방향 그래프

완전이진트리 기준 높이는 logN

트리를 순회하는 방법은 여러가지가 있음

1.**중위 순회** : left-root-right

2.**전위 순회** : root-left-right

3.**후위 순회** : left-right-root

4.**레벨 순서 순회** : 노드를 레벨 순서로 방문 (BFS와 동일해 큐로 구현 가능)"
131,Data Structure,자료구조,이진탐색트리(BST),"노드의 왼쪽은 노드의 값보다 작은 값들, 오른쪽은 노드의 값보다 큰 값으로 구성

삽입 및 삭제, 탐색까지 이상적일 때는 모두 O(logN) 가능

만약 편향된 트리면 O(N)으로 최악의 경우가 발생"
132,Data Structure,자료구조,해시 테이블(Hash Table),"효율적 탐색을 위한 자료구조

key - value 쌍으로 이루어짐

해시 함수를 통해 입력받은 key를 정수값(index)로 대응시킴

충돌(collision)에 대한 고려 필요"
133,Data Structure,자료구조,충돌(collision) 해결방안,"해시 테이블에서 중복된 값에 대한 충돌 가능성이 있기 때문에 해결방안을 세워야 함

##### 1.선형 조사법(linear probing)

충돌이 일어난 항목을 해시 테이블의 다른 위치에 저장

```
예시)
ht[k], ht[k+1], ht[k+2] ...

※ 삽입 상황
충돌이 ht[k]에서 일어났다면, ht[k+1]이 비어있는지 조사함. 차있으면 ht[k+2] 조사 ...
테이블 끝까지 도달하면 다시 처음으로 돌아옴. 시작 위치로 돌아온 경우는 테이블이 모두 가득 찬 경우임

※ 검색 상황
ht[k]에 있는 키가 다른 값이면, ht[k+1]에 같은 키가 있는지 조사함. 
비어있는 공간이 나오거나, 검색을 시작한 위치로 돌아오면 찾는 키가 없는 경우
```

##### 2.이차 조사법

선형 조사법에서 발생하는 **집적화 문제를 완화**시켜 줌

```
h(k), h(k)+1, h(k)+4, h(k)+9 ...
```

##### 3.이중 해시법

재해싱(rehasing)이라고도 함

충돌로 인해 비어있는 버킷을 찾을 때 추가적인 해시 함수 h'()를 사용하는 방식

```
h'(k) = C - (k mod C)

조사 위치
h(k), h(k)+h'(k), h(k) + 2h'(k) ...
```

##### 4.체이닝

각 버킷을 고정된 개수의 슬롯 대신, 유동적 크기를 갖는 **연결리스트로 구성**하는 방식

충돌 뿐만 아니라 오버플로우 문제도 해결 가능

버킷 내에서 항목을 찾을 때는 연결리스트 순차 탐색 활용

##### 5.해싱 성능 분석

```
a = n / M

a = 적재 비율
n = 저장되는 항목 개수
M = 해시테이블 크기
```"
134,Data Structure,자료구조,맵(map)과 해시맵(hashMap)의 차이는?,"map 컨테이너는 이진탐색트리(BST)를 사용하다가 최근에 레드블랙트리를 사용하는 중

key 값을 이용해 트리를 탐색하는 방식임 → 따라서 데이터 접근, 삽입, 삭제는 O( logN )

반면 해시맵은 해시함수를 활용해 O(1)에 접근 가능

하지만 C++에서는 해시맵을 STL로 지원해주지 않는데, 충돌 해결에 있어서 안정적인 방법이 아니기 때문 (해시 함수는 collision 정책에 따라 성능차이가 큼)"
135,Data Structure,Stack & Queue,스택(Stack),"입력과 출력이 한 곳(방향)으로 제한

##### LIFO (Last In First Out, 후입선출) : 가장 나중에 들어온 것이 가장 먼저 나옴

<br>

***언제 사용?***

함수의 콜스택, 문자열 역순 출력, 연산자 후위표기법

<br>

데이터 넣음 : push() 

데이터 최상위 값 뺌 : pop()

비어있는 지 확인 : isEmpty()

꽉차있는 지 확인 : isFull()

+SP

<br>

push와 pop할 때는 해당 위치를 알고 있어야 하므로 기억하고 있는 '스택 포인터(SP)'가 필요함

스택 포인터는 다음 값이 들어갈 위치를 가리키고 있음 (처음 기본값은 -1)

```java
private int sp = -1;
```

<br>

##### push

```java
public void push(Object o) {
    if(isFull(o)) {
        return;
    }
    
    stack[++sp] = o;
}
```

스택 포인터가 최대 크기와 같으면 return

아니면 스택의 최상위 위치에 값을 넣음

<br>

##### pop

```java
public Object pop() {
    
    if(isEmpty(sp)) {
        return null;
    }
    
    Object o = stack[sp--];
    return o;
    
}
```

스택 포인터가 0이 되면 null로 return;

아니면 스택의 최상위 위치 값을 꺼내옴

<br>

##### isEmpty

```java
private boolean isEmpty(int cnt) {
    return sp == -1 ? true : false;
}
```

입력 값이 최초 값과 같다면 true, 아니면 false

<br>

##### isFull

```java
private boolean isFull(int cnt) {
    return sp + 1 == MAX_SIZE ? true : false;
}
```

스택 포인터 값+1이 MAX_SIZE와 같으면 true, 아니면 false

<br>

<br>

#### 동적 배열 스택

위처럼 구현하면 스택에는 MAX_SIZE라는 최대 크기가 존재해야 한다

(스택 포인터와 MAX_SIZE를 비교해서 isFull 메소드로 비교해야되기 때문!)

<br>

최대 크기가 없는 스택을 만드려면?

> arraycopy를 활용한 동적배열 사용

<br>

```java
public void push(Object o) {
    
    if(isFull(sp)) {
        
        Object[] arr = new Object[MAX_SIZE * 2];
        System.arraycopy(stack, 0, arr, 0, MAX_SIZE);
        stack = arr;
        MAX_SIZE *= 2; // 2배로 증가
    }
    
    stack[sp++] = o;
}
```

기존 스택의 2배 크기만큼 임시 배열(arr)을 만들고

arraycopy를 통해 stack의 인덱스 0부터 MAX_SIZE만큼을 arr 배열의 0번째부터 복사한다

복사 후에 arr의 참조값을 stack에 덮어씌운다

마지막으로 MAX_SIZE의 값을 2배로 증가시켜주면 된다.

<br>

이러면, 스택이 가득찼을 때 자동으로 확장되는 스택을 구현할 수 있음

<br>

#### 스택을 연결리스트로 구현해도 해결 가능

```java
public class Node {

    public int data;
    public Node next;

    public Node() {
    }

    public Node(int data) {
        this.data = data;
        this.next = null;
    }
}
```

```java
public class Stack {
    private Node head;
    private Node top;

    public Stack() {
        head = top = null;
    }

    private Node createNode(int data) {
        return new Node(data);
    }

    private boolean isEmpty() {
        return top == null ? true : false;
    }

    public void push(int data) {
        if (isEmpty()) { // 스택이 비어있다면
            head = createNode(data);
            top = head;
        }
        else { //스택이 비어있지 않다면 마지막 위치를 찾아 새 노드를 연결시킨다.
            Node pointer = head;

            while (pointer.next != null)
                pointer = pointer.next;

            pointer.next = createNode(data);
            top = pointer.next;
        }
    }

    public int pop() {
        int popData;
        if (!isEmpty()) { // 스택이 비어있지 않다면!! => 데이터가 있다면!!
            popData = top.data; // pop될 데이터를 미리 받아놓는다.
            Node pointer = head; // 현재 위치를 확인할 임시 노드 포인터

            if (head == top) // 데이터가 하나라면
                head = top = null;
            else { // 데이터가 2개 이상이라면
                while (pointer.next != top) // top을 가리키는 노드를 찾는다.
                    pointer = pointer.next;

                pointer.next = null; // 마지막 노드의 연결을 끊는다.
                top = pointer; // top을 이동시킨다.
            }
            return popData;
        }
        return -1; // -1은 데이터가 없다는 의미로 지정해둠.

    }

}
```"
136,Data Structure,Stack & Queue,큐(Queue),"입력과 출력을 한 쪽 끝(front, rear)으로 제한

##### FIFO (First In First Out, 선입선출) : 가장 먼저 들어온 것이 가장 먼저 나옴

<br>

***언제 사용?***

버퍼, 마구 입력된 것을 처리하지 못하고 있는 상황, BFS

<br>

큐의 가장 첫 원소를 front, 끝 원소를 rear라고 부름

큐는 **들어올 때 rear로 들어오지만, 나올 때는 front부터 빠지는 특성**을 가짐

접근방법은 가장 첫 원소와 끝 원소로만 가능

<br>

데이터 넣음 : enQueue()

데이터 뺌 : deQueue()

비어있는 지 확인 : isEmpty()

꽉차있는 지 확인 : isFull()

<br>

데이터를 넣고 뺄 때 해당 값의 위치를 기억해야 함. (스택에서 스택 포인터와 같은 역할)

이 위치를 기억하고 있는 게 front와 rear

front : deQueue 할 위치 기억

rear : enQueue 할 위치 기억

<br>

##### 기본값

```java
private int size = 0; 
private int rear = -1; 
private int front = -1;

Queue(int size) { 
    this.size = size;
    this.queue = new Object[size];
}
```

<br>

<br>

##### enQueue

```java
public void enQueue(Object o) {
    
    if(isFull()) {
        return;
    }
    
    queue[++rear] = o;
}
```

enQueue 시, 가득 찼다면 꽉 차 있는 상태에서 enQueue를 했기 때문에 overflow

아니면 rear에 값 넣고 1 증가

<br>

<br>

##### deQueue

```java
public Object deQueue(Object o) {
    
    if(isEmpty()) { 
        return null;
    }
    
    Object o = queue[front];
    queue[front++] = null;
    return o;
}
```

deQueue를 할 때 공백이면 underflow

front에 위치한 값을 object에 꺼낸 후, 꺼낸 위치는 null로 채워줌

<br>

#####  isEmpty

```java
public boolean isEmpty() {
    return front == rear;
}
```

front와 rear가 같아지면 비어진 것

<br>

##### isFull

```java
public boolean isFull() {
    return (rear == queueSize-1);
}
```

rear가 사이즈-1과 같아지면 가득찬 것

<br>

---

일반 큐의 단점 : 큐에 빈 메모리가 남아 있어도, 꽉 차있는것으로 판단할 수도 있음

(rear가 끝에 도달했을 때)

<br>

이를 개선한 것이 **'원형 큐'**

논리적으로 배열의 처음과 끝이 연결되어 있는 것으로 간주함!

<br>

원형 큐는 초기 공백 상태일 때 front와 rear가 0

공백, 포화 상태를 쉽게 구분하기 위해 **자리 하나를 항상 비워둠**

```
(index + 1) % size로 순환시킨다
```

<br>

##### 기본값

```java
private int size = 0; 
private int rear = 0; 
private int front = 0;

Queue(int size) { 
    this.size = size;
    this.queue = new Object[size];
}
```

<br>

##### enQueue

```java
public void enQueue(Object o) {
    
    if(isFull()) {
        return;
    }
    
    rear = (++rear) % size;
    queue[rear] = o;
}
```

enQueue 시, 가득 찼다면 꽉 차 있는 상태에서 enQueue를 했기 때문에 overflow

<br>

<br>

##### deQueue

```java
public Object deQueue(Object o) {
    
    if(isEmpty()) { 
        return null;
    }
    
    front = (++front) % size;
    Object o = queue[front];
    return o;
}
```

deQueue를 할 때 공백이면 underflow

<br>

#####  isEmpty

```java
public boolean isEmpty() {
    return front == rear;
}
```

front와 rear가 같아지면 비어진 것

<br>

##### isFull

```java
public boolean isFull() {
    return ((rear+1) % size == front);
}
```

rear+1%size가 front와 같으면 가득찬 것

<br>

원형 큐의 단점 : 메모리 공간은 잘 활용하지만, 배열로 구현되어 있기 때문에 큐의 크기가 제한

<br>

<br>

이를 개선한 것이 '연결리스트 큐'

##### 연결리스트 큐는 크기가 제한이 없고 삽입, 삭제가 편리

<br>

##### enqueue 구현

```java
public void enqueue(E item) {
    Node oldlast = tail; // 기존의 tail 임시 저장
    tail = new Node; // 새로운 tail 생성
    tail.item = item;
    tail.next = null;
    if(isEmpty()) head = tail; // 큐가 비어있으면 head와 tail 모두 같은 노드 가리킴
    else oldlast.next = tail; // 비어있지 않으면 기존 tail의 next = 새로운 tail로 설정
}
```

> - 데이터 추가는 끝 부분인 tail에 한다.
>
> - 기존의 tail는 보관하고, 새로운 tail 생성
>
> - 큐가 비었으면 head = tail를 통해 둘이 같은 노드를 가리키도록 한다.
> - 큐가 비어있지 않으면, 기존 tail의 next에 새로만든 tail를 설정해준다.

<br>

##### dequeue 구현

```java
public T dequeue() {
    // 비어있으면
    if(isEmpty()) {
        tail = head;
        return null;
    }
    // 비어있지 않으면
    else {
        T item = head.item; // 빼낼 현재 front 값 저장
        head = head.next; // front를 다음 노드로 설정
        return item;
    }
}
```

> - 데이터는 head로부터 꺼낸다. (가장 먼저 들어온 것부터 빼야하므로)
> - head의 데이터를 미리 저장해둔다.
> - 기존의 head를 그 다음 노드의 head로 설정한다.
> - 저장해둔 데이터를 return 해서 값을 빼온다."
137,Database,Redis,Redis,"> 빠른 오픈 소스 인 메모리 키 값 데이터 구조 스토어

보통 데이터베이스는 하드 디스크나 SSD에 저장한다. 하지만 Redis는 메모리(RAM)에 저장해서 디스크 스캐닝이 필요없어 매우 빠른 장점이 존재함

캐싱도 가능해 실시간 채팅에 적합하며 세션 공유를 위해 세션 클러스터링에도 활용된다.`

***RAM은 휘발성 아닌가요? 껐다키면 다 날아가는데..***

이를 막기위한 백업 과정이 존재한다.

- snapshot : 특정 지점을 설정하고 디스크에 백업
- AOF(Append Only File) : 명령(쿼리)들을 저장해두고, 서버가 셧다운되면 재실행해서 다시 만들어 놓는 것

데이터 구조는 key/value 값으로 이루어져 있다. (따라서 Redis는 비정형 데이터를 저장하는 비관계형 데이터베이스 관리 시스템이다)

##### value 5가지

1. String (text, binary data) - 512MB까지 저장이 가능함
2. set (String 집합)
3. sorted set (set을 정렬해둔 상태)
4. Hash
5. List (양방향 연결리스트도 가능"
138,Database,SQL Injection,SQL Injection,"> 해커에 의해 조작된 SQL 쿼리문이 데이터베이스에 그대로 전달되어 비정상적 명령을 실행시키는 공격 기법

<br>

#### 공격 방법

##### 1) 인증 우회

보통 로그인을 할 때, 아이디와 비밀번호를 input 창에 입력하게 된다. 쉽게 이해하기 위해 가벼운 예를 들어보자. 아이디가 abc, 비밀번호가 만약 1234일 때 쿼리는 아래와 같은 방식으로 전송될 것이다.

```
SELECT * FROM USER WHERE ID = ""abc"" AND PASSWORD = ""1234"";
```

SQL Injection으로 공격할 때, input 창에 비밀번호를 입력함과 동시에 다른 쿼리문을 함께 입력하는 것이다.

```
1234; DELETE * USER FROM ID = ""1"";
```

보안이 완벽하지 않은 경우, 이처럼 비밀번호가 아이디와 일치해서 True가 되고 뒤에 작성한 DELETE 문도 데이터베이스에 영향을 줄 수도 있게 되는 치명적인 상황이다.

이 밖에도 기본 쿼리문의 WHERE 절에 OR문을 추가하여 `'1' = '1'`과 같은 true문을 작성하여 무조건 적용되도록 수정한 뒤 DB를 마음대로 조작할 수도 있다. 

<br>

##### 2) 데이터 노출

시스템에서 발생하는 에러 메시지를 이용해 공격하는 방법이다. 보통 에러는 개발자가 버그를 수정하는 면에서 도움을 받을 수 있는 존재다. 해커들은 이를 역이용해 악의적인 구문을 삽입하여 에러를 유발시킨다.

즉 예를 들면, 해커는 **GET 방식으로 동작하는 URL 쿼리 스트링을 추가하여 에러를 발생**시킨다. 이에 해당하는 오류가 발생하면, 이를 통해 해당 웹앱의 데이터베이스 구조를 유추할 수 있고 해킹에 활용한다.

<br>

<br>

#### 방어 방법

##### 1) input 값을 받을 때, 특수문자 여부 검사하기

> 로그인 전, 검증 로직을 추가하여 미리 설정한 특수문자들이 들어왔을 때 요청을 막아낸다.

##### 2) SQL 서버 오류 발생 시, 해당하는 에러 메시지 감추기

> view를 활용하여 원본 데이터베이스 테이블에는 접근 권한을 높인다. 일반 사용자는 view로만 접근하여 에러를 볼 수 없도록 만든다.

##### 3) preparestatement 사용하기

> preparestatement를 사용하면, 특수문자를 자동으로 escaping 해준다. (statement와는 다르게 쿼리문에서 전달인자 값을 `?`로 받는 것) 이를 활용해 서버 측에서 필터링 과정을 통해서 공격을 방어한다."
139,Database,SQL과 NOSQL의 차이,SQL (관계형 DB),"SQL을 사용하면 RDBMS에서 데이터를 저장, 수정, 삭제 및 검색 할 수 있음

관계형 데이터베이스에는 핵심적인 두 가지 특징이 있다.

- 데이터는 **정해진 데이터 스키마에 따라 테이블에 저장**된다.
- 데이터는 **관계를 통해 여러 테이블에 분산**된다.

<br>

데이터는 테이블에 레코드로 저장되는데, 각 테이블마다 명확하게 정의된 구조가 있다.
해당 구조는 필드의 이름과 데이터 유형으로 정의된다.

따라서 **스키마를 준수하지 않은 레코드는 테이블에 추가할 수 없다.** 즉, 스키마를 수정하지 않는 이상은 정해진 구조에 맞는 레코드만 추가가 가능한 것이 관계형 데이터베이스의 특징 중 하나다.

<br>

또한, 데이터의 중복을 피하기 위해 '관계'를 이용한다.

하나의 테이블에서 중복 없이 하나의 데이터만을 관리하기 때문에 다른 테이블에서 부정확한 데이터를 다룰 위험이 없어지는 장점이 있다."
140,Database,SQL과 NOSQL의 차이,NoSQL (비관계형 DB),"말그대로 관계형 DB의 반대다.

**스키마도 없고, 관계도 없다!**

<br>

NoSQL에서는 레코드를 문서(documents)라고 부른다.

여기서 SQL과 핵심적인 차이가 있는데, SQL은 정해진 스키마를 따르지 않으면 데이터 추가가 불가능했다. 하지만 NoSQL에서는 다른 구조의 데이터를 같은 컬렉션에 추가가 가능하다.

<br>

문서(documents)는 Json과 비슷한 형태로 가지고 있다. 관계형 데이터베이스처럼 여러 테이블에 나누어담지 않고, 관련 데이터를 동일한 '컬렉션'에 넣는다.

따라서 위 사진에 SQL에서 진행한 Orders, Users, Products 테이블로 나눈 것을 NoSQL에서는 Orders에 한꺼번에 포함해서 저장하게 된다.

따라서 여러 테이블에 조인할 필요없이 이미 필요한 모든 것을 갖춘 문서를 작성하는 것이 NoSQL이다. (NoSQL에는 조인이라는 개념이 존재하지 않음)

<br>

그러면 조인하고 싶을 때 NoSQL은 어떻게 할까? 

> 컬렉션을 통해 데이터를 복제하여 각 컬렉션 일부분에 속하는 데이터를 정확하게 산출하도록 한다.

하지만 이러면 데이터가 중복되어 서로 영향을 줄 위험이 있다. 따라서 조인을 잘 사용하지 않고 자주 변경되지 않는 데이터일 때 NoSQL을 쓰면 상당히 효율적이다."
141,Database,SQL과 NOSQL의 차이,확장 개념,"두 데이터베이스를 비교할 때 중요한 Scaling 개념도 존재한다.

데이터베이스 서버의 확장성은 '수직적' 확장과 '수평적' 확장으로 나누어진다.

- 수직적 확장 : 단순히 데이터베이스 서버의 성능을 향상시키는 것 (ex. CPU 업그레이드)
- 수평적 확장 : 더 많은 서버가 추가되고 데이터베이스가 전체적으로 분산됨을 의미 (하나의 데이터베이스에서 작동하지만 여러 호스트에서 작동)

<br>

데이터 저장 방식으로 인해 SQL 데이터베이스는 일반적으로 수직적 확장만 지원함

> 수평적 확장은 NoSQL 데이터베이스에서만 가능"
142,Database,SQL과 NOSQL의 차이,장단점,"##### SQL 장점

- 명확하게 정의된 스키마, 데이터 무결성 보장
- 관계는 각 데이터를 중복없이 한번만 저장

##### SQL 단점

- 덜 유연함. 데이터 스키마를 사전에 계획하고 알려야 함. (나중에 수정하기 힘듬)
- 관계를 맺고 있어서 조인문이 많은 복잡한 쿼리가 만들어질 수 있음
- 대체로 수직적 확장만 가능함

<br>

##### NoSQL 장점

- 스키마가 없어서 유연함. 언제든지 저장된 데이터를 조정하고 새로운 필드 추가 가능
- 데이터는 애플리케이션이 필요로 하는 형식으로 저장됨. 데이터 읽어오는 속도 빨라짐
- 수직 및 수평 확장이 가능해서 애플리케이션이 발생시키는 모든 읽기/쓰기 요청 처리 가능

##### NoSQL 단점

- 유연성으로 인해 데이터 구조 결정을 미루게 될 수 있음
- 데이터 중복을 계속 업데이트 해야 함
- 데이터가 여러 컬렉션에 중복되어 있기 때문에 수정 시 모든 컬렉션에서 수행해야 함
  (SQL에서는 중복 데이터가 없으므로 한번만 수행이 가능)

<br>

<br>

#### SQL 데이터베이스 사용이 더 좋을 때

- 관계를 맺고 있는 데이터가 자주 변경되는 애플리케이션의 경우

  > NoSQL에서는 여러 컬렉션을 모두 수정해야 하기 때문에 비효율적

- 변경될 여지가 없고, 명확한 스키마가 사용자와 데이터에게 중요한 경우

<br>

#### NoSQL 데이터베이스 사용이 더 좋을 때

- 정확한 데이터 구조를 알 수 없거나 변경/확장 될 수 있는 경우
- 읽기를 자주 하지만, 데이터 변경은 자주 없는 경우
- 데이터베이스를 수평으로 확장해야 하는 경우 (막대한 양의 데이터를 다뤄야 하는 경우)

<br>

<br>

하나의 제시 방법이지 완전한 정답이 정해져 있는 것은 아니다.

SQL을 선택해서 복잡한 JOIN문을 만들지 않도록 설계하여 단점을 없앨 수도 있고

NoSQL을 선택해서 중복 데이터를 줄이는 방법으로 설계해서 단점을 없앨 수도 있다."
143,Database,Transaction Isolation Level,트랜잭션 격리 수준(Transaction Isolation Level),"#### **Isolation level** 

---

트랜잭션에서 일관성 없는 데이터를 허용하도록 하는 수준

<br>

#### Isolation level의 필요성

----

데이터베이스는 ACID 특징과 같이 트랜잭션이 독립적인 수행을 하도록 한다.

따라서 Locking을 통해, 트랜잭션이 DB를 다루는 동안 다른 트랜잭션이 관여하지 못하도록 막는 것이 필요하다.

하지만 무조건 Locking으로 동시에 수행되는 수많은 트랜잭션들을 순서대로 처리하는 방식으로 구현하게 되면 데이터베이스의 성능은 떨어지게 될 것이다.

그렇다고 해서, 성능을 높이기 위해 Locking의 범위를 줄인다면, 잘못된 값이 처리될 문제가 발생하게 된다.

- 따라서 최대한 효율적인 Locking 방법이 필요함!

<br>

#### Isolation level 종류

----

1. ##### Read Uncommitted (레벨 0)

   > SELECT 문장이 수행되는 동안 해당 데이터에 Shared Lock이 걸리지 않는 계층

   트랜잭션에 처리중이거나, 아직 Commit되지 않은 데이터를 다른 트랜잭션이 읽는 것을 허용함

   ```
   사용자1이 A라는 데이터를 B라는 데이터로 변경하는 동안 사용자2는 아직 완료되지 않은(Uncommitted) 트랜잭션이지만 데이터B를 읽을 수 있다
   ```

   데이터베이스의 일관성을 유지하는 것이 불가능함

   <br>

2. ##### Read Committed (레벨 1)

   > SELECT 문장이 수행되는 동안 해당 데이터에 Shared Lock이 걸리는 계층

   트랜잭션이 수행되는 동안 다른 트랜잭션이 접근할 수 없어 대기하게 됨

   Commit이 이루어진 트랜잭션만 조회 가능

   대부분의 SQL 서버가 Default로 사용하는 Isolation Level임

   ```
   사용자1이 A라는 데이터를 B라는 데이터로 변경하는 동안 사용자2는 해당 데이터에 접근이 불가능함
   ```

   <br>

3. ##### Repeatable Read (레벨 2)

   > 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 Shared Lock이 걸리는 계층

   트랜잭션이 범위 내에서 조회한 데이터 내용이 항상 동일함을 보장함

   다른 사용자는 트랜잭션 영역에 해당되는 데이터에 대한 수정 불가능
  
   MySQL에서 Default로 사용하는 Isolation Level

   <br>

4. ##### Serializable (레벨 3)

   > 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 Shared Lock이 걸리는 계층

   완벽한 읽기 일관성 모드를 제공함

   다른 사용자는 트랜잭션 영역에 해당되는 데이터에 대한 수정 및 입력 불가능

   <br>

<br>

***선택 시 고려사항***

Isolation Level에 대한 조정은, 동시성과 데이터 무결성에 연관되어 있음

동시성을 증가시키면 데이터 무결성에 문제가 발생하고, 데이터 무결성을 유지하면 동시성이 떨어지게 됨

레벨을 높게 조정할 수록 발생하는 비용이 증가함

<br>

##### 낮은 단계 Isolation Level을 활용할 때 발생하는 현상들

- Dirty Read

  > 커밋되지 않은 수정중인 데이터를 다른 트랜잭션에서 읽을 수 있도록 허용할 때 발생하는 현상
  >
  > 어떤 트랜잭션에서 아직 실행이 끝나지 않은 다른 트랜잭션에 의한 변경사항을 보게되는 경우  
  - 발생 Level: Read Uncommitted

- Non-Repeatable Read

  > 한 트랜잭션에서 같은 쿼리를 두 번 수행할 때 그 사이에 다른 트랜잭션 값을 수정 또는 삭제하면서 두 쿼리의 결과가 상이하게 나타나는 일관성이 깨진 현상
  - 발생 Level: Read Committed, Read Uncommitted

- Phantom Read

  > 한 트랜잭션 안에서 일정 범위의 레코드를 두 번 이상 읽었을 때, 첫번째 쿼리에서 없던 레코드가 두번째 쿼리에서 나타나는 현상
  >
  > 트랜잭션 도중 새로운 레코드 삽입을 허용하기 때문에 나타나는 현상임
  - 발생 Level: Repeatable Read, Read Committed, Read Uncommitted"
144,Database,Transaction, 트랜잭션(Transaction),"> 데이터베이스의 상태를 변화시키기 위해 수행하는 작업 단위

<br>

상태를 변화시킨다는 것 → **SQL 질의어를 통해 DB에 접근하는 것**

```
- SELECT
- INSERT
- DELETE
- UPDATE
```

<br>

작업 단위 → **많은 SQL 명령문들을 사람이 정하는 기준에 따라 정하는 것**

```
예시) 사용자 A가 사용자 B에게 만원을 송금한다.

* 이때 DB 작업
- 1. 사용자 A의 계좌에서 만원을 차감한다 : UPDATE 문을 사용해 사용자 A의 잔고를 변경
- 2. 사용자 B의 계좌에 만원을 추가한다 : UPDATE 문을 사용해 사용자 B의 잔고를 변경

현재 작업 단위 : 출금 UPDATE문 + 입금 UPDATE문
→ 이를 통틀어 하나의 트랜잭션이라고 한다.
- 위 두 쿼리문 모두 성공적으로 완료되어야만 ""하나의 작업(트랜잭션)""이 완료되는 것이다. `Commit`
- 작업 단위에 속하는 쿼리 중 하나라도 실패하면 모든 쿼리문을 취소하고 이전 상태로 돌려놓아야한다. `Rollback`

```

<br>

**즉, 하나의 트랜잭션 설계를 잘 만드는 것이 데이터를 다룰 때 많은 이점을 가져다준다.**

<br>

#### 트랜잭션 특징

---

- 원자성(Atomicity)

  > 트랜잭션이 DB에 모두 반영되거나, 혹은 전혀 반영되지 않아야 된다.

- 일관성(Consistency)

  > 트랜잭션의 작업 처리 결과는 항상 일관성 있어야 한다.

- 독립성(Isolation)

  > 둘 이상의 트랜잭션이 동시에 병행 실행되고 있을 때, 어떤 트랜잭션도 다른 트랜잭션 연산에 끼어들 수 없다.

- 지속성(Durability)

  > 트랜잭션이 성공적으로 완료되었으면, 결과는 영구적으로 반영되어야 한다.

<br>

##### Commit

하나의 트랜잭션이 성공적으로 끝났고,  DB가 일관성있는 상태일 때 이를 알려주기 위해 사용하는 연산

<br>

##### Rollback

하나의 트랜잭션 처리가 비정상적으로 종료되어 트랜잭션 원자성이 깨진 경우

transaction이 정상적으로 종료되지 않았을 때, last consistent state (예) Transaction의 시작 상태) 로 roll back 할 수 있음. 

<br>

*상황이 주어지면 DB 측면에서 어떻게 해결할 수 있을지 대답할 수 있어야 함*"
145,Database,Transaction,Transaction 관리를 위한 DBMS의 전략,"이해를 위한 2가지 개념 : DBMS의 구조 / Buffer 관리 정책

<br>

1) DBMS의 구조

> 크게 2가지 : Query Processor (질의 처리기), Storage System (저장 시스템)
>
> 입출력 단위 : 고정 길이의 page 단위로 disk에 읽거나 쓴다.
>
> 저장 공간 : 비휘발성 저장 장치인 disk에 저장, 일부분을 Main Memory에 저장

<img src=""https://d2.naver.com/content/images/2015/06/helloworld-407507-1.png"">

<br>

2) Page Buffer Manager or Buffer Manager

DBMS의 Storage System에 속하는 모듈 중 하나로, Main Memory에 유지하는 페이지를 관리하는 모듈

> Buffer 관리 정책에 따라, UNDO 복구와 REDO 복구가 요구되거나 그렇지 않게 되므로, transaction 관리에 매우 중요한 결정을 가져온다.

<br>

3) UNDO

필요한 이유 : 수정된 Page들이 **<u>Buffer 교체 알고리즘에 따라서 디스크에 출력</u>**될 수 있음. Buffer 교체는 **<u>transaction과는 무관하게 buffer의 상태에 따라서, 결정됨</u>**. 이로 인해, 정상적으로 종료되지 않은 transaction이 변경한 page들은 원상 복구 되어야 하는데,  이 복구를 undo라고 함.

- 2개의 정책 (수정된 페이지를 디스크에 쓰는 시점으로 분류)

  steal : 수정된 페이지를 언제든지 디스크에 쓸 수 있는 정책

  - 대부분의 DBMS가 채택하는 Buffer 관리 정책
  - UNDO logging과 복구를 필요로 함.

  <br>

  ¬steal : 수정된 페이지들을 EOT (End Of Transaction)까지는 버퍼에 유지하는 정책

  - UNDO 작업이 필요하지 않지만, 매우 큰 메모리 버퍼가 필요함.

<br>

4) REDO

이미 commit한 transaction의 수정을 재반영하는 복구 작업

Buffer 관리 정책에 영향을 받음

- Transaction이 종료되는 시점에 해당 transaction이 수정한 page를 디스크에 쓸 것인가 아닌가로 기준.

  <br>

  FORCE : 수정했던 모든 페이지를 Transaction commit 시점에 disk에 반영

  transaction이 commit 되었을 때 수정된 페이지들이 disk 상에 반영되므로 redo 필요 없음.

  <br>

  ¬FORCE : commit 시점에 반영하지 않는 정책

  transaction이 disk 상의 db에 반영되지 않을 수 있기에 redo 복구가 필요. (대부분의 DBMS 정책)"
146,Database,Anomaly,Anomaly,"> 정규화를 해야하는 이유는 잘못된 테이블 설계로 인해 Anomaly (이상 현상)가 나타나기 때문이다.
>
> 이 페이지에서는 Anomaly가 무엇인지 살펴본다.

예) {Student ID, Course ID, Department, Course ID, Grade}

1. 삽입 이상 (Insertion Anomaly)

   기본키가 {Student ID, Course ID} 인 경우 -> Course를 수강하지 않은 학생은 Course ID가 없는 현상이 발생함. 결국 Course ID를 Null로 할 수밖에 없는데, 기본키는 Null이 될 수 없으므로, Table에 추가될 수 없음.

   굳이 삽입하기 위해서는 '미수강'과 같은 Course ID를 만들어야 함.

   > 불필요한 데이터를 추가해야지, 삽입할 수 있는 상황 = Insertion Anomaly

   

2. 갱신 이상 (Update Anomaly)

   만약 어떤 학생의 전공 (Department) 이 ""컴퓨터에서 음악""으로 바뀌는 경우.

   모든 Department를 ""음악""으로 바꾸어야 함. 그러나 일부를 깜빡하고 바꾸지 못하는 경우, 제대로 파악 못함.

   > 일부만 변경하여, 데이터가 불일치 하는 모순의 문제 = Update Anomaly

   

3. 삭제 이상 (Deletion Anomaly)

   만약 어떤 학생이 수강을 철회하는 경우, {Student ID, Department, Course ID, Grade}의 정보 중

   Student ID, Department 와 같은 학생에 대한 정보도 함께 삭제됨.

   > 튜플 삭제로 인해 꼭 필요한 데이터까지 함께 삭제되는 문제 = Deletion Anomaly"
147,Database, Index, Index(인덱스),"#### 목적

```
추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스 테이블의 검색 속도를 향상시키기 위한 자료구조
```

테이블의 칼럼을 색인화한다.

> 마치, 두꺼운 책의 목차와 같다고 생각하면 편하다.

데이터베이스 안의 레코드를 처음부터 풀스캔하지 않고, B+ Tree로 구성된 구조에서 Index 파일 검색으로 속도를 향상시키는 기술이다.

<br>

<br>

#### 파일 구성

테이블 생성 시, 3가지 파일이 생성된다.

- FRM : 테이블 구조 저장 파일
- MYD : 실제 데이터 파일
- MYI : Index 정보 파일 (Index 사용 시 생성)

<br>

사용자가 쿼리를 통해 Index를 사용하는 칼럼을 검색하게 되면, 이때 MYI 파일의 내용을 활용한다.

<BR>

#### 단점

- Index 생성시, .mdb 파일 크기가 증가한다.
- **한 페이지를 동시에 수정할 수 있는 병행성**이 줄어든다.
- 인덱스 된 Field에서 Data를 업데이트하거나, **Record를 추가 또는 삭제시 성능이 떨어진다.**
- 데이터 변경 작업이 자주 일어나는 경우, **Index를 재작성**해야 하므로 성능에 영향을 미친다.

<br>

#### 상황 분석

- ##### 사용하면 좋은 경우

  (1) Where 절에서 자주 사용되는 Column

  (2) 외래키가 사용되는 Column

  (3) Join에 자주 사용되는 Column

  <br>

- ##### Index 사용을 피해야 하는 경우

  (1) Data 중복도가 높은 Column

  (2) DML이 자주 일어나는 Column

<br>

#### DML이 일어났을 때의 상황

- ##### INSERT

  기존 Block에 여유가 없을 때, 새로운 Data가 입력된다.

  → 새로운 Block을 할당 받은 후, Key를 옮기는 작업을 수행한다.

  → Index split 작업 동안, 해당 Block의 Key 값에 대해서 DML이 블로킹 된다. (대기 이벤트 발생)

  → 이때 Block의 논리적인 순서와 물리적인 순서가 달라질 수 있다. (인덱스 조각화)

- ##### DELETE

  <Table과 Index 상황 비교>

  Table에서 data가 delete 되는 경우 : Data가 지워지고, 다른 Data가 그 공간을 사용 가능하다.

  Index에서 Data가 delete 되는 경우 : Data가 지워지지 않고, 사용 안 됨 표시만 해둔다.

  → **Table의 Data 수와 Index의 Data 수가 다를 수 있음**

- ##### UPDATE

  Table에서 update가 발생하면 → Index는 Update 할 수 없다.

  Index에서는 **Delete가 발생한 후, 새로운 작업의 Insert 작업** / 2배의 작업이 소요되어 힘들다."
148,Database, Index,인덱스 관리 방식,"- ##### B-Tree 자료구조

  이진 탐색트리와 유사한 자료구조

  자식 노드를 둘이상 가질 수 있고 Balanced Tree 라는 특징이 있다 → 즉 탐색 연산에 있어 O(log N)의 시간복잡도를 갖는다.

  모든 노드들에 대해 값을 저장하고 있으며 포인터 역할을 동반한다.

- ##### B+Tree 자료구조

  B-Tree를 개선한 형태의 자료구조

  값을 리프노드에만 저장하며 리프노드들 끼리는 링크드 리스트로 연결되어 있다 → 때문에 부등호문 연산에 대해 효과적이다.

  리프 노드를 제외한 노드들은 포인터의 역할만을 수행한다.

- ##### HashTable 자료구조

  해시 함수를 이용해서 값을 인덱스로 변경 하여 관리하는 자료구조

  일반적인 경우 탐색, 삽입, 삭제 연산에 대해 O(1)의 시간 복잡도를 갖는다.

  다른 관리 방식에 비해 빠른 성능을 갖는다.

  최악의 경우 해시 충돌이 발생하는 것으로 탐색, 삽입, 삭제 연산에 대해 O(N)의 시간복잡도를 갖는다.

  값 자체를 변경하기 때문에 부등호문, 포함문등의 연산에 사용할 수 없다.C67"
149,Database,Key,Key,"> Key란? : 검색, 정렬시 Tuple을 구분할 수 있는 기준이 되는 Attribute.

<br>

#### 1. Candidate Key (후보키)

> Tuple을 유일하게 식별하기 위해 사용하는 속성들의 부분 집합. (기본키로 사용할 수 있는 속성들)

2가지 조건 만족

* 유일성 : Key로 하나의 Tuple을 유일하게 식별할 수 있음
* 최소성 : 꼭 필요한 속성으로만 구성

<br>

#### 2. Primary Key (기본키)

> 후보키 중 선택한 Main Key

특징 

* Null 값을 가질 수 없음
* 동일한 값이 중복될 수 없음

<br>

#### 3. Alternate Key (대체키)

> 후보키 중 기본키를 제외한 나머지 키 = 보조키

<br>

#### 4. Super Key (슈퍼키)

> 유일성은 만족하지만, 최소성은 만족하지 못하는 키

<br>

#### 5. Foreign Key (외래키)

> 다른 릴레이션의 기본키를 그대로 참조하는 속성의 집합"
150,Database,Join,조인이란?,"> 두 개 이상의 테이블이나 데이터베이스를 연결하여 데이터를 검색하는 방법

테이블을 연결하려면, 적어도 하나의 칼럼을 서로 공유하고 있어야 하므로 이를 이용하여 데이터 검색에 활용한다.

<br>

#### JOIN 종류

---

- INNER JOIN
- LEFT OUTER JOIN
- RIGHT OUTER JOIN
- FULL OUTER JOIN
- CROSS JOIN
- SELF JOIN"
151,Database,Join,INNER JOIN,"  <img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F99799F3E5A8148D7036659"">

  교집합으로, 기준 테이블과 join 테이블의 중복된 값을 보여준다.

  ```sql
  SELECT
  A.NAME, B.AGE
  FROM EX_TABLE A
  INNER JOIN JOIN_TABLE B ON A.NO_EMP = B.NO_EMP
  ```"
152,Database,Join,LEFT OUTER JOIN,"  <img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F997E7F415A81490507F027"">

  기준테이블값과 조인테이블과 중복된 값을 보여준다.

  왼쪽테이블 기준으로 JOIN을 한다고 생각하면 편하다.

  ```SQL
  SELECT
  A.NAME, B.AGE
  FROM EX_TABLE A
  LEFT OUTER JOIN JOIN_TABLE B ON A.NO_EMP = B.NO_EMP
  ```"
153,Database,Join,RIGHT OUTER JOIN,"  <img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile25.uf.tistory.com%2Fimage%2F9984CE355A8149180ABD1D"">

  LEFT OUTER JOIN과는 반대로 오른쪽 테이블 기준으로 JOIN하는 것이다.

  ```SQL
  SELECT
  A.NAME, B.AGE
  FROM EX_TABLE A
  RIGHT OUTER JOIN JOIN_TABLE B ON A.NO_EMP = B.NO_EMP
  ```"
154,Database,Join,FULL OUTER JOIN,"  <img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile24.uf.tistory.com%2Fimage%2F99195F345A8149391BE0C3"">

  합집합을 말한다. A와 B 테이블의 모든 데이터가 검색된다.

  ```sql
  SELECT
  A.NAME, B.AGE
  FROM EX_TABLE A
  FULL OUTER JOIN JOIN_TABLE B ON A.NO_EMP = B.NO_EMP
  ```"
155,Database,Join,CROSS JOIN,"  <img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F993F4E445A8A2D281AC66B"">

  모든 경우의 수를 전부 표현해주는 방식이다.

  A가 3개, B가 4개면 총 3*4 = 12개의 데이터가 검색된다.

  ```sql
  SELECT
  A.NAME, B.AGE
  FROM EX_TABLE A
  CROSS JOIN JOIN_TABLE B
  ```"
156,Database,Join,SELF JOIN,"  <img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile25.uf.tistory.com%2Fimage%2F99341D335A8A363D0614E8"">

  자기자신과 자기자신을 조인하는 것이다.

  하나의 테이블을 여러번 복사해서 조인한다고 생각하면 편하다.

  자신이 갖고 있는 칼럼을 다양하게 변형시켜 활용할 때 자주 사용한다.

  ``` sql
  SELECT
  A.NAME, B.AGE
  FROM EX_TABLE A, EX_TABLE B
  ```"
157,Database,Stored PROCEDURE,저장 프로시저(Stored PROCEDURE),"```
일련의 쿼리를 마치 하나의 함수처럼 실행하기 위한 쿼리의 집합
```

<br>

데이터베이스에서 SQL을 통해 작업을 하다 보면, 하나의 쿼리문으로 원하는 결과를 얻을 수 없을 때가 생긴다. 원하는 결과물을 얻기 위해 사용할 여러줄의 쿼리문을 한 번의 요청으로 실행하면 좋지 않을까? 또한, 인자 값만 상황에 따라 바뀌고 동일한 로직의 복잡한 쿼리문을 필요할 때마다 작성한다면 비효율적이지 않을까?

이럴 때 사용할 수 있는 것이 바로 프로시저다.

<br>

프로시저를 만들어두면, 애플리케이션에서 여러 상황에 따라 해당 쿼리문이 필요할 때 인자 값만 전달하여 쉽게 원하는 결과물을 받아낼 수 있다."
158,Database,Stored PROCEDURE,프로시저 생성 및 호출,"```plsql
CREATE OR REPLACE PROCEDURE 프로시저명(변수명1 IN 데이터타입, 변수명2 OUT 데이터타입) -- 인자 값은 필수 아님
IS
[
변수명1 데이터타입;
변수명2 데이터타입;
..
]
BEGIN
 필요한 기능; -- 인자값 활용 가능
END;

EXEC 프로시저명; -- 호출
```

<br>

#### 예시1 (IN)

```plsql
CREATE OR REPLACE PROCEDURE test( name IN VARCHAR2 ) 
IS
	msg VARCHAR2(5) := '내 이름은';
BEGIN 
	dbms_output.put_line(msg||' '||name); 
END;

EXEC test('규글');
```

```
내 이름은 규글
```

<br>

#### 예시2 (OUT)

```plsql
CREATE OR REPLACE PROCEDURE test( name OUT VARCHAR2 ) 
IS
BEGIN 
	name := 'Gyoogle'
END;

DECLARE
out_name VARCHAR2(100);

BEGIN
test(out_name);
dbms_output.put_line('내 이름은 '||out_name);
END;
```

```
내 이름은 Gyoogle
```"
159,Database,Stored PROCEDURE,프로시저 장단점,"### 프로시저 장점

---

1. #### 최적화 & 캐시

   프로시저의 최초 실행 시 최적화 상태로 컴파일이 되며, 그 이후 프로시저 캐시에 저장된다.

   만약 해당 프로세스가 여러번 사용될 때, 다시 컴파일 작업을 거치지 않고 캐시에서 가져오게 된다.

2. #### 유지 보수

   작업이 변경될 때, 다른 작업은 건드리지 않고 프로시저 내부에서 수정만 하면 된다.
   (But, 장점이 단점이 될 수도 있는 부분이기도.. )

3. #### 트래픽 감소

   클라이언트가 직접 SQL문을 작성하지 않고, 프로시저명에 매개변수만 담아 전달하면 된다. 즉, SQL문이 서버에 이미 저장되어 있기 때문에 클라이언트와 서버 간 네트워크 상 트래픽이 감소된다.

4. #### 보안

   프로시저 내에서 참조 중인 테이블의 접근을 막을 수 있다.

<br>

### 프로시저 단점

---

1. #### 호환성

   구문 규칙이 SQL / PSM 표준과의 호환성이 낮기 때문에 코드 자산으로의 재사용성이 나쁘다.

2. #### 성능

   문자 또는 숫자 연산에서 프로그래밍 언어인 C나 Java보다 성능이 느리다.

3. #### 디버깅

   에러가 발생했을 때, 어디서 잘못됐는지 디버깅하는 것이 힘들 수 있다."
160,Database,Normalization,정규화(Normalization),"```
데이터의 중복을 줄이고, 무결성을 향상시킬 수 있는 정규화에 대해 알아보자
```

<br>

### Normalization

가장 큰 목표는 테이블 간 **중복된 데이터를 허용하지 않는 것**이다.

중복된 데이터를 만들지 않으면, 무결성을 유지할 수 있고, DB 저장 용량 또한 효율적으로 관리할 수 있다.

<br>

### 목적

- 데이터의 중복을 없애면서 불필요한 데이터를 최소화시킨다.
- 무결성을 지키고, 이상 현상을 방지한다.
- 테이블 구성을 논리적이고 직관적으로 할 수 있다.
- 데이터베이스 구조 확장이 용이해진다.

<br>

정규화에는 여러가지 단계가 있지만, 대체적으로 1~3단계 정규화까지의 과정을 거친다."
161,Database,Normalization,제 1정규화(1NF),"테이블 컬럼이 원자값(하나의 값)을 갖도록 테이블을 분리시키는 것을 말한다.

만족해야 할 조건은 아래와 같다.

- 어떤 릴레이션에 속한 모든 도메인이 원자값만으로 되어 있어야한다.
- 모든 속성에 반복되는 그룹이 나타나지 않는다.
- 기본키를 사용하여 관련 데이터의 각 집합을 고유하게 식별할 수 있어야 한다.

<br>

<img src=""http://dl.dropbox.com/s/9s8vowdzs3t66uw/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-12-02%2017.50.02.png"">

<br>

현재 테이블은 전화번호를 여러개 가지고 있어 원자값이 아니다. 따라서 1NF에 맞추기 위해서는 아래와 같이 분리할 수 있다.

<br>

<img src=""http://dl.dropbox.com/s/1rr8ofxuy46i61b/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-12-02%2018.00.52.png"">"
162,Database,Normalization,제 2정규화(2NF),"테이블의 모든 컬럼이 완전 함수적 종속을 만족해야 한다.

조금 쉽게 말하면, 테이블에서 기본키가 복합키(키1, 키2)로 묶여있을 때, 두 키 중 하나의 키만으로 다른 컬럼을 결정지을 수 있으면 안된다.

> 기본키의 부분집합 키가 결정자가 되어선 안된다는 것

<br>

<img src=""http://dl.dropbox.com/s/c2xfxdanbuiaw1l/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-12-03%2006.58.17.png"">

<br>

`Manufacture`과 `Model`이 키가 되어 `Model Full Name`을 알 수 있다.

`Manufacturer Country`는 `Manufacturer`로 인해 결정된다. (부분 함수 종속)

따라서, `Model`과 `Manufacturer Country`는 아무런 연관관계가 없는 상황이다.

<br>

결국 완전 함수적 종속을 충족시키지 못하고 있는 테이블이다. 부분 함수 종속을 해결하기 위해 테이블을 아래와 같이 나눠서 2NF를 만족할 수 있다.

<br>

<img src=""http://dl.dropbox.com/s/x8481598dhnpzeg/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-12-03%2010.58.15.png"">"
163,Database,Normalization,제 3정규화(3NF),"2NF가 진행된 테이블에서 이행적 종속을 없애기 위해 테이블을 분리하는 것이다.

> 이행적 종속 : A → B, B → C면 A → C가 성립된다

아래 두가지 조건을 만족시켜야 한다.

- 릴레이션이 2NF에 만족한다.
- 기본키가 아닌 속성들은 기본키에 의존한다.

<br>

<img src=""http://dl.dropbox.com/s/xtfoetv8hg6jn3f/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-12-03%2012.59.46.png"">

<br>

현재 테이블에서는 `Tournament`와 `Year`이 기본키다.

`Winner`는 이 두 복합키를 통해 결정된다.

하지만 `Winner Date of Birth`는 기본키가 아닌 `Winner`에 의해 결정되고 있다. 

따라서 이는 3NF를 위반하고 있으므로 아래와 같이 분리해야 한다.

<br>

<img src=""http://dl.dropbox.com/s/ks03nkc26nsffin/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202018-12-04%2014.51.39.png"">"
164,NetWork,DNS,DNS란?,"모든 통신은 IP를 기반으로 연결된다. 하지만 사용자에게 일일히 IP 주소를 입력하기란 UX적으로 좋지 않다

때문에 DNS 가 등장 했으며 DNS 는 IP 주소와 도메인 주소를 매핑하는 역할을 수행한다"
165,NetWork,DNS,도메인 주소가 IP로 변환되는 과정,"1. 디바이스는 hosts 파일을 열어 봅니다
   - hosts 파일에는 로컬에서 직접 설정한 호스트 이름과 IP 주소를 매핑 하고 있습니다
2. DNS는 캐시를 확인 합니다
   - 기존에 접속했던 사이트의 경우 캐시에 남아 있을 수 있습니다
   - DNS는 브라우저 캐시, 로컬 캐시(OS 캐시), 라우터 캐시, ISP(Internet Service Provider)캐시 순으로 확인 합니다
3. DNS는 Root DNS에 요청을 보냅니다
   - 모든 DNS에는 Root DNS의 주소가 포함 되어 있습니다
   - 이를 통해 Root DNS에게 질의를 보내게 됩니다
   - Root DNS는 도메인 주소의 최상위 계층을 확인하여 TLD(Top Level DNS)의 주소를 반환 합니다
4. DNS는 TLD에 요청을 보냅니다
   - Root DNS로 부터 반환받은 주소를 통해 요청을 보냅니다
   - TLD는 도메인에 권한이 있는 Authoritative DNS의 주소를 반환 합니다
5. DNS는 Authoritative DNS에 요청을 보냅니다
   - 도메인 이름에 대한 IP 주소를 반환 합니다"
166,NetWork,OSI 7 계층,물리(Physical),"> 리피터, 케이블, 허브 등

단지 데이터를 전기적인 신호로 변환해서 주고받는 기능을 진행하는 공간

즉, 데이터를 전송하는 역할만 진행한다."
167,NetWork,OSI 7 계층,데이터 링크(Data Link),"> 브릿지, 스위치 등

물리 계층으로 송수신되는 정보를 관리하여 안전하게 전달되도록 도와주는 역할

Mac 주소를 통해 통신한다. 프레임에 Mac 주소를 부여하고 에러검출, 재전송, 흐름제어를 진행한다."
168,NetWork,OSI 7 계층,네트워크(NetWork),"> 라우터, IP

데이터를 목적지까지 가장 안전하고 빠르게 전달하는 기능을 담당한다.

라우터를 통해 이동할 경로를 선택하여 IP 주소를 지정하고, 해당 경로에 따라 패킷을 전달해준다.

라우팅, 흐름 제어, 오류 제어, 세그먼테이션 등을 수행한다."
169,NetWork,OSI 7 계층,전송(Transport),"> TCP, UDP

TCP와 UDP 프로토콜을 통해 통신을 활성화한다. 포트를 열어두고, 프로그램들이 전송을 할 수 있도록 제공해준다.

- TCP : 신뢰성, 연결지향적

- UDP : 비신뢰성, 비연결성, 실시간"
170,NetWork,OSI 7 계층,세션(Session),"> API, Socket

데이터가 통신하기 위한 논리적 연결을 담당한다. TCP/IP 세션을 만들고 없애는 책임을 지니고 있다."
171,NetWork,OSI 7 계층,표현(Presentation),"> JPEG, MPEG 등

데이터 표현에 대한 독립성을 제공하고 암호화하는 역할을 담당한다.

파일 인코딩, 명령어를 포장, 압축, 암호화한다."
172,NetWork,OSI 7 계층,응용(Aplication),"> HTTP, FTP, DNS 등

최종 목적지로, 응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행한다.

사용자 인터페이스, 전자우편, 데이터베이스 관리 등의 서비스를 제공한다."
173,NetWork,3 way handshake & 4 way handshake,3 way handshake,"TCP는 정확한 전송을 보장해야 한다. 따라서 통신하기에 앞서, 논리적인 접속을 성립하기 위해 3 way handshake 과정을 진행한다.

1) 클라이언트가 서버에게 SYN 패킷을 보냄 (sequence : x)

2) 서버가 SYN(x)을 받고, 클라이언트로 받았다는 신호인 ACK와 SYN 패킷을 보냄 (sequence : y, ACK : x + 1)

3) 클라이언트는 서버의 응답은 ACK(x+1)와 SYN(y) 패킷을 받고, ACK(y+1)를 서버로 보냄

<br>

이렇게 3번의 통신이 완료되면 연결이 성립된다. (3번이라 3 way handshake인 것)"
174,NetWork,3 way handshake & 4 way handshake,4 way handshake,"연결 성립 후, 모든 통신이 끝났다면 해제해야 한다.

1) 클라이언트는 서버에게 연결을 종료한다는 FIN 플래그를 보낸다.

2) 서버는 FIN을 받고, 확인했다는 ACK를 클라이언트에게 보낸다. (이때 모든 데이터를 보내기 위해 CLOSE_WAIT 상태가 된다)

3) 데이터를 모두 보냈다면, 연결이 종료되었다는 FIN 플래그를 클라이언트에게 보낸다.

4) 클라이언트는 FIN을 받고, 확인했다는 ACK를 서버에게 보낸다. (아직 서버로부터 받지 못한 데이터가 있을 수 있으므로 TIME_WAIT을 통해 기다린다.)

- 서버는 ACK를 받은 이후 소켓을 닫는다 (Closed)

- TIME_WAIT 시간이 끝나면 클라이언트도 닫는다 (Closed)

<br>

이렇게 4번의 통신이 완료되면 연결이 해제된다."
175,NetWork,TCP,TCP란?,"- 네트워크 통신에서 신뢰적인 연결방식
  - TCP는 기본적으로 unreliable network에서, reliable network를 보장할 수 있도록 하는 프로토콜
  - TCP는 network congestion avoidance algorithm을 사용"
176,NetWork,TCP,흐름제어,"- 수신측이 송신측보다 데이터 처리 속도가 빠르면 문제없지만, 송신측의 속도가 빠를 경우 문제가 생긴다.

- 수신측에서 제한된 저장 용량을 초과한 이후에 도착하는 데이터는 손실 될 수 있으며, 만약 손실 된다면 불필요하게 응답과 데이터 전송이 송/수신 측 간에 빈번히 발생한다.

- 이러한 위험을 줄이기 위해 송신 측의 데이터 전송량을 수신측에 따라 조절해야한다.

- 해결방법

  - Stop and Wait : 매번 전송한 패킷에 대해 확인 응답을 받아야만 그 다음 패킷을 전송하는 방법

  - Sliding Window (Go Back N ARQ) 
    - 수신측에서 설정한 윈도우 크기만큼 송신측에서 확인응답없이 세그먼트를 전송할 수 있게 하여 데이터 흐름을 동적으로 조절하는 제어기법

    - 목적 : 전송은 되었지만, acked를 받지 못한 byte의 숫자를 파악하기 위해 사용하는 protocol

      LastByteSent - LastByteAcked <= ReceivecWindowAdvertised

      (마지막에 보내진 바이트 - 마지막에 확인된 바이트 <= 남아있는 공간) ==

      (현재 공중에 떠있는 패킷 수 <= sliding window)

  - 동작방식 : 먼저 윈도우에 포함되는 모든 패킷을 전송하고, 그 패킷들의 전달이 확인되는대로 이 윈도우를 옆으로 옮김으로써 그 다음 패킷들을 전송


  - Window : TCP/IP를 사용하는 모든 호스트들은 송신하기 위한 것과 수신하기 위한 2개의 Window를 가지고 있다. 호스트들은 실제 데이터를 보내기 전에 '3 way handshaking'을 통해 수신 호스트의 receive window size에 자신의 send window size를 맞추게 된다."
177,NetWork,TCP,혼잡제어,"- 송신측의 데이터는 지역망이나 인터넷으로 연결된 대형 네트워크를 통해 전달된다. 만약 한 라우터에 데이터가 몰릴 경우, 자신에게 온 데이터를 모두 처리할 수 없게 된다. 이런 경우 호스트들은 또 다시 재전송을 하게되고 결국 혼잡만 가중시켜 오버플로우나 데이터 손실을 발생시키게 된다. 따라서 이러한 네트워크의 혼잡을 피하기 위해 송신측에서 보내는 데이터의 전송속도를 강제로 줄이게 되는데, 이러한 작업을 혼잡제어라고 한다.
- 또한 네트워크 내에 패킷의 수가 과도하게 증가하는 현상을 혼잡이라 하며, 혼잡 현상을 방지하거나 제거하는 기능을 혼잡제어라고 한다.
- 흐름제어가 송신측과 수신측 사이의 전송속도를 다루는데 반해, 혼잡제어는 호스트와 라우터를 포함한 보다 넓은 관점에서 전송 문제를 다루게 된다.
- 해결 방법
    - 처음에 패킷을 하나씩 보내고 이것이 문제없이 도착하면 window 크기(단위 시간 내에 보내는 패킷의 수)를 1씩 증가시켜가며 전송하는 방법
    - 패킷 전송에 실패하거나 일정 시간을 넘으면 패킷의 보내는 속도를 절반으로 줄인다.
    - 공평한 방식으로, 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 진입하는 쪽이 처음에는 불리하지만, 시간이 흐르면 평형상태로 수렴하게 되는 특징이 있다.
    - 문제점은 초기에 네트워크의 높은 대역폭을 사용하지 못하여 오랜 시간이 걸리게 되고, 네트워크가 혼잡해지는 상황을 미리 감지하지 못한다. 즉, 네트워크가 혼잡해지고 나서야 대역폭을 줄이는 방식이다.
  - Slow Start (느린 시작)
    - AIMD 방식이 네트워크의 수용량 주변에서는 효율적으로 작동하지만, 처음에 전송 속도를 올리는데 시간이 오래 걸리는 단점이 존재했다.
    - Slow Start 방식은 AIMD와 마찬가지로 패킷을 하나씩 보내면서 시작하고, 패킷이 문제없이 도착하면 각각의 ACK 패킷마다 window size를 1씩 늘려준다. 즉, 한 주기가 지나면 window size가 2배로 된다. 
    - 전송속도는 AIMD에 반해 지수 함수 꼴로 증가한다. 대신에 혼잡 현상이 발생하면 window size를 1로 떨어뜨리게 된다.
    - 처음에는 네트워크의 수용량을 예상할 수 있는 정보가 없지만, 한번 혼잡 현상이 발생하고 나면 네트워크의 수용량을 어느 정도 예상할 수 있다. 
    - 그러므로 혼잡 현상이 발생하였던 window size의 절반까지는 이전처럼 지수 함수 꼴로 창 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시킨다.
  - Fast Retransmit (빠른 재전송)
    - 빠른 재전송은 TCP의 혼잡 조절에 추가된 정책이다. 
    - 패킷을 받는 쪽에서 먼저 도착해야할 패킷이 도착하지 않고 다음 패킷이 도착한 경우에도 ACK 패킷을 보내게 된다. 
    - 단, 순서대로 잘 도착한 마지막 패킷의 다음 패킷의 순번을 ACK 패킷에 실어서 보내게 되므로, 중간에 하나가 손실되게 되면 송신 측에서는 순번이 중복된 ACK 패킷을 받게 된다. 이것을 감지하는 순간 문제가 되는 순번의 패킷을 재전송 해줄 수 있다.
    - 중복된 순번의 패킷을 3개 받으면 재전송을 하게 된다. 약간 혼잡한 상황이 일어난 것이므로 혼잡을 감지하고 window size를 줄이게 된다.
  - Fast Recovery (빠른 회복)
    - 혼잡한 상태가 되면 window size를 1로 줄이지 않고 반으로 줄이고 선형증가시키는 방법이다. 이 정책까지 적용하면 혼잡 상황을 한번 겪고 나서부터는 순수한 AIMD 방식으로 동작하게 된다.
"
178,NetWork,UDP,UDP란?,"- UDP 통신이란?

  - User Datagram Protocol의 약자로 데이터를 데이터그램 단위로 처리하는 프로토콜이다. 
  - 비연결형, 신뢰성 없는 전송 프로토콜이다.
  - 데이터그램 단위로 쪼개면서 전송을 해야하기 때문에 전송 계층이다.
  - Transport layer에서 사용하는 프로토콜.

- TCP와 UDP는 왜 나오게 됐는가?

  1. IP의 역할은 Host to Host (장치 to 장치)만을 지원한다. 장치에서 장치로 이동은 IP로 해결되지만, 하나의 장비안에서 수많은 프로그램들이 통신을 할 경우에는 IP만으로는 한계가 있다.

  2. 또한, IP에서 오류가 발생한다면 ICMP에서 알려준다. 하지만 ICMP는 알려주기만 할 뿐 대처를 못하기 때문에 IP보다 위에서 처리를 해줘야 한다.

  - 1번을 해결하기 위하여 포트 번호가 나오게 됐고, 2번을 해결하기 위해 상위 프로토콜인 TCP와 UDP가 나오게 되었다.

  * *ICMP : 인터넷 제어 메시지 프로토콜로 네트워크 컴퓨터 위에서 돌아가는 운영체제에서 오류 메시지를 전송받는데 주로 쓰임

- 그렇다면 TCP와 UDP가 어떻게 오류를 해결하는가?

  - TCP : 데이터의 분실, 중복, 순서가 뒤바뀜 등을 자동으로 보정해줘서 송수신 데이터의 정확한 전달을 할 수 있도록 해준다.
  - UDP : IP가 제공하는 정도의 수준만을 제공하는 간단한 IP 상위 계층의 프로토콜이다. TCP와는 다르게 에러가 날 수도 있고, 재전송이나 순서가 뒤바뀔 수도 있어서 이 경우, 어플리케이션에서 처리하는 번거로움이 존재한다.

- UDP는 왜 사용할까?

  - UDP의 결정적인 장점은 데이터의 신속성이다. 데이터의 처리가 TCP보다 빠르다.
  - 주로 실시간 방송과 온라인 게임에서 사용된다. 네트워크 환경이 안 좋을때, 끊기는 현상을 생각하면 된다.

- DNS(Domain Name System)에서 UDP를 사용하는 이유

  - Request의 양이 작음 -> UDP Request에 담길 수 있다.
  - 3 way handshaking으로 연결을 유지할 필요가 없다. (오버헤드 발생)
  - Request에 대한 손실은 Application Layer에서 제어가 가능하다.
  - DNS : port 53번
  - But, TCP를 사용할 때가 있다! 크기가 512(UDP 제한)이 넘을 때, TCP를 사용해야한다. "
179,NetWork,UDP,UDP 사용하는 이유?,"1. TCP가 3-way handshake를 사용하는 반면, UDP는 connection 을 유지할 필요가 없음.

2. DNS request는 UDP segment에 꼭 들어갈 정도로 작음.

   DNS query는 single UDP request와 server로부터의 single UDP reply로 구성되어 있음.

3. UDP는 not reliable이나, reliability는 application layer에 추가될 수 있음.
   (Timeout 추가나, resend 작업을 통해)

DNS는 UDP를 53번 port에서 사용함.

------

그러나 TCP를 사용하는 경우가 있음.

Zone transfer 을 사용해야하는 경우에는 TCP를 사용해야 함.

(Zone Transfer : DNS 서버 간의 요청을 주고 받을 떄 사용하는 transfer)

만약에 데이터가 512 bytes를 넘거나, 응답을 못받은 경우 TCP로 함."
180,NetWork,대칭키 & 공개키,대칭키,"> 암호화와 복호화에 같은 암호키(대칭키)를 사용하는 알고리즘

동일한 키를 주고받기 때문에, 매우 빠르다는 장점이 있음

but, 대칭키 전달과정에서 해킹 위험에 노출"
181,NetWork,대칭키 & 공개키,공개키(public Key)/ 비대칭 키(Asymmetric Key),"> 암호화와 복호화에 사용하는 암호키를 분리한 알고리즘

대칭키의 키 분배 문제를 해결하기 위해 고안됨.(대칭키일 때는 송수신자 간만 키를 알아야하기 때문에 분배가 복잡하고 어렵지만 공개키와 비밀키로 분리할 경우, 남들이 알아도 되는 공개키만 공개하면 되므로)

자신이 가지고 있는 고유한 암호키(비밀키)로만 복호화할 수 있는 암호키(공개키)를 대중에 공개함"
182,NetWork,대칭키 & 공개키,공개키 암호화 방식 진행 과정,"1) A가 웹 상에 공개된 'B의 공개키'를 이용해 평문을 암호화하여 B에게 보냄
2) B는 자신의 비밀키로 복호화한 평문을 확인, A의 공개키로 응답을 암호화하여 A에개 보냄
3) A는 자신의 비밀키로 암호화된 응답문을 복호화함

하지만 이 방식은 Confidentiallity만 보장해줄 뿐, Integrity나 Authenticity는 보장해주지 못함

-> 이는 MAC(Message Authentication Code)나 전자 서명(Digital Signature)으로 해결
(MAC은 공개키 방식이 아니라 대칭키 방식임을 유의! T=MAC(K,M) 형식)

대칭키에 비해 암호화 복호화가 매우 복잡함

(암호화하는 키가 복호화하는 키가 서로 다르기 때문)"
183,NetWork,HTTP & HTTPS,HTTP(HyperText Transfer Protocol),"인터넷 상에서 클라이언트와 서버가 자원을 주고 받을 때 쓰는 통신 규약

<br>

HTTP는 텍스트 교환이므로, 누군가 네트워크에서 신호를 가로채면 내용이 노출되는 보안 이슈가 존재한다.

이런 보안 문제를 해결해주는 프로토콜이 **'HTTPS'**"
184,NetWork,HTTP & HTTPS,HTTP의 보안 취약점,"1. **도청이 가능하다**

- 평문으로 통신하기 때문에 도청이 가능하다
- 이를 해결하기 위해서 통신자체를암호화(HTTPS)하거나 데이터를 암호화 하는 방법등이 있다
- 데이터를 암호화 하는 경우 수신측에서는 보호화 과정이 필요하다

2. **위장이 가능하다**

- 통신 상대를 확인하지 않기 깨문에 위장된 상대와 통신할 수 있다
- HTTPS는 CA 인증서를 통해 인증된 상대와 통신이 가능하다

3. **변조가 가능하다**

- 완전성을 보장하지 않기 때문에 변조가 가능하다
- HTTPS는 메세지 인증 코드(MAC), 전자 서명등을 통해 변조를 방지 한다
"
185,NetWork,HTTP & HTTPS,HTTPS(HyperText Transfer Protocol Secure),"인터넷 상에서 정보를 암호화하는 SSL 프로토콜을 사용해 클라이언트와 서버가 자원을 주고 받을 때 쓰는 통신 규약

HTTPS는 텍스트를 암호화한다. (공개키 암호화 방식으로!)"
186,NetWork,HTTP & HTTPS,HTTPS 통신 흐름,"1. 애플리케이션 서버(A)를 만드는 기업은 HTTPS를 적용하기 위해 공개키와 개인키를 만든다.

2. 신뢰할 수 있는 CA 기업을 선택하고, 그 기업에게 내 공개키 관리를 부탁하며 계약을 한다.

**_CA란?_** : Certificate Authority로, 공개키를 저장해주는 신뢰성이 검증된 민간기업

3. 계약 완료된 CA 기업은 해당 기업의 이름, A서버 공개키, 공개키 암호화 방법을 담은 인증서를 만들고, 해당 인증서를 CA 기업의 개인키로 암호화해서 A서버에게 제공한다.

4. A서버는 암호화된 인증서를 갖게 되었다. 이제 A서버는 A서버의 공개키로 암호화된 HTTPS 요청이 아닌 요청이 오면, 이 암호화된 인증서를 클라이언트에게 건내준다.

5. 클라이언트가 `main.html` 파일을 달라고 A서버에 요청했다고 가정하자. HTTPS 요청이 아니기 때문에 CA기업이 A서버의 정보를 CA 기업의 개인키로 암호화한 인증서를 받게 된다.

CA 기업의 공개키는 브라우저가 이미 알고있다. (세계적으로 신뢰할 수 있는 기업으로 등록되어 있기 때문에, 브라우저가 인증서를 탐색하여 해독이 가능한 것)

6. 브라우저는 해독한 뒤 A서버의 공개키를 얻게 되었다.

7. 클라이언트가 A서버와 HandShaking 과정에서 주고받은 난수를 조합하여 pre-master-secret-key 를 생성한 뒤, A서버의 공개키로 해당 대칭키를 암호화하여 서버로 보냅니다.

8. A서버는 암호화된 대칭키를 자신의 개인키로 복호화 하여 클라이언트와 동일한 대칭키를 획득합니다.

9. 클라이언트, 서버는 각각 pre-master-secret-key를 master-secret-key으로 만듭니다.

10. master-secret-key 를 통해 session-key를 생성하고 이를 이용하여 대칭키 방식으로 통신합니다.

11. 각 통신이 종료될 때마다 session-key를 파기합니다.

<br>

HTTPS도 무조건 안전한 것은 아니다. (신뢰받는 CA 기업이 아닌 자체 인증서 발급한 경우 등)

이때는 HTTPS지만 브라우저에서 `주의 요함`, `안전하지 않은 사이트`와 같은 알림으로 주의 받게 된다."
187,NetWork,TLS/SSL,TLS/SSL HandShake란?,"HTTPS에서 클라이언트와 서버간 통신 전
SSL 인증서로 신뢰성 여부를 판단하기 위해 연결하는 방식"
188,NetWork,TLS/SSL,TLS/SSL HandShake 진행 순서,"1. 클라이언트는 서버에게 `client hello` 메시지를 담아 서버로 보낸다.
   이때 암호화된 정보를 함께 담는데, `버전`, `암호 알고리즘`, `압축 방식` 등을 담는다.

   <br>

2. 서버는 클라이언트가 보낸 암호 알고리즘과 압축 방식을 받고, `세션 ID`와 `CA 공개 인증서`를 `server hello` 메시지와 함께 담아 응답한다. 이 CA 인증서에는 앞으로 통신 이후 사용할 대칭키가 생성되기 전, 클라이언트에서 handshake 과정 속 암호화에 사용할 공개키를 담고 있다.

   <br>

3. 클라이언트 측은 서버에서 보낸 CA 인증서에 대해 유효한 지 CA 목록에서 확인하는 과정을 진행한다.

   <br>

4. CA 인증서에 대한 신뢰성이 확보되었다면, 클라이언트는 난수 바이트를 생성하여 서버의 공개키로 암호화한다. 이 난수 바이트는 대칭키를 정하는데 사용이 되고, 앞으로 서로 메시지를 통신할 때 암호화하는데 사용된다.

   <br>

5. 만약 2번 단계에서 서버가 클라이언트 인증서를 함께 요구했다면, 클라이언트의 인증서와 클라이언트의 개인키로 암호화된 임의의 바이트 문자열을 함께 보내준다.

   <br>

6. 서버는 클라이언트의 인증서를 확인 후, 난수 바이트를 자신의 개인키로 복호화 후 대칭 마스터 키 생성에 활용한다.

   <br>

7. 클라이언트는 handshake 과정이 완료되었다는 `finished` 메시지를 서버에 보내면서, 지금까지 보낸 교환 내역들을 해싱 후 그 값을 대칭키로 암호화하여 같이 담아 보내준다.

   <br>

8. 서버도 동일하게 교환 내용들을 해싱한 뒤 클라이언트에서 보내준 값과 일치하는 지 확인한다. 일치하면 서버도 마찬가지로  `finished` 메시지를 이번에 만든 대칭키로 암호화하여 보낸다.

   <br>

9. 클라이언트는 해당 메시지를 대칭키로 복호화하여 서로 통신이 가능한 신뢰받은 사용자란 걸 인지하고, 앞으로 클라이언트와 서버는 해당 대칭키로 데이터를 주고받을 수 있게 된다.
"
189,NetWork,로드밸런싱,로드밸런싱이란?,"> 둘 이상의 CPU or 저장장치와 같은 컴퓨터 자원들에게 작업을 나누는 것

<br>

요즘 시대에는 웹사이트에 접속하는 인원이 급격히 늘어나게 되었다.

따라서 이 사람들에 대해 모든 트래픽을 감당하기엔 1대의 서버로는 부족하다. 대응 방안으로 하드웨어의 성능을 올리거나(Scale-up) 여러대의 서버가 나눠서 일하도록 만드는 것(Scale-out)이 있다. 하드웨어 향상 비용이 더욱 비싸기도 하고, 서버가 여러대면 무중단 서비스를 제공하는 환경 구성이 용이하므로 Scale-out이 효과적이다. 이때 여러 서버에게 균등하게 트래픽을 분산시켜주는 것이 바로 **로드 밸런싱**이다.

<br>

**로드 밸런싱**은 분산식 웹 서비스로, 여러 서버에 부하(Load)를 나누어주는 역할을 한다. Load Balancer를 클라이언트와 서버 사이에 두고, 부하가 일어나지 않도록 여러 서버에 분산시켜주는 방식이다. 서비스를 운영하는 사이트의 규모에 따라 웹 서버를 추가로 증설하면서 로드 밸런서로 관리해주면 웹 서버의 부하를 해결할 수 있다."
190,NetWork,로드밸런싱,로드밸런서가 서버를 선택하는 방식,"- 라운드 로빈(Round Robin) : CPU 스케줄링의 라운드 로빈 방식 활용
- Least Connections : 연결 개수가 가장 적은 서버 선택 (트래픽으로 인해 세션이 길어지는 경우 권장)
- Source : 사용자 IP를 해싱하여 분배 (특정 사용자가 항상 같은 서버로 연결되는 것 보장)"
191,NetWork,로드밸런싱,로드밸런서 서버 장애 대비,"서버를 분배하는 로드 밸런서에 문제가 생길 수 있기 때문에 로드 밸런서를 이중화하여 대비한다.

> Active 상태와 Passive 상태"
192,NetWork,Blocking I/O & Non-Blocking I/O,Blocking I/O," I/O Blocking 형태의 작업은 

   (1) Process(Thread)가 Kernel에게 I/O를 요청하는 함수를 호출

   (2) Kernel이 작업을 완료하면 작업 결과를 반환 받음.

   

   * 특징
     * I/O 작업이 진행되는 동안 user Process(Thread) 는 자신의 작업을 중단한 채 대기
     * Resource 낭비가 심함 <br>(I/O 작업이 CPU 자원을 거의 쓰지 않으므로)

   <br>

   `여러 Client 가 접속하는 서버를 Blocking 방식으로 구현하는 경우` -> I/O 작업을 진행하는 작업을 중지 -> 다른 Client가 진행중인 작업을 중지하면 안되므로, client 별로 별도의 Thread를 생성해야 함 -> 접속자 수가 매우 많아짐

   이로 인해, 많아진 Threads 로 *컨텍스트 스위칭 횟수가 증가함,,, 비효율적인 동작 방식*"
193,NetWork,Blocking I/O & Non-Blocking I/O,Non-Blocking I/O," I/O 작업이 진행되는 동안 User Process의 작업을 중단하지 않음. 

   * 진행 순서

     1. User Process가 recvfrom 함수 호출 (커널에게 해당 Socket으로부터 data를 받고 싶다고 요청함)

     2. Kernel은 이 요청에 대해서, 곧바로 recvBuffer를 채워서 보내지 못하므로, ""EWOULDBLOCK""을 return함.

     3. Blocking 방식과 달리, User Process는 다른 작업을 진행할 수 있음.

     4. recvBuffer에 user가 받을 수 있는 데이터가 있는 경우, Buffer로부터 데이터를 복사하여 받아옴.

        > 이때, recvBuffer는 Kernel이 가지고 있는 메모리에 적재되어 있으므로, Memory간 복사로 인해, I/O보다 훨씬 빠른 속도로 data를 받아올 수 있음.

     5. recvfrom 함수는 빠른 속도로 data를 복사한 후, 복사한 data의 길이와 함께 반환함."
194,NetWork,Blocking I/O & Non-Blocking I/O & Synchronous/Asynchronous,Synchronous/Asynchronous,"동기/비동기는 일을 수행 중인 `동시성`에 주목하자

함수 A, B가 있고, A 안에서 B를 호출했다고 가정해보자. 이때 호출한 함수는 A고, 호출된 함수는 B가 된다. B의 수행 결과나 종료 상태를 A가 신경쓰고 있는 유무의 차이라고 생각하면 된다.

- **Synchronous** : 함수 A는 함수 B가 일을 하는 중에 기다리면서, 현재 상태가 어떤지 계속 체크한다. 
- **Asynchronous** : 함수 B의 수행 상태를 B 혼자 직접 신경쓰면서 처리한다. (Callback)

즉, 호출된 함수(B)를 호출한 함수(A)가 신경쓰는지, 호출된 함수(B) 스스로 신경쓰는지를 동기/비동기라고 생각하면 된다.

비동기는 호출시 Callback을 전달하여 작업의 완료 여부를 호출한 함수에게 답하게 된다. (Callback이 오기 전까지 호출한 함수는 신경쓰지 않고 다른 일을 할 수 있음)"
195,NetWork,Blocking I/O & Non-Blocking I/O & Synchronous/Asynchronous,Synchronous/Asynchronous 예시,"```
상황 : 치킨집에 직접 치킨을 사러감
```

<br>

### 1) Blocking & Synchronous

```
나 : 사장님 치킨 한마리만 포장해주세요
사장님 : 네 금방되니까 잠시만요!
나 : 넹
-- 사장님 치킨 튀기는 중--
나 : (아 언제 되지?..궁금한데 그냥 멀뚱히 서서 치킨 튀기는거 보면서 기다림)
```

<br>

### 2) Blocking & Asynchronous

```
나 : 사장님 치킨 한마리만 포장해주세요
사장님 : 네 금방되니까 잠시만요!
나 : 앗 넹
-- 사장님 치킨 튀기는 중--
나 : (언제 되는지 안 궁금함, 잠시만이래서 다 될때까지 서서 붙잡힌 상황)
```

<br>

### 3) Non-blocking & Synchronous

```
나 : 사장님 치킨 한마리만 포장해주세요
사장님 : 네~ 주문 밀려서 시간 좀 걸리니까 볼일 보시다 오세요
나 : 넹
-- 사장님 치킨 튀기는 중--
(5분뒤) 나 : 제꺼 나왔나요?
사장님 : 아직이요
(10분뒤) 나 : 제꺼 나왔나요?
사장님 : 아직이요ㅠ
(15분뒤) 나 : 제꺼 나왔나요?
사장님 : 아직이요ㅠㅠ
```

<br>

### 4) Non-blocking & Asynchronous

```
나 : 사장님 치킨 한마리만 포장해주세요
사장님 : 네~ 주문 밀려서 시간 좀 걸리니까 볼일 보시다 오세요
나 : 넹
-- 사장님 치킨 튀기는 중--
나 : (앉아서 다른 일 하는 중)
...
사장님 : 치킨 나왔습니다
나 : 잘먹겠습니다~
```"
196,SoftWare Engineering,클린코드 & 리펙토링,클린코드란?,"클린코드란, 가독성이 높은 코드를 말한다.

가독성을 높이려면 다음과 같이 구현해야 한다.

- 네이밍이 잘 되어야 함
- 오류가 없어야 함
- 중복이 없어야 함
- 의존성을 최대한 줄여야 함
- 클래스 혹은 메소드가 한가지 일만 처리해야 함

<br>

얼마나 **코드가 잘 읽히는 지, 코드가 지저분하지 않고 정리된 코드인지**를 나타내는 것이 바로 '클린 코드'

```java
public int AAA(int a, int b){
    return a+b;
}
public int BBB(int a, int b){
    return a-b;
}
```

<br>

두 가지 문제점이 있다.

<br>

```java
public int sum(int a, int b){
    return a+b;
}

public int sub(int a, int b){
    return a-b;
}
```

첫째는 **함수 네이밍**이다. 다른 사람들이 봐도 무슨 역할을 하는 함수인 지 알 수 있는 이름을 사용해야 한다.

둘째는 **함수와 함수 사이의 간격**이다. 여러 함수가 존재할 때 간격을 나누지 않으면 시작과 끝을 구분하는 것이 매우 힘들다.
"
197,SoftWare Engineering,클린코드 & 리펙토링,리펙토링이란?,"프로그램의 외부 동작은 그대로 둔 채, 내부의 코드를 정리하면서 개선하는 것을 말함

```
이미 공사가 끝난 집이지만, 더 튼튼하고 멋진 집을 만들기 위해 내부 구조를 개선하는 리모델링 작업
```

<br>

프로젝트가 끝나면, 지저분한 코드를 볼 때 가독성이 떨어지는 부분이 존재한다. 이 부분을 개선시키기 위해 필요한 것이 바로 '리팩토링 기법'

리팩토링 작업은 코드의 가독성을 높이고, 향후 이루어질 유지보수에 큰 도움이 된다."
198,SoftWare Engineering,클린코드 & 리펙토링,리펙토링이 필요한 코드,"- 중복 코드
- 긴 메소드
- 거대한 클래스
- Switch 문
- 절차지향으로 구현한 코드

<br>

리팩토링의 목적은, 소프트웨어를 더 이해하기 쉽고 수정하기 쉽게 만드는 것

```
리팩토링은 성능을 최적화시키는 것이 아니다.
코드를 신속하게 개발할 수 있게 만들어주고, 코드 품질을 좋게 만들어준다.
```

이해하기 쉽고, 수정하기 쉬우면? → 개발 속도가 증가!"
199,SoftWare Engineering,클린코드 & 리펙토링,리펙토링이 필요한 상황,">  소프트웨어에 새로운 기능을 추가해야 할 때

```
명심해야할 것은, 우선 코드가 제대로 돌아가야 한다는 것. 리팩토링은 우선적으로 해야 할 일이 아님을 명심하자
```

<br>

객체지향 특징을 살리려면, switch-case 문을 적게 사용해야 함

(switch문은 오버라이드로 다 바꿔버리자)

<br>

# 리팩토링 예제

<br>

1번

```java
// 수정 전
public int getFoodPrice(int arg1, int arg2) {
    return arg1 * arg2;
}
```

함수명 직관적 수정, 변수명을 의미에 맞게 수정

```java
// 수정 후
public int getTotalFoodPrice(int price, int quantity) {
    return price * quantity;
}
```

<br>

2번

```java
// 수정 전
public int getTotalPrice(int price, int quantity, double discount) {
    return (int) ((price * quantity) * (price * quantity) * (discount /100));
}
```

`price * quantity`가 중복된다. 따로 변수로 추출하자

할인율을 계산하는 부분을 메소드로 따로 추출하자

할인율 함수 같은 경우는 항상 일정하므로 외부에서 건드리지 못하도록 private 선언

```java
// 수정 후
public int getTotalFoodPrice(int price, int quantity, double discount) {
    int totalPriceQuantity = price * quantity;
    return (int) (totalPriceQuantity - getDiscountPrice(discount, totalPriceQuantity))
}

private double getDiscountPrice(double discount, int totalPriceQuantity) {
    return totalPriceQuantity * (discount / 100);
}
```

<br>

이 코드를 한번 더 리팩토링 해보면?

<br>





3번

```java
// 수정 전
public int getTotalFoodPrice(int price, int quantity, double discount) {
	
    int totalPriceQuantity = price * quantity;
    return (int) (totalPriceQuantity - getDiscountPrice(discount, totalPriceQuantity))
}

private double getDiscountPrice(double discount, int totalPriceQuantity) {
    return totalPriceQuantity * (discount / 100);
}
```

<br>

totalPriceQuantity를 getter 메소드로 추출이 가능하다.

지불한다는 의미를 주기 위해 메소드 명을 수정해주자

<br>

```java
// 수정 후
public int getFoodPriceToPay(int price, int quantity, double discount) {
    
    int totalPriceQuantity = getTotalPriceQuantity(price, quantity);
    return (int) (totalPriceQuantity - getDiscountPrice(discount, totalPriceQuantity));
}

private double getDiscountPrice(double discount, int totalPriceQuantity) {
    return totalPriceQuantity * (discount / 100);
}

private int getTotalPriceQuantity(int price, int quantity) {
    return price * quantity;
}
```"
200,SoftWare Engineering,클린코드 & 리팩토링,클린코드와 리팩토링의 차이,"리팩토링이 더 큰 의미를 가진 것 같다. 클린 코드는 단순히 가독성을 높이기 위한 작업으로 이루어져 있다면, 리팩토링은 클린 코드를 포함한 유지보수를 위한 코드 개선이 이루어진다.

클린코드와 같은 부분은 설계부터 잘 이루어져 있는 것이 중요하고, 리팩토링은 결과물이 나온 이후 수정이나 추가 작업이 진행될 때 개선해나가는 것이 올바른 방향이다."
201,SoftWare Engineering,시큐어 코딩,시큐어 코딩이란?,"> 안전한 소프트웨어를 개발하기 위해, 소스코드 등에 존재할 수 있는 잠재적인 보안약점을 제거하는 것"
202,SoftWare Engineering,시큐어 코딩,보안 약점을 노려 발생하는 사고 사례,"- SQL 인젝션 취약점으로 개인유출 사고 발생
- URL 파라미터 조작 개인정보 노출
- 무작위 대입공격 기프트카드 정보 유출"
203,SoftWare Engineering,시큐어 코딩,SQL 인젝션 예,"- 안전하지 않은 코드

```
String query ""SELECT * FROM users WHERE userid = '"" + userid + ""'"" + ""AND password = '"" + password + ""'"";

Statement stmt = connection.createStatement();
ResultSet rs = stmt.executeQuery(query);
```

<br>

- 안전한 코드

```
String query = ""SELECT * FROM users WHERE userid = ? AND password = ?"";

PrepareStatement stmt = connection.prepareStatement(query);
stmt.setString(1, userid);
stmt.setString(2, password);
ResultSet rs = stmt.executeQuery();
```

적절한 검증 작업이 수행되어야 안전함

<br>

입력받는 값의 변수를 `$` 대신 `#`을 사용하면서 바인딩 처리로 시큐어 코딩이 가능하다."
204,SoftWare Engineering,TDD,TDD란?,"테스트가 개발을 이끌어 나간다.'

<br>
<br>
우리는 보통 개발할 때, 설계(디자인)를 한 이후 코드 개발과 테스트 과정을 거치게 된다.
<br>


![img](https://mblogthumb-phinf.pstatic.net/MjAxNzA2MjhfMTU0/MDAxNDk4NjA2NTAyNjU2.zKGh5ZuYgToTz6p1lWgMC_Xb30i7uU86Yh00N2XrpMwg.8b3X9cCS6_ijzWyXEiQFombsWM1J8FlU9LhQ2j0nanog.PNG.suresofttech/image.png?type=w800)


<br>
하지만 TDD는 기존 방법과는 다르게, 테스트케이스를 먼저 작성한 이후에 실제 코드를 개발하는 리팩토링 절차를 밟는다.
<br>


![img](https://mblogthumb-phinf.pstatic.net/MjAxNzA2MjhfMjE3/MDAxNDk4NjA2NTExNDgw.fp8XF9y__Kz75n86xknIPDthTHj9a8Q08ocIJIqMR6Ag.24jJa_8_T0Qj04P62FZbchqt8oTNXGFSLUItzMP95s8g.PNG.suresofttech/image.png?type=w800)
<br>
```
작가가 책을 쓰는 과정에 대해서 생각해보자.

책을 쓰기 전, 목차를 먼저 구성한다.
이후 목차에 맞는 내용을 먼저 구상한 뒤, 초안을 작성하고 고쳐쓰기를 반복한다.

목차 구성 : 테스트 코드 작성
초안 작성 : 코드 개발
고쳐 쓰기 : 코드 수정(리팩토링)
```
<br>


반복적인 '검토'와 '고쳐쓰기'를 통해 좋은 글이 완성된다. 이런 방법을 소프트웨어에 적용한 것이 TDD!

> 소프트웨어 또한 반복적인 테스트와 수정을 통해 고품질의 소프트웨어를 탄생시킬 수 있다.
"
205,SoftWare Engineering,TDD,TDD 장점,"작업과 동시에 테스트를 진행하면서 실시간으로 오류 파악이 가능함 ( 시스템 결함 방지 )

짧은 개발 주기를 통해 고객의 요구사항 빠르게 수용 가능. 피드백이 가능하고 진행 상황 파악이 쉬움

자동화 도구를 이용한 TDD 테스트케이스를 단위 테스트로 사용이 가능함

(자바는 JUnit, C와 C++은 CppUnit 등)

개발자가 기대하는 앱의 동작에 관한 문서를 테스트가 제공해줌 <br>
`또한 이 테스트 케이스는 코드와 함께 업데이트 되므로 문서 작성과 거리가 먼 개발자에게 매우 좋음`"
206,SoftWare Engineering,TDD,TDD 단점,"기존 개발 프로세스에 테스트케이스 설계가 추가되므로 생산 비용 증가

테스트의 방향성, 프로젝트 성격에 따른 테스트 프레임워크 선택 등 추가로 고려할 부분의 증가
"
207,SoftWare Engineering,TDD,TDD 사용하는 이유,"TDD를 활용하면, 처음 시작하는 단계에서 테스트케이스를 설계하기 위한 초기 비용이 확실히 더 들게 된다. 하지만 개발 과정에 있어서 '초기 비용'보다 '유지보수 비용'이 더 클 수 있다는 것을 명심하자

또한 안전성이 필요한 소프트웨어 프로젝트에서는 개발 초기 단계부터 확실하게 다져놓고 가는 것이 중요하다. 

유지보수 비용이 더 크거나 비행기, 기차에 필요한 소프트웨어 등 안전성이 중요한 프로젝트의 경우 현재 실무에서도 TDD를 활용한 개발을 통해 이루어지고 있다."
208,SoftWare Engineering,애자일,애자일이란?,"<img src=""https://gmlwjd9405.github.io/images/what-is-agile/scrum-diagram.png"">

**'협력'과 '피드백'**을 더 자주하고, 일찍하고, 잘하는 것!

<br>

애자일의 핵심은 바로 '협력'과 '피드백'이다."
209,SoftWare Engineering,애자일,협력,"> 소프트웨어를 개발한 사람들 안에서의 협력을 말함(직무 역할을 넘어선 협력)

스스로 느낀 좋은 통찰은 협력을 통해 다른 사람에게도 전해줄 수 있음

예상치 못한 팀의 기대 효과를 가져옴

```
ex) 좋은 일은 x2가 된다.

어떤 사람이 2배의 속도로 개발할 수 있는 방법을 발견함

협력이 약하면? → 혼자만 좋은 보상과 칭찬을 받음. 하지만 그 사람 코드와 다른 사람의 코드의 이질감이 생겨서 시스템 문제 발생 가능성

협력이 강하면? → 다른 사람과 공유해서 모두 같이 빠르게 개발하고 더 나은 발전점을 찾기에 용이함. 팀 전체 개선이 일어나는 긍정적 효과 발생
```

```
ex) 안 좋은 일은 /2가 된다.

문제가 발생하는 부분을 찾기 쉬워짐
예상치 못한 문제를 협력으로 막을 수 있음

실수를 했는데 어딘지 찾기 힘들거나, 개선점이 생각나지 않을 때 서로 다른 사람들과 협력하면 새로운 방안이 탄생할 수도 있음"
210,SoftWare Engineering,애자일,피드백,"학습의 가장 큰 전제조건이 '피드백'. 내가 어떻게 했는지 확인하면서 학습을 진행해야 함

소프트웨어의 불확실성이 높을 수록 학습의 중요도는 올라간다.
**(모르는 게 많으면 더 빨리 배워나가야 하기 때문!!)**

<br>

일을 잘하는 사람은 이처럼 피드백을 찾는 능력 뛰어남. 더 많은 사람들에게 피드백을 구하고 발전시켜 나간다.

<br>

**피드백 진행 방법**

```
내부적으로는 내가 만든 것이 어떻게 됐는지 확인하고, 외부적으로는 내가 만든 것을 고객이나 다른 부서가 사용해보고 나온 산출물을 통해 또 다른 것을 배워나가는 것!
```"
211,SoftWare Engineering,애자일,불확실성,"애자일에서는 소프트웨어 개발의 불확실성이 중요함

불확실성이 높으면, `우리가 생각한거랑 다르다..`라는 상황에 직면한다.

이때 전통적인 방법론과 애자일의 방법론의 차이는 아래와 같다.

```
전통적 방법론 
: '그때 계획 세울 때 좀 더 잘 세워둘껄.. 
이런 리스크도 생각했어야 했는데ㅠ 일단 계속 진행하자'

애자일 방법론
: '이건 생각 못했네. 어쩔 수 없지. 다시 빨리 수정해보자'
```

<br>

전통적 방법에 속하는 '폭포수 모델'은 요구분석단계에서 한번에 모든 요구사항을 정확하게 전달하는 것이 원칙이다. 하지만 요즘같이 변화가 많은 프로젝트에서는 현실적으로 불가능에 가깝다.

<br>

이런 한계점을 극복해주는 애자일은, **개발 과정에 있어서 시스템 변경사항을 유연하게 or 기민하게 대응할 수 있도록 방법론을 제공**해준다.
"
212,SoftWare Engineering,애자일,진행방법,"1. 개발자와 고객 사이의 <u>지속적 커뮤니케이션을 통해 변화하는 요구사항을 수용</u>한다.
2. 고객이 결정한 사항을 가장 우선으로 시행하고, <u>개발자 개인의 가치보다 팀의 목표를 우선</u>으로 한다.
3. 팀원들과 <u>주기적인 미팅</u>을 통해 프로젝트를 점검한다.
4. 주기적으로 제품 시현을 하고 <u>고객으로부터 피드백</u>을 받는다.
5. 프로그램 품질 향상에 신경쓰며 간단한 내부 구조 형성을 통한 <u>비용절감을 목표</u>로 한다.

<br>

애자일을 통한 가장 많이 사용하는 개발 방법론이 **'스크럼'**

> 럭비 경기에서 사용되던 용어인데, 반칙으로 인해 경기가 중단됐을 때 쓰는 대형을 말함

즉, 소프트웨어 측면에서 `팀이라는 단어가 주는 의미를 적용시키고, 효율적인 성과를 얻기 위한 것`

<br>

<img src=""https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile21.uf.tistory.com%2Fimage%2F214EE04E58A2A65C155D51"">

<br>

1. #### 제품 기능 목록 작성

   > 개발할 제품에 대한 요구사항 목록 작성
   >
   > 우선순위가 매겨진, 사용자의 요구사항 목록이라고 말할 수 있음
   >
   > 개발 중에 수정이 가능하기는 하지만, **일반적으로 한 주기가 끝날 때까지는 제품 기능 목록을 수정하지 않는 것이 원칙**

2. #### 스프린트 Backlog

   > 스프린트 각각의 목표에 도달하기 위해 필요한 작업 목록
   >
   > - 세부적으로 어떤 것을 구현해야 하는지
   > - 작업자
   > - 예상 작업 시간
   >
   > 최종적으로 개발이 어떻게 진행되고 있는지 상황 파악 가능

3. #### 스프린트

   > `작은 단위의 개발 업무를 단기간 내에 전력질주하여 개발한다`
   >
   > 한달동안의 큰 계획을 **3~5일 단위로 반복 주기**를 정했다면 이것이 스크럼에서 스프린트에 해당함
   >
   > - 주기가 회의를 통해 결정되면 (보통 2주 ~ 4주) 목표와 내용이 개발 도중에 바뀌지 않아야 하고, 팀원들 동의 없이 바꿀 수 없는 것이 원칙

4. #### 일일 스크럼 회의

   > 몇가지 규칙이 있다.
   >
   > 모든 팀원이 참석하여 매일하고, 짧게(15분)하고, 진행 상황 점검한다.
   >
   > 한사람씩 어제 한 일, 오늘 할 일, 문제점 및 어려운 점을 이야기함
   >
   > 완료된 세부 작업 항목을 스프린트 현황판에서 업데이트 시킴

5. #### 제품완성 및 스프린트 검토 회의

   > 모든 스프린트 주기가 끝나면, 제품 기능 목록에서 작성한 제품이 완성된다.
   >
   > 최종 제품이 나오면 고객들 앞에서 시연을 통한 스프린트 검토 회의 진행
   >
   > - 고객의 요구사항에 얼마나 부합했는가?
   > - 개선점 및 피드백

6. #### 스프린트 회고

   > 스프린트에서 수행한 활동과 개발한 것을 되돌아보며 개선점이나 규칙 및 표준을 잘 준수했는지 검토
   >
   > `팀의 단점보다는 강점과 장점을 찾아 더 극대화하는데 초점을 둔다`"
213,SoftWare Engineering,애자일,스크럼 장점,"- 스프린트마다 생산되는 실행 가능한 제품을 통해 사용자와 의견을 나눌 수 있음
- 회의를 통해 팀원들간 신속한 협조와 조율이 가능
- 자신의 일정을 직접 발표함으로써 업무 집중 환경 조성
- 프로젝트 진행 현황을 통해 신속하게 목표와 결과 추정이 가능하며 변화 시도가 용이함"
214,SoftWare Engineering,애자일,스크럼 단점,"- 추가 작업 시간이 필요함 (스프린트마다 테스트 제품을 만들어야하기 때문)
- 15분이라는 회의 시간을 지키기 힘듬 ( 시간이 초과되면 그만큼 작업 시간이 줄어듬)
- 스크럼은 프로젝트 관리에 무게중심을 두기 때문에 프로세스 품질 평가에는 미약함"
215,SoftWare Engineering,객체지향 프로그래밍,객체지향 프로그래밍이란?,"보통 OOP라고 많이 부른다. 객체지향은 수 없이 많이 들어왔지만, 이게 뭔지 설명해달라고 하면 어디서부터 해야할 지 막막해진다.. 개념을 잡아보자

<br>

객체지향 패러다임이 나오기 이전의 패러다임들부터 간단하게 살펴보자. 

패러다임의 발전 과정을 보면 점점 개발자들이 **편하게 개발할 수 있도록 개선되는 방식**으로 나아가고 있는 걸 확인할 수 있다.

<br>

가장 먼저 **순차적, 비구조적 프로그래밍**이 있다.  말 그대로 순차적으로 코딩해나가는 것!

필요한 게 있으면 계속 순서대로 추가해가며 구현하는 방식이다. 직관적일 것처럼 생각되지만, 점점 규모가 커지게 되면 어떻게 될까?

이런 비구조적 프로그래밍에서는 **goto문을 활용**한다. 만약 이전에 작성했던 코드가 다시 필요하면 그 곳으로 이동하기 위한 것이다. 점점 규모가 커지면 goto문을 무분별하게 사용하게 되고, 마치 실뜨기를 하는 것처럼 베베 꼬이게 된다. (코드 안에서 위로 갔다가 아래로 갔다가..뒤죽박죽) 나중에 코드가 어떻게 연결되어 있는지 확인조차 하지 못하게 될 문제점이 존재한다.

> 이러면, 코딩보다 흐름을 이해하는 데 시간을 다 소비할 가능성이 크다

오늘날 수업을 듣거나 공부하면서 `goto문은 사용하지 않는게 좋다!`라는 말을 분명 들어봤을 것이다. goto문은 장기적으로 봤을 때 크게 도움이 되지 않는 구현 방식이기 때문에 그런 것이었다. 

<br>

이런 문제점을 해결하기 위해 탄생한 것이 바로 **절차적, 구조적 프로그래밍**이다. 이건 대부분 많이 들어본 패러다임일 것이다. 

**반복될 가능성이 있는 것들을 재사용이 가능한 함수(프로시저)로 만들어 사용**하는 프로그래밍 방식이다. 

여기서 보통 절차라는 의미는 함수(프로시저)를 뜻하고, 구조는 모듈을 뜻한다. 모듈이 함수보다 더 작은 의미이긴 하지만, 요즘은 큰 틀로 같은 의미로 쓰이고 있다. 
"
216,SoftWare Engineering,객체지향 프로그래밍,프로시저란?,"> 반환값(리턴)이 따로 존재하지 않는 함수를 뜻한다. 예를 들면, printf와 같은 함수는 반환값을 얻기 위한 것보단, 화면에 출력하는 용도로 쓰이는 함수다. 이와 같은 함수를 프로시저로 부른다.
>
> (정확히 말하면 printf는 int형을 리턴해주기는 함. 하지만 목적 자체는 프로시저에 가까움)

<br>

하지만 이런 패러다임도 문제점이 존재한다. 바로 `너무 추상적`이라는 것..

실제로 사용되는 프로그램들은 추상적이지만은 않다. 함수는 논리적 단위로 표현되지만, 실제 데이터에 해당하는 변수나 상수 값들은 물리적 요소로 되어있기 때문이다.

<br>

도서관리 프로그램이 있다고 가정해보자.

책에 해당하는 자료형(필드)를 구현해야 한다. 또한 책과 관련된 함수를 구현해야 한다. 구조적인 프로그래밍에서는 이들을 따로 만들어야 한다. 결국 많은 데이터를 만들어야 할 때, 구분하기 힘들고 비효율적으로 코딩할 가능성이 높아진다. 

> 책에 대한 자료형, 책에 대한 함수가 물리적으론 같이 있을 수 있지만 (같은 위치에 기록)
>
> 논리적으로는 함께할 수 없는 구조가 바로 `구조적 프로그래밍`

<br>

따라서, 이를 한번에 묶기 위한 패러다임이 탄생한다.

<br>

바로 **객체지향 프로그래밍**이다.

우리가 vo를 만들 때와 같은 형태다. 클래스마다 필요한 필드를 선언하고, getter와 setter로 구성된 모습으로 해결한다. 바로 **특정한 개념의 함수와 자료형을 함께 묶어서 관리하기 위해 탄생**한 것!

<br>

가장 중요한 점은, **객체 내부에 자료형(필드)와 함수(메소드)가 같이 존재하는 것**이다.

이제 도서관리 프로그램을 만들 때, 해당하는 책의 제목, 저자, 페이지와 같은 자료형과 읽기, 예약하기 등 메소드를 '책'이라는 객체에 한번에 묶어서 저장하는 것이 가능해졌다.

이처럼 가능한 모든 물리적, 논리적 요소를 객체로 만드려는 것이 `객체지향 프로그래밍`이라고 말할 수 있다.

 <br>

객체지향으로 구현하게 되면, 객체 간의 독립성이 생기고 중복코드의 양이 줄어드는 장점이 있다. 또한 독립성이 확립되면 유지보수에도 도움이 될 것이다."
217,SoftWare Engineering,객체지향 프로그래밍,객체지향 프로그래밍 특징,"객체지향의 패러다임이 생겨나면서 크게 4가지 특징을 갖추게 되었다.

이 4가지 특성을 잘 이해하고 구현해야 객체를 통한 효율적인 구현이 가능해진다.

<br>

1. **추상화(Abstraction)**

   > 필요로 하는 속성이나 행동을 추출하는 작업

   추상적인 개념에 의존하여 설계해야 유연함을 갖출 수 있다.

   즉, 세부적인 사물들의 공통적인 특징을 파악한 후 하나의 집합으로 만들어내는 것이 추상화다

   ```
   ex. 아우디, BMW, 벤츠는 모두 '자동차'라는 공통점이 있다.
   
   자동차라는 추상화 집합을 만들어두고, 자동차들이 가진 공통적인 특징들을 만들어 활용한다.
   ```

   ***'왜 필요하죠?'***

   예를 들면, '현대'와 같은 다른 자동차 브랜드가 추가될 수도 있다. 이때 추상화로 구현해두면 다른 곳의 코드는 수정할 필요 없이 추가로 만들 부분만 새로 생성해주면 된다.
   <br>

2. **캡슐화(Encapsulation)**

   > 낮은 결합도를 유지할 수 있도록 설계하는 것

   쉽게 말하면, **한 곳에서 변화가 일어나도 다른 곳에 미치는 영향을 최소화 시키는 것**을 말한다.

   (객체가 내부적으로 기능을 어떻게 구현하는지 감추는 것!)

   결합도가 낮도록 만들어야 하는 이유가 무엇일까? **결합도(coupling)란, 어떤 기능을 실행할 때 다른 클래스나 모듈에 얼마나 의존적인가를 나타내는 말**이다.

   즉, 독립적으로 만들어진 객체들 간의 의존도가 최대한 낮게 만드는 것이 중요하다. 객체들 간의 의존도가 높아지면 굳이 객체 지향으로 설계하는 의미가 없어진다.

   우리는 소프트웨어 공학에서 **객체 안의 모듈 간의 요소가 밀접한 관련이 있는 것으로 구성하여 응집도를 높이고 결합도를 줄여야 요구사항 변경에 대처하는 좋은 설계 방법**이라고 배운다.

   이것이 바로 `캡슐화`와 크게 연관된 부분이라고 할 수 있다.

   <br>


   그렇다면, 캡슐화는 어떻게 높은 응집도와 낮은 결합도를 갖게 할까?

   바로 **정보 은닉**을 활용한다.

   외부에서 접근할 필요가 없는 것들은 private으로 접근하지 못하도록 제한을 두는 것이다.

   (객체안의 필드를 선언할 때 private으로 선언하라는 말이 바로 이 때문!!)

   <br>

3. **상속**

   > 일반화 관계(Generalization)라고도 하며, 여러 개체들이 지닌 공통된 특성을 부각시켜 하나의 개념이나 법칙으로 성립하는 과정

   일반화(상속)은 또 다른 캡슐화다.

   **자식 클래스를 외부로부터 은닉하는 캡슐화의 일종**이라고 말할 수 있다.

   <br>

   아까 자동차를 통해 예를 들어 추상화를 설명했었다. 여기에 추가로 대리 운전을 하는 사람 클래스가 있다고 생각해보자. 이때, 자동차의 자식 클래스에 해당하는 벤츠, BMW, 아우디 등은 캡슐화를 통해 은닉해둔 상태다.
   <br>

   사람 클래스의 관점으로는, 구체적인 자동차의 종류가 숨겨져 있는 상태다. 대리 운전자 입장에서는 자동차의 종류가 어떤 것인지는 운전하는데 크게 중요하지 않다.

   새로운 자동차들이 추가된다고 해도, 사람 클래스는 영향을 받지 않는 것이 중요하다. 그러므로 캡슐화를 통해 사람 클래스 입장에서는 확인할 수 없도록 구현하는 것이다.

   <br>

   이처럼, 상속 관계에서는 단순히 하나의 클래스 안에서 속성 및 연산들의 캡슐화에 한정되지 않는다. 즉, 자식 클래스 자체를 캡슐화하여 '사람 클래스'와 같은 외부에 은닉하는 것으로 확장되는 것이다.

   이처럼 자식 클래스를 캡슐화해두면, 외부에선 이러한 클래스들에 영향을 받지 않고 개발을 이어갈 수 있는 장점이 있다.

   <br>

   ***상속 재사용의 단점***

   상속을 통한 재사용을 할 때 나타나는 단점도 존재한다.

   1) 상위 클래스(부모 클래스)의 변경이 어려워진다.

   > 부모 클래스에 의존하는 자식 클래스가 많을 때, 부모 클래스의 변경이 필요하다면?
   >
   > 이를 의존하는 자식 클래스들이 영향을 받게 된다.

   2) 불필요한 클래스가 증가할 수 있다.

   > 유사기능 확장시, 필요 이상의 불필요한 클래스를 만들어야 하는 상황이 발생할 수 있다.

   3) 상속이 잘못 사용될 수 있다.

   > 같은 종류가 아닌 클래스의 구현을 재사용하기 위해 상속을 받게 되면, 문제가 발생할 수 있다. 상속 받는 클래스가 부모 클래스와 IS-A 관계가 아닐 때 이에 해당한다.

   <br>

   ***해결책은?***

   객체 조립(Composition), 컴포지션이라고 부르기도 한다.

   객체 조립은, **필드에서 다른 객체를 참조하는 방식으로 구현**된다.

   상속에 비해 비교적 런타임 구조가 복잡해지고, 구현이 어려운 단점이 존재하지만 변경 시 유연함을 확보하는데 장점이 매우 크다. 

   따라서 같은 종류가 아닌 클래스를 상속하고 싶을 때는 객체 조립을 우선적으로 적용하는 것이 좋다.

   <br>

   ***그럼 상속은 언제 사용?***

   - IS-A 관계가 성립할 때
   - 재사용 관점이 아닌, 기능의 확장 관점일 때

   <br>

4. **다형성(Polymorphism)**

   > 서로 다른 클래스의 객체가 같은 메시지를 받았을 때 각자의 방식으로 동작하는 능력

   객체 지향의 핵심과도 같은 부분이다.

   다형성은, 상속과 함께 활용할 때 큰 힘을 발휘한다. 이와 같은 구현은 코드를 간결하게 해주고, 유연함을 갖추게 해준다.

   <br>


   즉, **부모 클래스의 메소드를 자식 클래스가 오버라이딩해서 자신의 역할에 맞게 활용하는 것이 다형성**이다.

   이처럼 다형성을 사용하면, 구체적으로 현재 어떤 클래스 객체가 참조되는 지는 무관하게 프로그래밍하는 것이 가능하다.

   상속 관계에 있으면, 새로운 자식 클래스가 추가되어도 부모 클래스의 함수를 참조해오면 되기 때문에 다른 클래스는 영향을 받지 않게 된다."
218,SoftWare Engineering,객체지향 프로그래밍,객체지향 설계 과정,"- 제공해야 할 기능을 찾고 세분화한다. 그리고 그 기능을 알맞은 객체에 할당한다.
- 기능을 구현하는데 필요한 데이터를 객체에 추가한다.
- 그 데이터를 이용하는 기능을 넣는다.
- 기능은 최대한 캡슐화하여 구현한다.
- 객체 간에 어떻게 메소드 요청을 주고받을 지 결정한다."
219,SoftWare Engineering,객체지향 프로그래밍,객체지향 설계 원칙,"SOLID라고 부르는 5가지 설계 원칙이 존재한다.

1. **SRP(Single Responsibility) - 단일 책임 원칙**

   클래스는 단 한 개의 책임을 가져야 한다.

   클래스를 변경하는 이유는 단 한개여야 한다.

   이를 지키지 않으면, 한 책임의 변경에 의해 다른 책임과 관련된 코드에 영향이 갈 수 있다.

   <br>

2. **OCP(Open-Closed) - 개방-폐쇄 원칙**

   확장에는 열려 있어야 하고, 변경에는 닫혀 있어야 한다.

   기능을 변경하거나 확장할 수 있으면서, 그 기능을 사용하는 코드는 수정하지 않는다.

   이를 지키지 않으면, instanceof와 같은 연산자를 사용하거나 다운 캐스팅이 일어난다.

   <br>

3. **LSP(Liskov Substitution) - 리스코프 치환 원칙**

   상위 타입의 객체를 하위 타입의 객체로 치환해도, 상위 타입을 사용하는 프로그램은 정상적으로 동작해야 한다.

   상속 관계가 아닌 클래스들을 상속 관계로 설정하면, 이 원칙이 위배된다.

   <br>

4. **ISP(Interface Segregation) - 인터페이스 분리 원칙**

   인터페이스는 그 인터페이스를 사용하는 클라이언트를 기준으로 분리해야 한다.

   각 클라이언트가 필요로 하는 인터페이스들을 분리함으로써, 각 클라이언트가 사용하지 않는 인터페이스에 변경이 발생하더라도 영향을 받지 않도록 만들어야 한다.

   <br>

5. **DIP(Dependency Inversion) - 의존 역전 원칙**

   고수준 모듈은 저수준 모듈의 구현에 의존해서는 안된다.

   저수준 모듈이 고수준 모듈에서 정의한 추상 타입에 의존해야 한다.

   즉, 저수준 모듈이 변경돼도 고수준 모듈은 변경할 필요가 없는 것이다."
220,SoftWare Engineering,함수형 프로그래밍,함수형 프로그래밍이란?,"> 순수 함수를 조합하고 공유 상태, 변경 가능한 데이터 및 부작용을 **피해** 소프트웨어를 만드는 프로세스

<br>

<img src=""https://user-images.githubusercontent.com/6733004/46247710-5ce5fb00-c44a-11e8-9400-16dd44626820.png"">

<br>

'선언형' 프로그래밍으로, 애플리케이션의 상태는 순수 함수를 통해 전달된다.

애플리케이션의 상태가 일반적으로 공유되고 객체의 메서드와 함께 배치되는 OOP와는 대조되는 프로그래밍 방식

<br>

- **명령형 프로그래밍(절차지향, 객체지향)**

  > 상태와 상태를 변경시키는 관점에서 연산을 설명하는 방식 
  >
  > 알고리즘을 명시하고, 목표는 명시하지 않음

- **선언형 프로그래밍**

  > How보다는 What을 설명하는 방식 (어떻게보단 무엇을)
  >
  > 알고리즘을 명시하지 않고 목표만 명시함

<br>

```
명령형 프로그래밍은 어떻게 할지 표현하고, 선언형 프로그래밍은 무엇을 할 건지 표현한다.
```

<br>

함수형 코드는 명령형 프로그래밍이나 OOP 코드보다 더 간결하고 예측가능하여 테스트하는 것이 쉽다.

(하지만 익숙치 않으면 더 복잡해보이고 이해하기 어려움)

<br>

함수형 프로그래밍은 프로그래밍 언어나 방식을 배우는 것이 아닌, 함수로 프로그래밍하는 사고를 배우는 것이다.

`기존의 사고방식을 전환하여 프로그래밍을 더 유연하게 문제해결 하도록 접근하는 것`"
221,SoftWare Engineering,함수형 프로그래밍,함수형 프로그래밍의 의미를 파악하기 전 꼭 알아야 할 것들,"- 순수 함수 (Pure functions)

  > 입출력이 순수해야함 : 반드시 하나 이상의 인자를 받고, 받은 인자를 처리해 반드시 결과물을 돌려줘야 함. 인자 외 다른 변수 사용 금지

- 합성 함수 (Function composition)

- 공유상태 피하기 (Avoid shared state)

- 상태변화 피하기 (Avoid mutating state)

- 부작용 피하기 (Avoid side effects)

  > 프로그래머가 바꾸고자 하는 변수 외에는 변경되면 안됨. 원본 데이터는 절대 불변!

<br>

대표적인 자바스크립트 함수형 프로그래밍 함수 : map, filter, reduce"
222,SoftWare Engineering,함수형 프로그래밍,함수형 프로그래밍 예,"```javascript
var arr = [1, 2, 3, 4, 5];
var map = arr.map(function(x) {
  return x * 2;
}); // [2, 4, 6, 8, 10]
```

arr을 넣어서 map을 얻었음. arr을 사용했지만 값은 변하지 않았고 map이라는 결과를 내고 어떠한 부작용도 낳지 않음

이런 것이 바로 함수형 프로그래밍의 순수함수라고 말한다.

<br>

```javascript
var arr = [1, 2, 3, 4, 5];
var condition = function(x) { return x % 2 === 0; }
var ex = function(array) {
  return array.filter(condition);
};
ex(arr); // [2, 4]
```

이는 순수함수가 아니다. 이유는 ex 메소드에서 인자가 아닌 condition을 사용했기 때문.

순수함수로 고치면 아래와 같다.

```javascript
var ex = function(array, cond) {
  return array.filter(cond);
};
ex(arr, condition);
```

순수함수로 만들면, 에러를 추적하는 것이 쉬워진다. 인자에 문제가 있거나 함수 내부에 문제가 있거나 둘 중 하나일 수 밖에 없기 때문이다.
"
223,SoftWare Engineering,함수형 프로그래밍,JAVA에서의 함수형 프로그래밍,"---
- 람다식
- stream api
- 함수형 인터페이스
Java 8이 릴리즈되면서, Java에서도 함수형 프로그래밍이 가능해졌다.

```
함수형 프로그래밍 : 부수효과를 없애고 순수 함수를 만들어 모듈화 수준을 높이는 프로그래밍 패러다임
```

부수효과 : 주어진 값 이외의 외부 변수 및 프로그래밍 실행에 영향을 끼치지 않아야 된다는 의미

최대한 순수함수를 지향하고, 숨겨진 입출력을 최대한 제거하여 코드를 순수한 입출력 관계로 사용하는 것이 함수형 프로그래밍의 목적이다.



Java의 객체 지향은 명령형 프로그래밍이고, 함수형은 선언형 프로그래밍이다.

둘의 차이는 `문제해결의 관점`

여태까지 우리는 Java에서 객체지향 프로그래밍을 할 때 '데이터를 어떻게 처리할 지에 대해 명령을 통해 해결'했다.

함수형 프로그래밍은 선언적 함수를 통해 '무엇을 풀어나가야할지 결정'하는 것이다."
224,SoftWare Engineering,데브옵스,데브옵스란?,"> Development + Operations의 합성어

소프트웨어 개발자와 정보기술 전문가 간의 소통, 협업 및 통합을 강조하는 개발 환경이나 문화를 의미한다.

<br>

**목적** : 소프트웨어 제품과 서비스를 빠른 시간에 개발 및 배포하는 것

<br>

결국, 소프트웨어 제품이나 서비스를 알맞은 시기에 출시하기 위해 개발과 운영이 상호 의존적으로 대응해야 한다는 의미로 많이 사용하고 있다.

<br>

<br>

데브옵스의 개념은 애자일 기법과 지속적 통합의 개념과도 관련이 있다."
225,SoftWare Engineering,써드 파티,써드 파티란?,"
> 하드웨어 생산자와 소프트웨어 개발자의 관계를 나타낼 때 사용한다.
>
> 그 중에서 **서드파티**는, 프로그래밍을 도와주는 라이브러리를 만드는 외부 생산자를 뜻한다.
>
> ```
>  ex) 게임제조사와 소비자를 연결해주는 게임회사(퍼플리싱)
>  스마일게이트와 같은 회사
> ```

<br>

- 하드웨어 생산자가 '직접' 소프트웨어를 개발하는 경우 : 퍼스트 파티 개발자
- 하드웨어 생산자인 기업과 자사간의 관계(또는 하청업체)에 속한 소프트웨어 개발자 : **세컨드 파티 개발자**
- 아무 관련없는 제3자 소프트웨어 개발자 : 서드 파티 개발자

<br>

주로 편한 개발을 위해 `플러그인`이나 `라이브러리` 혹은 `프레임워크`를 사용하는데, 이처럼 <u>제 3자로 중간다리 역할로 도움을 주는 것</u>이 **서드 파티**로 볼 수 있고, 이런 것을 만드는 개발자가 **서드 파티 개발자**다."
226,SoftWare Engineering,마이크로 서비스 아키텍처,마이크로 서비스 아키텍처란?,"```
MSA는 소프트웨어 개발 기법 중 하나로, 어플리케이션 단위를 '목적'으로 나누는 것이 핵심
```"
227,SoftWare Engineering,마이크로 서비스 아키텍처,Monolithic vs MSA ,"MSA가 도입되기 전, Monolithic 아키텍처 방식으로 개발이 이루어졌다. Monolithic의 사전적 정의에 맞게 '한 덩어리'에 해당하는 구조로 이루어져 있다. 모든 기능을 하나의 어플리케이션에서 비즈니스 로직을 구성해 운영한다. 따라서 개발을 하거나 환경설정에 있어서 간단한 장점이 있어 작은 사이즈의 프로젝트에서는 유리하지만, 시스템이 점점 확장되거나 큰 프로젝트에서는 단점들이 존재한다.

- 빌드/테스트 시간의 증가 : 하나를 수정해도 시스템 전체를 빌드해야 함. 즉, 유지보수가 힘들다
- 작은 문제가 시스템 전체에 문제를 일으킴 : 만약 하나의 서비스 부분에 트래픽 문제로 서버가 다운되면, 모든 서비스 이용이 불가능할 것이다.
- 확장성에 불리 : 서비스 마다 이용률이 다를 수 있다. 하나의 서비스를 확장하기 위해 전체 프로젝트를 확장해야 한다.

 <br>

MSA는 좀 더 세분화 시킨 아키텍처라고 말할 수 있다. 한꺼번에 비즈니스 로직을 구성하던 Monolithic 방식과는 다르게 기능(목적)별로 컴포넌트를 나누고 조합할 수 있도록 구축한다.

<img src=""https://www.redhat.com/cms/managed-files/monolithic-vs-microservices.png"">

<img src=""https://miro.medium.com/max/1250/1*V_mvV0mbfcBoCcirDgsvZw.png"">

<br>

MSA에서 각 컴포넌트는 API를 통해 다른 서비스와 통신을 하는데, 모든 서비스는 각각 독립된 서버로 운영하고 배포하기 때문에 서로 의존성이 없다. 하나의 서비스에 문제가 생겨도 다른 서비스에는 영향을 끼치지 않으며, 서비스 별로 부분적인 확장이 가능한 장점이 있다.

<img src=""http://clipsoft.co.kr/wp/wp-content/uploads/2020/06/leh_6.png"">

즉, 서비스 별로 개발팀이 꾸려지면 다른 팀과 의존없이 팀 내에서 피드백을 빠르게 할 수 있고, 비교적 유연하게 운영이 가능할 것이다.

좋은 점만 있지는 않다. MSA는 서비스 별로 호출할 때 API로 통신하므로 속도가 느리다. 그리고 서비스 별로 통신에 맞는 데이터로 맞추는 과정이 필요하기도 하다. Monolithic 방식은 하나의 프로세스 내에서 진행되기 때문에 속도 면에서는 MSA보다 훨씬 빠를 것이다. 또한, MSA는 DB 또한 개별적으로 운영되기 때문에 트랜잭션으로 묶기 힘든 점도 있다. 

<br>

따라서, 서비스별로 분리를 하면서 얻을 수 있는 장점도 있지만, 그만큼 체계적으로 준비돼 있지 않으면 MSA로 인해 오히려 프로젝트 성능이 떨어질 수도 있다는 점을 알고있어야 한다. 정답이 정해져 있는 것이 아니라, 프로젝트 목적, 현재 상황에 맞는 아키텍처 방식이 무엇인지 설계할 때부터 잘 고민해서 선택하자.
"
228,Web,브라우저,브라우저 주요 기능,"사용자가 선택한 자원을 서버에 요청, 브라우저에 표시

자원은 html 문서, pdf, image 등 다양한 형태

자원의 주소는 URI에 의해 정해짐

<br>

브라우저는 html과 css 명세에 따라 html 파일을 해석해서 표시함

이 '명세'는 웹 표준화 기구인 `W3C(World wide web Consortium)`에서 정해짐

> 예전 브라우저들은 일부만 명세에 따라 구현하고 독자적 방법으로 확장했음
>
> (결국 **심각한 호환성 문제** 발생... 그래서 요즘은 대부분 모두 표준 명세를 따름)

<br>

브라우저가 가진 인터페이스는 보통 비슷비슷한 요소들이 존재

> 시간이 지나면서, 사용자에게 필요한 서비스들로 서로 모방하며 갖춰지게 된 것

- URI 입력하는 주소 표시 줄
- 이전 버튼, 다음 버튼
- 북마크(즐겨찾기)
- 새로 고침 버튼
- 홈 버튼"
229,Web,브라우저,브라우저 기본 구조,"##### 사용자 인터페이스

주소 표시줄, 이전/다음 버튼, 북마크 등 사용자가 활용하는 서비스들
(요청한 페이지를 보여주는 창을 제외한 나머지 부분)

##### 브라우저 엔진

사용자 인터페이스와 렌더링 엔진 사이의 동작 제어

##### 렌더링 엔진

요청한 콘텐츠 표시 (html 요청이 들어오면? → html, css 파싱해서 화면에 표시)

##### 통신

http 요청과 같은 네트워크 호출에 사용
(플랫폼의 독립적인 인터페이스로 구성되어있음)

##### UI 백엔드

플랫폼에서 명시하지 않은 일반적 인터페이스. 콤보 박스 창같은 기본적 장치를 그림

##### 자바스크립트 해석기

자바스크립트 코드를 해석하고 실행

##### 자료 저장소

쿠키 등 모든 종류의 자원을 하드 디스크에 저장하는 계층"
230,Web,브라우저,렌더링이란?,"렌더링 엔진은 요청 받은 내용을 브라우저 화면에 표시해준다.

기본적으로 html, xml 문서와 이미지를 표시할 수 있음

추가로 플러그인이나 브라우저 확장 기능으로 pdf 등 다른 유형도 표시가 가능함

(추가로 확장이 필요한 유형은 바로 뜨지 않고 팝업으로 확장 여부를 묻는 것을 볼 수 있을 것임)"
231,Web,브라우저,렌더링 엔진 종류,"크롬, 사파리 : 웹킷(Webkit) 엔진 사용

파이어폭스 : 게코(Gecko) 엔진 사용"
232,Web,브라우저,렌더링 동작 과정,"```
먼저 html 문서를 파싱한다.

그리고 콘텐츠 트리 내부에서 태그를 모두 DOM 노드로 변환한다.

그 다음 외부 css 파일과 함께 포함된 스타일 요소를 파싱한다.

이 스타일 정보와 html 표시 규칙은 렌더 트리라고 부르는 또 다른 트리를 생성한다.

이렇게 생성된 렌더 트리는 정해진 순서대로 화면에 표시되는데, 생성 과정이 끝났을 때 배치가 진행되면서 노드가 화면의 정확한 위치에 표시되는 것을 의미한다.

이후에 UI 백엔드에서 렌더 트리의 각 노드를 가로지으며 형상을 만드는 그리기 과정이 진행된다.

이러한 과정이 점진적으로 진행되며, 렌더링 엔진은 좀더 빠르게 사용자에게 제공하기 위해 모든 html을 파싱할 때까지 기다리지 않고 배치와 그리기 과정을 시작한다. (마치 비동기처럼..?)

전송을 받고 기다리는 동시에 받은 내용을 먼저 화면에 보여준다
(우리가 웹페이지에 접속할 때 한꺼번에 뜨지 않고 점점 화면에 나오는 것이 이 때문!!!)
```"
233,Web,브라우저,DOM이란?,"Document Object Model(문서 객체 모델)

웹페이지 소스를 까보면 `<html>, <body>`와 같은 태그들이 존재한다. 이를 Javascript가 활용할 수 있는 객체로 만들면 `문서 객체`가 된다.

모델은 말 그대로, 모듈화로 만들었다거나 객체를 인식한다라고 해석하면 된다.

즉, **DOM은 웹 브라우저가 html 페이지를 인식하는 방식**을 말한다. (트리구조)"
234,Web,브라우저,웹킷이란?,"최초 리눅스 플랫폼에 동작하기 위한 오픈소스 엔진
(애플이 맥과 윈도우에서 사파리 브라우저를 지원하기 위해 수정을 더했음)"
235,Web,브라우저,파싱(parsing)이란?,"문서 파싱은, 브라우저가 코드를 이해하고 사용할 수 있는 구조로 변환하는 것

<br>

문서를 가지고, **어휘 분석과 구문 분석** 과정을 거쳐 파싱 트리를 구축한다.

조금 복잡한데, 어휘 분석기를 통해 언어의 구문 규칙에 따라 문서 구조를 분석한다. 이 과정에서 구문 규칙과 일치하는 지 비교하고, 일치하는 노드만 파싱 트리에 추가시킨다. 
(끝까지 규칙이 맞지 않는 부분은 문서가 유효하지 않고 구문 오류가 포함되어 있다는 것)

<br>

파서 트리가 나왔다고 해서 끝이 아니다.

컴파일의 과정일 뿐, 다시 기계코드 문서로 변환시키는 과정까지 완료되면 최종 결과물이 나오게 된다.

<br>

보통 이런 파서를 생성하는 것은 문법에 대한 규칙 부여 등 복잡하고 최적화하기 힘드므로, 자동으로 생성해주는 `파서 생성기`를 많이 활용한다.

>  웹킷은 플렉스(flex)나 바이슨(bison)을 이용하여 유용하게 파싱이 가능

<br>

우리가 head 태그를 실수로 빠뜨려도, 파서가 돌면서 오류를 수정해줌 ( head 엘리먼트 객체를 암묵적으로 만들어준다)

결국 이 파싱 과정을 거치면서 서버로부터 받은 문서를 브라우저가 이해하고 쉽게 사용할 수 있는 DOM 트리구조로 변환시켜주는 것이다!"
236,Web,쿠키 & 세션,쿠키와 세션의 비교,"#### 저장 위치

- 쿠키 : 클라이언트의 웹 브라우저가 지정하는 메모리 or 하드디스크
- 세션 : 서버의 메모리에 저장



#### 만료 시점

- 쿠키 : 저장할 때 expires 속성을 정의해 무효화시키면 삭제될 날짜 정할 수 있음
- 세션 : 클라이언트가 로그아웃하거나, 설정 시간동안 반응이 없으면 무효화 되기 때문에 정확한 시점 알 수 없음



#### 리소스

- 쿠키 : 클라이언트에 저장되고 클라이언트의 메모리를 사용하기 때문에 서버 자원 사용하지 않음
- 세션 : 세션은 서버에 저장되고, 서버 메모리로 로딩 되기 때문에 세션이 생길 때마다 리소스를 차지함



#### 용량 제한

- 쿠키 : 클라이언트도 모르게 접속되는 사이트에 의하여 설정될 수 있기 때문에 쿠키로 인해 문제가 발생하는 걸 막고자 한 도메인당 20개, 하나의 쿠키 당 4KB로 제한해 둠
- 세션 : 클라이언트가 접속하면 서버에 의해 생성되므로 개수나 용량 제한 없음"
237,Web,HTTP Request Methods,HTTP Request Methods란?,"```
클라이언트가 웹서버에게 요청하는 목적 및 그 종류를 알리는 수단을 말한다.
```

<br>

1. #### GET

   리소스(데이터)를 받기 위함

   URL(URI) 형식으로 서버 측에 리소스를 요청한다.

   <br>

2. #### HEAD

   메세지 헤더 정보를 받기 위함

   GET과 유사하지만, HEAD는 실제 문서 요청이 아닌 문서에 대한 정보 요청이다. 즉, Response 메세지를 받았을 때, Body는 비어있고, Header 정보만 들어있다.

   <br>

3. #### POST

   내용 및 파일 전송을 하기 위함

   클라이언트에서 서버로 어떤 정보를 제출하기 위해 사용한다. Request 데이터를 HTTP Body에 담아 웹 서버로 전송한다.

   <br>

4. #### PUT

   리소스(데이터)를 갱신하기 위함

   POST와 유사하나, 기존 데이터를 갱신할 때 사용한다.

   <br>

5. #### DELETE

   리소스(데이터)를 삭제하기 위함

   웹 서버측에 요청한 리소스를 삭제할 때 사용한다.

   > 실제로 클라이언트에서 서버 자원을 삭제하도록 하진 않아 비활성화로 구성한다.

   <br>

6. #### CONNECT

   클라이언트와 서버 사이의 중간 경유를 위함

   보통 Proxy를 통해 SSL 통신을 하고자할 때 사용한다.

   <br>

7. #### OPTIONS

   서버 측 제공 메소드에 대한 질의를 하기 위함

   웹 서버 측에서 지원하고 있는 메소드가 무엇인지 알기 위해 사용한다.

   <br>

8. #### TRACE

   Request 리소스가 수신되는 경로를 보기 위함

   웹 서버로부터 받은 내용을 확인하기 위해 loop-back 테스트를 할 때 사용한다.

   <br>

9. #### PATCH

   리소스(데이터)의 일부분만 갱신하기 위함

   PUT과 유사하나, 모든 데이터를 갱신하는 것이 아닌 리소스의 일부분만 수정할 때 쓰인다."
238,Web,HTTP status code,HTTP status code의 종류,"<br>

- 10x : 정보 확인
- 20x : 통신 성공
- 30x : 리다이렉트
- 40x : 클라이언트 오류
- 50x : 서버 오류

<br>

##### 200번대 : 통신 성공

| 상태코드 |    이름     |           의미           |
| :------: | :---------: | :----------------------: |
|   200    |     OK      |      요청 성공(GET)      |
|   201    |   Create    |     생성 성공(POST)      |
|   202    |  Accepted   | 요청 접수O, 리소스 처리X |
|   204    | No Contents |  요청 성공O, 내용 없음   |

<br>

##### 300번대 : 리다이렉트
| 상태코드 |       이름       |             의미              |
| :------: | :--------------: | :---------------------------: |
|   300    | Multiple Choice  | 요청 URI에 여러 리소스가 존재 |
|   301    | Move Permanently |  요청 URI가 새 위치로 옮겨감  |
|   304    |   Not Modified   |    요청 URI의 내용이 변경X    |

<br>

##### 400번대 : 클라이언트 오류

| 상태코드 |        이름        |               의미                |
| :------: | :----------------: | :-------------------------------: |
|   400    |    Bad Request     | API에서 정의되지 않은 요청 들어옴 |
|   401    |    Unauthorized    |             인증 오류             |
|   403    |     Forbidden      |        권한 밖의 접근 시도        |
|   404    |     Not Found      |   요청 URI에 대한 리소스 존재X    |
|   405    | Method Not Allowed | API에서 정의되지 않은 메소드 호출 |
|   406    |   Not Acceptable   |             처리 불가             |
|   408    |  Request Timeout   |        요청 대기 시간 초과        |
|   409    |      Conflict      |               모순                |
|   429    |  Too Many Request  |        요청 횟수 상한 초과        |

<br>

##### 500번대 : 서버 오류

| 상태코드 |         이름          |         의미         |
| :------: | :-------------------: | :------------------: |
|   500    | Internal Server Error |    서버 내부 오류    |
|   502    |      Bad Gateway      |   게이트웨이 오류    |
|   503    |  Service Unavailable  |   서비스 이용 불가   |
|   504    |    Gateway Timeout    | 게이트웨이 시간 초과 |"
239,Web,REST API,REST API란?,"REST : 웹 (HTTP) 의 장점을 활용한 아키텍쳐 

#### 1. REST (<u>RE</u>presentational <u>S</u>tate <u>T</u>ransfer) 기본

* REST의 요소

  * Method

    | Method | 의미   | Idempotent |
    | ------ | ------ | ---------- |
    | POST   | Create | No         |
    | GET    | Select | Yes        |
    | PUT    | Update | Yes        |
    | DELETE | Delete | Yes        |

    > Idempotent : 한 번 수행하냐, 여러 번 수행했을 때 결과가 같나?

    <br>

  * Resource

    * http://myweb/users와 같은 URI
    * 모든 것을 Resource (명사)로 표현하고, 세부 Resource에는 id를 붙임

    <br>

  * Message

    * 메시지 포맷이 존재

      : JSON, XML 과 같은 형태가 있음 (최근에는 JSON 을 씀)

      ```text
      HTTP POST, http://myweb/users/
      {
      	""users"" : {
      		""name"" : ""terry""
      	}
      }
      ```

    <br>

* REST 특징

  * Uniform Interface

    * HTTP 표준만 맞는다면, 어떤 기술도 가능한 Interface 스타일

      예) REST API 정의를 HTTP + JSON로 하였다면, C, Java, Python, IOS 플랫폼 등 특정 언어나 기술에 종속 받지 않고, 모든 플랫폼에 사용이 가능한 Loosely Coupling 구조

    * 포함
      * Self-Descriptive Messages

        * API 메시지만 보고, API를 이해할 수 있는 구조 (Resource, Method를 이용해 무슨 행위를 하는지 직관적으로 이해할 수 있음)

      * HATEOAS(Hypermedia As The Engine Of Application State)

        * Application의 상태(State)는 Hyperlink를 통해 전이되어야 함.
        * 서버는 현재 이용 가능한 다른 작업에 대한 하이퍼링크를 포함하여 응답해야 함.

      * Resource Identification In Requests

      * Resource Manipulation Through Representations

  * Statelessness

    * 즉, HTTP Session과 같은 컨텍스트 저장소에 **<u>상태 정보 저장 안함</u>**
    * **<u>Request만 Message로 처리</u>**하면 되고, 컨텍스트 정보를 신경쓰지 않아도 되므로, **<u>구현이 단순해짐</u>**.

    * 따라서, REST API 실행중 실패가 발생한 경우, Transaction 복구를 위해 기존의 상태를 저장할 필요가 있다. (POST Method 제외)

  * Resource 지향 아키텍쳐 (ROA : Resource Oriented Architecture)

    * Resource 기반의 복수형 명사 형태의 정의를 권장.
  
  * Client-Server Architecture
  
  * Cache Ability
  
  * Layered System
  
  * Code On Demand(Optional)"
240,Web,정적 페이지,정적 페이지(Static Pages)란?,"> 바뀌지 않는 페이지

웹 서버는 파일 경로 이름을 받고, 경로와 일치하는 file contents를 반환함

항상 동일한 페이지를 반환함"
241,Web,동적 페이지,동적페이지(Dynamic Pages)란?,"> 인자에 따라 바뀌는 페이지

인자의 내용에 맞게 동적인 contents를 반환함

웹 서버에 의해 실행되는 프로그램을 통해 만들어진 결과물임
(Servlet : was 위에서 돌아가는 자바 프로그램)

개발자는 Servlet에 doGet() 메소드를 구현함"
242,Web,"Web Server, WAS",Web Server와 WAS의 차이,"#### 웹 서버

개념에 있어서 하드웨어와 소프트웨어로 구분된다.

**하드웨어** : Web 서버가 설치되어 있는 컴퓨터

**소프트웨어** : 웹 브라우저 클라이언트로부터 HTTP 요청을 받고, 정적인 컨텐츠(html, css 등)를 제공하는 컴퓨터 프로그램

<br>

##### 웹 서버 기능

> Http 프로토콜을 기반으로, 클라이언트의 요청을 서비스하는 기능을 담당

요청에 맞게 두가지 기능 중 선택해서 제공해야 한다.

- 정적 컨텐츠 제공

  > WAS를 거치지 않고 바로 자원 제공

- 동적 컨텐츠 제공을 위한 요청 전달

  > 클라이언트 요청을 WAS에 보내고, WAS에서 처리한 결과를 클라이언트에게 전달

<br>

**웹 서버 종류** : Apache, Nginx, IIS 등

<br>

#### WAS

Web Application Server의 약자

>  DB 조회 및 다양한 로직 처리 요구시 **동적인 컨텐츠를 제공**하기 위해 만들어진 애플리케이션 서버

HTTP를 통해 애플리케이션을 수행해주는 미들웨어다.

**WAS는 웹 컨테이너 혹은 서블릿 컨테이너**라고도 불림

(컨테이너란 JSP, Servlet을 실행시킬 수 있는 소프트웨어. 즉, WAS는 JSP, Servlet 구동 환경을 제공해줌)

<br>

##### 역할

WAS = 웹 서버 + 웹 컨테이너

웹 서버의 기능들을 구조적으로 분리하여 처리하는 역할

> 보안, 스레드 처리, 분산 트랜잭션 등 분산 환경에서 사용됨 ( 주로 DB 서버와 함께 사용 )

<br>

##### WAS 주요 기능

1.프로그램 실행 환경 및 DB 접속 기능 제공

2.여러 트랜잭션 관리 기능

3.업무 처리하는 비즈니스 로직 수행

<br>

**WAS 종류** : Tomcat, JBoss 등

<br>

<br>

#### 그럼, 둘을 구분하는 이유는?

<br>

##### 웹 서버가 필요한 이유

웹 서버에서는 정적 컨텐츠만 처리하도록 기능 분배를 해서 서버 부담을 줄이는 것

```
클라이언트가 이미지 파일(정적 컨텐츠)를 보낼 때..

웹 문서(html 문서)가 클라이언트로 보내질 때 이미지 파일과 같은 정적 파일은 함께 보내지지 않음
먼저 html 문서를 받고, 이에 필요한 이미지 파일들을 다시 서버로 요청해서 받아오는 것

따라서 웹 서버를 통해서 정적인 파일을 애플리케이션 서버까지 가지 않고 앞단에 빠르게 보낼 수 있음!
```

<br>

##### WAS가 필요한 이유

WAS를 통해 요청에 맞는 데이터를 DB에서 가져와 비즈니스 로직에 맞게 그때마다 결과를 만들고 제공하면서 자원을 효율적으로 사용할 수 있음

```
동적인 컨텐츠를 제공해야 할때..

웹 서버만으로는 사용자가 원하는 요청에 대한 결과값을 모두 미리 만들어놓고 서비스하기에는 자원이 절대적으로 부족함

따라서 WAS를 통해 요청이 들어올 때마다 DB와 비즈니스 로직을 통해 결과물을 만들어 제공!
```

<br>

##### 그러면 WAS로 웹 서버 역할까지 다 처리할 수 있는거 아닌가요?

```
WAS는 DB 조회, 다양한 로직을 처리하는 데 집중해야 함. 따라서 단순한 정적 컨텐츠는 웹 서버에게 맡기며 기능을 분리시켜 서버 부하를 방지하는 것

만약 WAS가 정적 컨텐츠 요청까지 처리하면, 부하가 커지고 동적 컨텐츠 처리가 지연되면서 수행 속도가 느려짐 → 페이지 노출 시간 늘어나는 문제 발생
```

<br>

또한, 여러 대의 WAS를 연결지어 사용이 가능하다.

웹 서버를 앞 단에 두고, WAS에 오류가 발생하면 사용자가 이용하지 못하게 막아둔 뒤 재시작하여 해결할 수 있음 (사용자는 오류를 느끼지 못하고 이용 가능) 

<br>

자원 이용의 효율성 및 장애 극복, 배포 및 유지 보수의 편의성 때문에 웹 서버와 WAS를 분리해서 사용하는 것이다.

<br>

##### 가장 효율적인 방법

> 웹 서버를 WAS 앞에 두고, 필요한 WAS들을 웹 서버에 플러그인 형태로 설정하면 효율적인 분산 처리가 가능함

<br>

<img src=""https://gmlwjd9405.github.io/images/web/web-service-architecture.png"">

<br>

클라이언트의 요청을 먼저 웹 서버가 받은 다음, WAS에게 보내 관련된 Servlet을 메모리에 올림

WAS는 web.xml을 참조해 해당 Servlet에 대한 스레드를 생성 (스레드 풀 이용)

이때 HttpServletRequest와 HttpServletResponse 객체를 생성해 Servlet에게 전달

> 스레드는 Servlet의 service() 메소드를 호출
>
> service() 메소드는 요청에 맞게 doGet()이나 doPost() 메소드를 호출

doGet()이나 doPost() 메소드는 인자에 맞게 생성된 적절한 동적 페이지를 Response 객체에 담아 WAS에 전달

WAS는 Response 객체를 HttpResponse 형태로 바꿔 웹 서버로 전달

생성된 스레드 종료하고, HttpServletRequest와 HttpServletResponse 객체 제거"
243,Web,Oauth,Oauth(Open Authorization)란?,"인터넷 사용자들이 비밀번호를 제공하지 않고, 다른 웹사이트 상의 자신들의 정보에 대해 웹사이트나 애플리케이션의 접근 권한을 부여할 수있는 개방형 표준 방법
<br>
이러한 매커니즘은 구글, 페이스북, 트위터 등이 사용하고 있으며 타사 애플리케이션 및 웹사이트의 계정에 대한 정보를 공유할 수 있도록 허용해준다."
244,Web,Oauth,Oauth 사용 용어,"- **사용자** : 계정을 가지고 있는 개인
- **소비자** : OAuth를 사용해 서비스 제공자에게 접근하는 웹사이트 or 애플리케이션
- **서비스 제공자** : OAuth를 통해 접근을 지원하는 웹 애플리케이션
- **소비자 비밀번호** : 서비스 제공자에서 소비자가 자신임을 인증하기 위한 키
- **요청 토큰** : 소비자가 사용자에게 접근권한을 인증받기 위해 필요한 정보가 담겨있음
- **접근 토큰** : 인증 후에 사용자가 서비스 제공자가 아닌 소비자를 통해 보호 자원에 접근하기 위한 키 값

<br>

토큰 종류로는 Access Token과 Refresh Token이 있다.

Access Token은 만료시간이 있고 끝나면 다시 요청해야 한다. Refresh Token은 만료되면 아예 처음부터 진행해야 한다. "
245,Web,Oauth,Oauth 인증 과정,"> 소비자 <-> 서비스 제공자

1. 소비자가 서비스 제공자에게 요청토큰을 요청한다.
2. 서비스 제공자가 소비자에게 요청토큰을 발급해준다.
3. 소비자가 사용자를 서비스제공자로 이동시킨다. 여기서 사용자 인증이 수행된다.
4. 서비스 제공자가 사용자를 소비자로 이동시킨다.
5. 소비자가 접근토큰을 요청한다.
6. 서비스제공자가 접근토큰을 발급한다.
7. 발급된 접근토큰을 이용해서 소비자에서 사용자 정보에 접근한다."
246,Web,JWT,JWT (JSON Web Token)란?,"```
JSON Web Tokens are an open, industry standard [RFC 7519]
method for representing claims securely between two parties.
출처 : https://jwt.io
```
JWT는 웹표준(RFC 7519)으로서 두 개체에서 JSON 객체를 사용하여 가볍고 자가수용적인 방식으로 정보를 안전성 있게 전달해줍니다."
247,Web,JWT,JWT 구성요소,"JWT는 `.` 을 구분자로 3가지의 문자열로 구성되어 있습니다.

aaaa.bbbbb.ccccc 의 구조로 앞부터 헤더(header), 내용(payload), 서명(signature)로 구성됩니다.

### 헤더 (Header)
헤더는 typ와 alg 두가지의 정보를 지니고 있습니다.
typ는 토큰의 타입을 지정합니다. JWT이기에 ""JWT""라는 값이 들어갑니다.
alg : 해싱 알고리즘을 지정합니다. 기본적으로 HMAC, SHA256, RSA가 사용되면 토큰을 검증 할 때 사용되는 signature부분에서 사용됩니다.
```
{
	""typ"" : ""JWT"",
	""alg"" : ""HS256""
}
```

### 정보(payload)
Payload 부분에는 토큰을 담을 정보가 들어있습니다. 정보의 한 조각을 클레임(claim)이라고 부르고, 이는 name / value의 한 쌍으로 이뤄져있습니다. 토큰에는 여러개의 클레임들을 넣을 수 있지만 너무 많아질경우 토큰의 길이가 길어질 수 있습니다.

클레임의 종류는 크게 세분류로 나누어집니다.
1. 등록된(registered) 클레임
등록된 클레임들은 서비스에서 필요한 정보들이 아닌, 토큰에 대한 정보들을 담기위하여 이름이 이미 정해진 클레임들입니다. 등록된 클레임의 사용은 모두 선택적(optional)이며, 이에 포함된 크레임 이름들은 다음과 같습니다.
- `iss` : 토큰 발급자 (issuer)
- `sub` : 토큰 제목 (subject)
- `aud` : 토큰 대상자 (audience)
- `exp` : 토큰의 만료시간(expiration), 시간은 NumericDate 형식으로 되어있어야 하며 언제나 현재 시간보다 이후로 설정되어 있어야 합니다.
- `nbf` : Not before을 의미하며, 토큰의 활성 날짜와 비슷한 개념입니다. 여기에도 NumericDate형식으로 날짜를 지정하며, 이 날짜가 지정하며, 이 날짜가 지나기 전까지는 토큰이 처리되지 않습니다.
- `iat` : 토큰이 발급된 시간(issued at), 이 값을 사용하여 토큰의 age가 얼마나 되었는지 판단 할 수 있습니다.
- `jti` : JWT의 고유 식별자로서, 주로 중복적인 처리를 방지하기 위하여 사용됩니다. 일회용 토큰에 사용하면 유용합니다.

2. 공개(public) 클레임
공개 클레임들은 충돌이 방지된(collision-resistant)이름을 가지고 있어야 합니다. 충돌을 방지하기 위해서는, 클레임 이름을 URI형식으로 짓습니다.
```
{
	""https://chup.tistory.com/jwt_claims/is_admin"" : true
}
```
3. 비공개(private) 클레임
등록된 클레임도 아니고, 공개된 클레임들도 아닙니다. 양 측간에(보통 클라이언트 <-> 서버) 합의하에 사용되는 클레임 이름들입니다. 공개 클레임과는 달리 이름이 중복되어 충돌이 될 수 있으니 사용할때에 유의해야합니다.

### 서명(signature)
서명은 헤더의 인코딩값과 정보의 인코딩값을 합친후 주어진 비밀키로 해쉬를 하여 생성합니다.
이렇게 만든 해쉬를 `base64`형태로 나타내게 됩니다."
248,Web,JWT,로그인 인증 시 JWT 사용,"만약 유효기간이 짧은 Token을 발급하게되면 사용자 입장에서 자주 로그인을 해야하기 때문에 번거롭고 반대로 유효기간이 긴 Token을 발급하게되면 제 3자에게 토큰을 탈취당할 경우 보안에 취약하다는 약점이 있습니다.
그 점들을 보완하기 위해 **Refresh Token** 을 사용하게 되었습니다.
Refresh Token은 Access Token과 똑같은 JWT입니다. Access Token의 유효기간이 만료되었을 때, Refresh Token이 새로 발급해주는 열쇠가 됩니다.
예를 들어, Refresh Token의 유효기간은 1주, Access Token의 유효기간은 1시간이라고 한다면, 사용자는 Access Token으로 1시간동안 API요청을 하다가 시간이 만료되면 Refresh Token을 이용하여 새롭게 발급해줍니다.
이 방법또한 Access Token이 탈취당한다해도 정보가 유출이 되는걸 막을 수 없지만, 더 짧은 유효기간때문에 탈취되는 가능성이 적다는 점을 이용한 것입니다.
Refresh Token또한 유효기간이 만료됐다면, 사용자는 새로 로그인해야 합니다. Refresh Token도 탈취 될 가능성이 있기 때문에 적절한 유효기간 설정이 필요합니다."
249,Web,JWT,Access Token + Refresh Token 인증 과정,"<img src=""https://static.packt-cdn.com/products/9781784395407/graphics/B03653_08_02.jpg"">"
250,Web,Authentication and Authorization,API Key 인증 방식,"## API Key
서비스들이 거대해짐에 따라 기능들을 분리하기 시작하였는데 이를위해 Module이나 Application들간의 공유와 독립성을 보장하기 위한 기능들이 등장하기 시작했다.
그 중 제일 먼저 등장하고 가장 널리 보편적으로 쓰이는 기술이 API Key이다.

### 동작방식
1. 사용자는 API Key를 발급받는다. (발급 받는 과정은 서비스들마다 다르다. 예를들어 공공기관 API같은 경우에는 신청에 필요한 양식을 제출하면 관리자가 확인 후 Key를 발급해준다.
2. 해당 API를 사용하기 위해 Key와 함께 요청을 보낸다.
3. Application은 요청이 오면 Key를 통해 User정보를 확인하여 누구의 Key인지 권한이 무엇인지를 확인한다.
4. 해당 Key의 인증과 인가에 따라 데이터를 사용자에게 반환한다.

### 문제점
API Key를 사용자에게 직접 발급하고 해당 Key를 통해 통신을 하기 때문에 통신구간이 암호화가 잘 되어 있더라도 Key가 유출된 경우에 대비하기 힘들다.
그렇기때문에 주기적으로 Key를 업데이트를 해야하기 때문에 번거롭고 예기치 못한 상황(한쪽만 업데이트가 실행되어 서로 매치가 안된다는 등)이 발생할 수 있다. 또한, Key한가지로 정보를 제어하기 때문에 보안문제가 발생하기 쉬운편이다."
251,Web,Authentication and Authorization,OAuth2 인증 방식,"## OAuth2
API Key의 단점을 메꾸기 위해 등작한 방식이다. 대표적으로 페이스북, 트위터 등 SNS 로그인기능에서 쉽게 볼 수 있다. 요청하고 요청받는 단순한 방식이 아니라 인증하는 부분이 추가되어 독립적으로 세분화가 이루어졌다.

### 동작방식
1. 사용자가 Application의 기능을 사용하기 위한 요청을 보낸다. (로그인 기능, 특정 정보 열람 등 다양한 곳에서 쓰일 수 있다. 여기에서는 로그인으로 통일하여 설명하겠다.)
2. Application은 해당 사용자가 로그인이 되어 있는지를 확인한다. 로그인이 되어 있지 않다면 다음 단계로 넘어간다.
3. Application은 사용자가 로그인되어 있지 않으면 사용자를 인증서버로 Redirection한다.
4. 간접적으로 Authorize 요청을 받은 인증서버는 해당 사용자가 회원인지 그리고 인증서버에 로그인 되어있는지를 확인한다.
5. 인증을 거쳤으면 사용자가 최초의 요청에 대한 권한이 있는지를 확인한다. 이러한 과정을 Grant라고 하는데 대체적으로 인증서버는 사용자의 의지를 확인하는 Grant처리를 하게 되고, 각 Application은 다시 권한을 관리 할 수도 있다. 이 과정에서 사용자의 Grant가 확인이 되지않으면 다시 사용자에게 Grant요청을 보낸다.
> *Grant란?*
> Grant는 인가와는 다른 개념이다. 인가는 서비스 제공자 입장에서 사용자의 권한을 보는 것이지만, Grant는 사용자가 자신의 인증정보(보통 개인정보에 해당하는 이름, 이메일 등)를 Application에 넘길지 말지 결정하는 과정이다.
6. 사용자가 Grant요청을 받게되면 사용자는 해당 인증정보에 대한 허가를 내려준다. 해당 요청을 통해 다시 인증서버에 인가 처리를 위해 요청을 보내게 된다.
7. 인증서버에서 인증과 인가에 대한 과정이 모두 완료되면 Application에게 인가코드를 전달해준다. 인증서버는 해당 인가코드를 자신의 저장소에 저장을 해둔다. 해당 코드는 보안을 위해 매우 짧은 기간동안만 유효하다.
8. 인가 코드는 짧은 시간 유지되기 떄문에 이제 Application은 해당 코드를 Request Token으로 사용하여 인증서버에 요청을 보내게된다.
9. 해당 Request Token을 받은 인증서버는 자신의 저장소에 저장한 코드(7번 과정)과 일치하지를 확인하고 긴 유효기간을 가지고 실제 리소스 접근에 사용하게 될 Access Token을 Application에게 전달한다.
10. 이제 Application은 Access Token을 통해 업무를 처리할 수 있다. 해당 Access Token을 통해 리소스 서버(인증서버와는 다름)에 요청을 하게된다. 하지만 이 과정에서도 리소스 서버는 바로 데이터를 전달하는 것이 아닌 인증서버에 연결하여 해당 토큰이 유효한지 확인을 거치게된다. 해당 토큰이 유효하다면 사용자는 드디어 요청한 정보를 받을 수 있다.

### 문제점
기존 API Key방식에 비해 좀 더 복잡한 구조를 가진다. 물론 많은 부분이 개선되었다.
하지만 통신에 사용하는 Token은 무의미한 문자열을 가지고 기본적으로 정해진 규칙없이 발행되기 때문에 증명확인 필요하다. 그렇기에 인증서버에 어떤 식이든 DBMS 접근이든 다른 API를 활용하여 접근하는 등의 유효성 확인 작업이 필요하다는 공증 여부 문제가 있다. 이러한 공증여부 문제뿐만 아니라 유효기간 문제도 있다."
252,Web,Authentication and Authorization,JWT 인증 방식,"## JWT
JWT는 JSON Web Token의 줄임말로 인증 흐름의 규약이 아닌 Token 작성에 대한 규약이다. 
기본적인 Access Token은 의미가 없는 문자열로 이루어져 있어 Token의 진위나 유효성을 매번 확인해야 하는 것임에 반하여, JWT는 인증여부 확인을 위한 값, 유효성 검증을 위한 값 그리고 인증 정보 자체를 담고 있기 때문에 인증서버에 묻지 않고도 사용할 수 있다.

### 문제점
서버에 직접 연결하여 인증을 학인하지 않아도 되기 때문에 생기는 장점들이 많다. 하지만 토큰 자체가 인증 정보를 가지고 있기때문에 민감한 정보는 인증서버에 다시 접속하는 과정이 필요하다."
253,Web,Logging Level,Logging Level란?,"보통 log4j 라이브러리를 활용한다.

크게 ERROR, WARN, INFO, DEBUG로 로그 레벨을 나누어 작성한다.

<br>

- #### ERROR

  에러 로그는, 프로그램 동작에 큰 문제가 발생했다는 것으로 즉시 문제를 조사해야 하는 것

  `DB를 사용할 수 없는 상태, 중요 에러가 나오는 상황`

  <br>

- #### WARN

  주의해야 하지만, 프로세스는 계속 진행되는 상태. 하지만 WARN에서도 2가지의 부분에선 종료가 일어남

  - 명확한 문제 : 현재 데이터를 사용 불가, 캐시값 사용 등
  - 잠재적 문제 : 개발 모드로 프로그램 시작, 관리자 콘솔 비밀번호가 보호되지 않고 접속 등

  <br>

- #### INFO

  중요한 비즈니스 프로세스가 시작될 때와 종료될 때를 알려주는 로그

  `~가 ~를 실행했음`

  <br>

- #### DEBUG

  개발자가 기록할 가치가 있는 정보를 남기기 위해 사용하는 레벨"
254,Web,UI,UI란?,"> User Interface

사용자가 앱을 사용할 때 마주하는 디자인, 레이아웃, 기술적인 부분이다.

디자인의 구성 요소인 폰트, 색깔, 줄간격 등 상세한 요소가 포함되고, 기술적 부분은 반응형이나 애니메이션효과 등이 포함된다.

따라서 UI는 사용자가 사용할 때 큰 불편함이 없어야하며, 만족도를 높여야 한다."
255,Web,UX,UX란?,"> User eXperience

앱을 주로 사용하는 사용자들의 경험을 분석하여 더 편하고 효율적인 방향으로 프로세스가 진행될 수 있도록 만드는 것이다.

(터치 화면, 사용자의 선택 flow 등)

UX는 통계자료, 데이터를 기반으로 앱을 사용하는 유저들의 특성을 분석하여 상황과 시점에 맞도록 변화시킬 수 있어야 한다."
256,Web,"CSR, SSR",CSR & SSR,"> CSR : Client Side Rendering
>
> SSR : Server Side Rendering

<br>

CSR에는 모바일 시대에 들어서 SPA가 등장했다.

##### SPA(Single Page Applictaion)

> 최초 한 번 페이지 전체를 로딩한 뒤, 데이터만 변경하여 사용할 수 있는 애플리케이션

SPA는 기본적으로 페이지 로드가 없고, 모든 페이지가 단순히 Html5 History에 의해 렌더링된다.

<br>

기존의 전통적 방법인 SSR 방식에는 성능 문제가 있었다.

요즘 웹에서 제공되는 정보가 워낙 많다. 요청할 때마다 새로고침이 일어나면서 페이지를 로딩할 때마다 서버로부터 리소스를 전달받아 해석하고, 화면에 렌더링하는 방식인 SSR은 데이터가 많을 수록 성능문제가 발생했다.

```
현재 주소에서 동일한 주소를 가리키는 버튼을 눌렀을 때,
설정페이지에서 필요한 데이터를 다시 가져올 수 없다.
```

이는, 인터랙션이 많은 환경에서 비효율적이다. 렌더링을 서버쪽에서 진행하면 그만큼 서버 자원이 많이 사용되기 때문에 불필요한 트래픽이 낭비된다.

<br>

CSR 방식은 사용자의 행동에 따라 필요한 부분만 다시 읽어온다. 따라서 서버 측에서 렌더링하여 전체 페이지를 다시 읽어들이는 것보다 빠른 인터렉션을 기대할 수 있다. 서버는 단지 JSON파일만 보내주고, HTML을 그리는 역할은 자바스크립트를 통해 클라이언트 측에서 수행하는 방식이다.

<br>

뷰 렌더링을 유저의 브라우저가 담당하고, 먼저 웹앱을 브라우저에게 로드한 다음 필요한 데이터만 전달받아 보여주는 CSR은 트래픽을 감소시키고, 사용자에게 더 나은 경험을 제공할 수 있도록 도와준다.

<br>

<br>

#### CSR 장단점

- ##### 장점

  - 트래픽 감소

    > 필요한 데이터만 받는다

  - 사용자 경험

    > 새로고침이 발생하지 않음. 사용자가 네이티브 앱과 같은 경험을 할 수 있음

- ##### 단점

  - 검색 엔진

    > 크롬에서 리액트로 만든 웹앱 소스를 확인하면 내용이 비어있음. 이처럼 검색엔진 크롤러가 데이터 수집에 어려움이 있을 가능성 존재
    >
    > 구글 검색엔진은 자바스크립트 엔진이 내장되어있지만, 네이버나 다음 등 검색엔진은 크롤링에 어려움이 있어 SSR을 따로 구현해야하는 번거로움 존재

<br>

#### SSR 장단점

- ##### 장점

  - 검색엔진 최적화

  - 초기로딩 성능개선

    > 첫 렌더링된 HTML을 클라이언트에서 전달해주기 때문에 초기로딩속도를 많이 줄여줌

- ##### 단점

  - 프로젝트 복잡도

    > 라우터 사용하다보면 복잡도가 높아질 수 있음

  - 성능 악화 가능성"
257,Web,"Vue.js, React",Vue.js와 React의 차이,"##### 개발 CLI

- Vue.js : vue-cli
- React : create-react-app

##### CSS 파일 존재 유무

- Vue.js : 없음. style이 실제 컴포넌트 파일 안에서 정의됨
- React : 파일이 존재. 해당 파일을 통해 style 적용

##### 데이터 변이

- Vue.js : 반드시 데이터 객체를 생성한 이후 data를 업데이트 할 수 있음
- React : state 객체를 만들고, 업데이트에 조금 더 작업이 필요

```
name: kim 값을 lee로 바꾸려면
Vue.js : this.name = 'lee'
React : this.setState({name:'lee'})
```

Vue에서는 data를 업데이트할 때마다 setState를 알아서 결합한다."
258,Web,Native App,Native App란?,"흔히 우리가 자주 사용하는 어플리케이션을 의미한다.

모바일 기기에 최적화된 언어로 개발된 앱으로 안드로이드 SDK를 이용한 Java 언어나 iOS 기반 SDK를 이용한 Swift 언어로 만드는 앱이 네이티브 앱에 속한다.

<br>

##### 장점

- 성능이 웹앱, 하이브리드 앱에 비해 가장 높음
- 네이티브 API를 호출하여 사용함으로 플랫폼과 밀착되어있음
- Java나 Swift에 익숙한 사용자면 쉽게 접근 가능함

##### 단점

- 플랫폼에 한정적
- 언어에 제약적"
259,Web,Mobile Wep App,Mobile Wep App란?,"모바일웹 + 네이티브 앱을 결합한 형태

모바일 웹의 특징을 가지면서도, 네이티브 앱의 장점을 지녔다. 따라서 기존의 모바일 웹보다는 모바일에 최적화 된 앱이라고 말할 수 있다.

웹앱은 SPA를 활용해 속도가 빠르다는 장점이 있다.

> 쉽게 말해, PC용 홈페이지를 모바일 스크린 크기에 맞춰 줄여 놓은 것이라고 생각하면 편함

<br>

##### 장점

- 웹 사이트를 보는 것이므로 따로 설치할 필요X
- 모든 기기와 브라우저에서 접근 가능
- 별도 설치 및 승인 과정이 필요치 않아 유지보수에 용이

##### 단점

- 플랫폼 API 사용 불가능. 오로지 브라우저 API만 사용가능
- 친화적 터치 앱을 개발하기 약간 번거로움
- 네이티브, 하이브리드 앱보다 실행 까다로움 (브라우저 열거 검색해서 들어가야함)"
260,Web,Hybrid App,Hybrid App란?,"> 네이티브 + 웹앱

네이티브 웹에, 웹 view를 띄워 웹앱을 실행시킨다. 양쪽의 API를 모두 사용할 수 있는 것이 가장 큰 장점

<br>

##### 장점

- 네이티브 API, 브라우저 API를 모두 활용한 다양한 개발 가능
- 웹 개발 기술로 앱 개발 가능
- 한번의 개발로 다수 플랫폼에서 사용 가능

##### 단점

- 네이티브 기능 접근 위해 개발 지식 필요
- UI 프레임도구 사용안하면 개발자가 직접 UI 제작"
261,Web,PWA,PWA (Progressive Web App)란?,"> 웹의 장점과 앱의 장점을 결합한 환경
>
> `앱 수준과 같은 사용자 경험을 웹에서 제공하는 것이 목적!`

<br>

#### 특징

확장성이 좋고, 깊이 있는 앱같은 웹을 만드는 것을 지향한다.

웹 주소만 있다면, 누구나 접근하여 사용이 가능하고 스마트폰의 저장공간을 잡아 먹지 않음

**서비스 작업자(Service Worker) API** : 웹앱의 중요한 부분을 캐싱하여 사용자가 다음에 열 때 빠르게 로딩할 수 있도록 도와줌

→ 네트워크 환경이 좋지 않아도 빠르게 구동되며, 사용자에게 푸시 알림을 보낼 수도 있음

<br>

#### PWA 제공 기능

- 프로그래시브 : 점진적 개선을 통해 작성돼서 어떤 브라우저든 상관없이 모든 사용자에게 적합
- 반응형 : 데스크톱, 모바일, 테블릿 등 모든 폼 factor에 맞음
- 연결 독립적 : 서비스 워커를 사용해 오프라인에서도 작동이 가능함
- 안전 : HTTPS를 통해 제공이 되므로 스누핑이 차단되어 콘텐츠가 변조되지 않음
- 검색 가능 : W3C 매니페스트 및 서비스 워커 등록 범위 덕분에 '앱'으로 식별되어 검색이 가능함
- 재참여 가능 : 푸시 알림과 같은 기능을 통해 쉽게 재참여가 가능함"
262,Web,CSRF,CSRF란?,"> Cross Site Request Forgery

웹 어플리케이션 취약점 중 하나로, 인터넷 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위 (modify, delete, register 등)를 특정한 웹사이트에 request하도록 만드는 공격을 말한다.

주로 해커들이 많이 이용하는 것으로, 유저의 권한을 도용해 중요한 기능을 실행하도록 한다. 

우리가 실생활에서 CSRF 공격을 볼 수 있는 건, 해커가 사용자의 SNS 계정으로 광고성 글을 올리는 것이다.

정확히 말하면, CSRF는 해커가 사용자 컴퓨터를 감염시거나 서버를 해킹해서 공격하는 것이 아니다. CSRF 공격은 아래와 같은 조건이 만족할 때 실행된다.

- 사용자가 해커가 만든 피싱 사이트에 접속한 경우
- 위조 요청을 전송하는 서비스에 사용자가 로그인을 한 상황

보통 자동 로그인을 해둔 경우에 이런 피싱 사이트에 접속하게 되면서 피해를 입는 경우가 많다. 또한, 해커가 XSS 공격을 성공시킨 사이트라면, 피싱 사이트가 아니더라도 CSRF 공격이 이루어질 수 있다.

<br>

#### 대응 기법

- ##### 리퍼러(Refferer) 검증

  백엔드 단에서 Refferer 검증을 통해 승인된 도메인으로 요청시에만 처리하도록 한다.

- ##### Security Token 사용

  사용자의 세션에 임의의 난수 값을 저장하고, 사용자의 요청시 해당 값을 포함하여 전송시킨다. 백엔드 단에서는 요청을 받을 때 세션에 저장된 토큰값과 요청 파라미터로 전달받는 토큰 값이 일치하는 지 검증 과정을 거치는 방법이다.

> 하지만, XSS에 취약점이 있다면 공격을 받을 수도 있다."
263,Web,XSS,XSS란?,"> Cross Site Scription

CSRF와 같이 웹 어플리케이션 취약점 중 하나로, 관리자가 아닌 권한이 없는 사용자가 웹 사이트에 스크립트를 삽입하는 공격 기법을 말한다.

악의적으로 스크립트를 삽입하여 이를 열람한 사용자의 쿠키가 해커에게 전송시키며, 이 탈취한 쿠키를 통해 세션 하이재킹 공격을 한다. 해커는 세션ID를 가진 쿠키로 사용자의 계정에 로그인이 가능해지는 것이다.

공격 종류로는 지속성, 반사형, DOM 기반 XSS 등이 있다.

- **지속성** : 말 그대로 지속적으로 피해를 입히는 유형으로, XSS 취약점이 존재하는 웹 어플리케이션에 악성 스크립트를 삽입하여 열람한 사용자의 쿠키를 탈취하거나 리다이렉션 시키는 공격을 한다. 이때 삽입된 스크립트를 데이터베이스에 저장시켜 지속적으로 공격을 하기 때문에 Persistent XSS라고 불린다.
- **반사형** : 사용자에게 입력 받은 값을 서버에서 되돌려 주는 곳에서 발생한다. 공격자는 악의 스크립트와 함께 URL을 사용자에게 누르도록 유도하고, 누른 사용자는 이 스크립트가 실행되어 공격을 당하게 되는 유형이다.
- **DOM 기반** : 악성 스크립트가 포함된 URL을 사용자가 요청하게 되면서 브라우저를 해석하는 단계에서 발생하는 공격이다. 이 스크립트로 인해 클라이언트 측 코드가 원래 의도와 다르게 실행된다. 이는 다른 XSS 공격과는 달리 서버 측에서 탐지가 어렵다.

<br>

#### 대응 기법

- ##### 입출력 값 검증

  XSS Cheat Sheet에 대한 필터 목록을 만들어 모든 Cheat Sheet에 대한 대응을 가능하도록 사전에 대비한다. XSS 필터링을 적용 후 스크립트가 실행되는지 직접 테스트 과정을 거쳐볼 수도 있다,

- ##### XSS 방어 라이브러리, 확장앱 

  Anti XSS 라이브러리를 제공해주는 회사들이 많다. 이 라이브러리는 서버단에서 추가하며, 사용자들은 각자 브라우저에서 악성 스크립트가 실행되지 않도록 확장앱을 설치하여 방어할 수 있다.

- ##### 웹 방화벽

  웹 방화벽은 웹 공격에 특화된 것으로, 다양한 Injection을 한꺼번에 방어할 수 있는 장점이 있다.

- ##### CORS, SOP 설정
  
  CORS(Cross-Origin Resource Sharing), SOP(Same-Origin-Policy)를 통해 리소스의 Source를 제한 하는것이 효과적인 방어 방법이 될 수 있다. 웹 서비스상 취약한 벡터에 공격 스크립트를 삽입 할 경우, 치명적인 공격을 하기 위해 스크립트를 작성하면 입력값 제한이나 기타 요인 때문에 공격 성공이 어렵다. 그러나 공격자의 서버에 위치한 스크립트를 불러 올 수 있다면 이는 상대적으로 쉬워진다. 그렇기 떄문에 CORS, SOP를 활용 하여 사전에 지정된 도메인이나 범위가 아니라면 리소스를 가져올 수 없게 제한해야 한다. "
264,Web,Spring,Spring Bean Scope란?,"Bean은 스프링에서 사용하는 POJO 기반 객체다.

상황과 필요에 따라 Bean을 사용할 때 하나만 만들어야 할 수도 있고, 여러개가 필요할 때도 있고, 어떤 한 시점에서만 사용해야할 때가 있을 수 있다.

이를 위해 Scope를 설정해서 Bean의 사용 범위를 개발자가 설정할 수 있다.

<br>

우선 따로 설정을 해주지 않으면, Spring에서 Bean은 `Singleton`으로 생성된다. 싱글톤 패턴처럼 특정 타입의 Bean을 딱 하나만 만들고 모두 공유해서 사용하기 위함이다. 보통은 Bean을 이렇게 하나만 만들어 사용하는 경우가 대부분이지만, 요구사항이나 구현에 따라 아닐 수도 있을 것이다.

따라서 Bean Scope는 싱글톤 말고도 여러가지를 지원해준다.

<br>

### Scope 종류

- #### singleton

  해당 Bean에 대해 IoC 컨테이너에서 단 하나의 객체로만 존재한다.

- #### prototype

  해당 Bean에 대해 다수의 객체가 존재할 수 있다.

- #### request

  해당 Bean에 대해 하나의 HTTP Request의 라이프사이클에서 단 하나의 객체로만 존재한다.

- #### session

  해당 Bean에 대해 하나의 HTTP Session의 라이프사이클에서 단 하나의 객체로만 존재한다.

- #### global session

  해당 Bean에 대해 하나의 Global HTTP Session의 라이프사이클에서 단 하나의 객체로만 존재한다.

> request, session, global session은 MVC 웹 어플리케이션에서만 사용함

<br>

Scope들은 Bean으로 등록하는 클래스에 어노테이션으로 설정해줄 수 있다.

```java
import org.springframework.context.annotation.Scope;
import org.springframework.stereotype.Service;
 
@Scope(""prototype"")
@Component
public class UserController {
}
```"
265,Web,Spring,Spring MVC Framework란?,"<img src=""https://media.vlpt.us/images/miscaminos/post/80555c98-2846-4774-9b27-9746336f3dce/springMVC_Dispatcher_centered.jpg"">

클라이언트가 서버에게 url을 통해 요청할 때 일어나는 스프링 프레임워크의 동작을 그림으로 표현한 것이다.

<br>

### MVC 진행 과정

----

- 클라이언트가 url을 요청하면, 웹 브라우저에서 스프링으로 request가 보내진다.
- `Dispatcher Servlet`이 request를 받으면, `Handler Mapping`을 통해 해당 url을 담당하는 Controller를 탐색 후 찾아낸다.
- 찾아낸 `Controller`로 request를 보내주고, 보내주기 위해 필요한 Model을 구성한다.
- `Model`에서는 페이지 처리에 필요한 정보들을 Database에 접근하여 쿼리문을 통해 가져온다.
- 데이터를 통해 얻은 Model 정보를 Controller에게 response 해주면, Controller는 이를 받아 Model을 완성시켜 Dispatcher Servlet에게 전달해준다.
- Dispatcher Servlet은 `View Resolver`를 통해 request에 해당하는 view 파일을 탐색 후 받아낸다.
- 받아낸 View 페이지 파일에 Model을 보낸 후 클라이언트에게 보낼 페이지를 완성시켜 받아낸다.
- 완성된 View 파일을 클라이언트에 response하여 화면에 출력한다.

<br>

### 구성 요소

---

#### Dispatcher Servlet

모든 request를 처리하는 중심 컨트롤러라고 생각하면 된다.  서블릿 컨테이너에서 http 프로토콜을 통해 들어오는 모든 request에 대해 제일 앞단에서 중앙집중식으로 처리해주는 핵심적인 역할을 한다.

기존에는 web.xml에 모두 등록해줘야 했지만, 디스패처 서블릿이 모든 request를 핸들링하면서 작업을 편리하게 할 수 있다. 

<br>

#### Handler Mapping

클라이언트의 request url을 어떤 컨트롤러가 처리해야 할 지 찾아서 Dispatcher Servlet에게 전달해주는 역할을 담당한다.

> 컨트롤러 상에서 url을 매핑시키기 위해 `@RequestMapping`을 사용하는데, 핸들러가 이를 찾아주는 역할을 한다.

<br>

#### Controller

실질적인 요청을 처리하는 곳이다. Dispatcher Servlet이 프론트 컨트롤러라면, 이 곳은 백엔드 컨트롤러라고 볼 수 있다.

모델의 처리 결과를 담아 Dispatcher Servlet에게 반환해준다.

<br>

#### View Resolver

컨트롤러의 처리 결과를 만들 view를 결정해주는 역할을 담당한다. 다양한 종류가 있기 때문에 상황에 맞게 활용하면 된다."
266,Web,Spring,Spring Boot SpringApplication란?,"스프링 부트로 프로젝트를 실행할 때 Application 클래스를 만든다.

클래스명은 개발자가 프로젝트에 맞게 설정할 수 있지만, 큰 틀은 아래와 같다.

```java
@SpringBootApplication
public class Application {

	public static void main(String[] args) {
		SpringApplication.run(Application.class, args);
	}

}
```

<br>

`@SpringBootApplication` 어노테이션을 통해 스프링 Bean을 읽어와 자동으로 생성해준다.

이 어노테이션이 있는 파일 위치부터 설정들을 읽어가므로, 반드시 프로젝트의 최상단에 만들어야 한다.

`SpringApplication.run()`으로 해당 클래스를 run하면, 내장 WAS를 실행한다. 내장 WAS의 장점으로는 개발자가 따로 톰캣과 같은 외부 WAS를 설치 후 설정해두지 않아도 애플리케이션을 실행할 수 있다.

또한, 외장 WAS를 사용할 시 이 프로젝트를 실행시키기 위한 서버에서 모두 외장 WAS의 종류와 버전, 설정을 일치시켜야만 한다. 따라서 내장 WAS를 사용하면 이런 신경은 쓰지 않아도 되기 때문에 매우 편리하다.

> 실제로 많은 회사들이 이런 장점을 살려 내장 WAS를 사용하고 있고, 전환하고 있다."
267,Web,Spring,Spring Boot Test Code란?,"#### 테스트 코드를 작성해야 하는 이유

- 개발단계 초기에 문제를 발견할 수 있음
- 나중에 코드를 리팩토링하거나 라이브러리 업그레이드 시 기존 기능이 잘 작동하는 지 확인 가능함
- 기능에 대한 불확실성 감소

<br>

개발 코드 이외에 테스트 코드를 작성하는 일은 개발 시간이 늘어날 것이라고 생각할 수 있다. 하지만 내 코드에 오류가 있는 지 검증할 때, 테스트 코드를 작성하지 않고 진행한다면 더 시간 소모가 클 것이다.

```
1. 코드를 작성한 뒤 프로그램을 실행하여 서버를 킨다.
2. API 프로그램(ex. Postman)으로 HTTP 요청 후 결과를 Print로 찍어서 확인한다.
3. 결과가 예상과 다르면, 다시 프로그램을 종료한 뒤 코드를 수정하고 반복한다.
```

위와 같은 방식이 얼마나 반복될 지 모른다. 그리고 하나의 기능마다 저렇게 테스트를 하면 서버를 키고 끄는 작업 또한 너무 비효율적이다.

이 밖에도 Print로 눈으로 검증하는 것도 어느정도 선에서 한계가 있다. 테스트 코드는 자동으로 검증을 해주기 때문에 성공한다면 수동으로 검증할 필요 자체가 없어진다.

새로운 기능이 추가되었을 때도 테스트 코드를 통해 만약 기존의 코드에 영향이 갔다면 어떤 부분을 수정해야 하는 지 알 수 있는 장점도 존재한다.

<br>

따라서 테스트 코드는 개발하는 데 있어서 필수적인 부분이며 반드시 활용해야 한다.

<br>

#### 테스트 코드 예제

```java
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;
import org.springframework.test.context.junit4.SpringRunner;
import org.springframework.test.web.servlet.MockMvc;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;
import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;

@RunWith(SpringRunner.class)
@WebMvcTest(controllers = HomeController.class)
public class HomeControllerTest {

    @Autowired
    private MockMvc mvc;

    @Test
    public void home_return() throws Exception {
        //when
        String home = ""home"";

        //then
        mvc.perform(get(""/home""))
                .andExpect(status().isOk())
                .andExpect(content().string(home));
    }
}
```

<br>

1) `@RunWith(SpringRunner.class)`

테스트를 진행할 때 JUnit에 내장된 실행자 외에 다른 실행자를 실행시킨다.

스프링 부트 테스트와 JUnit 사이의 연결자 역할을 한다고 생각하면 된다.

2) `@WebMvcTest`

컨트롤러만 사용할 때 선언이 가능하며, Spring MVC에 집중할 수 있는 어노테이션이다.

3) `@Autowired`

스프링이 관리하는 Bean을 주입시켜준다.

4) `MockMvc`

웹 API를 테스트할 때 사용하며, 이를 통해 HTTP GET, POST, DELETE 등에 대한 API 테스트가 가능하다.

5) `mvc.perform(get(""/home""))`

`/home` 주소로 HTTP GET 요청을 한 상황이다.

6)  `.andExpect(status().isOk())`

결과를 검증하는 `andExpect`로, 여러개를 붙여서 사용이 가능하다. `status()`는 HTTP Header를 검증하는 것으로 결과에 대한 HTTP Status 상태를 확인할 수 있다. 현재 `isOK()`는 200 코드가 맞는지 확인하고 있다.

<br>

프로젝트를 만들면서 다양한 기능들을 구현하게 되는데, 이처럼 테스트 코드로 견고한 프로젝트를 만들기 위한 기능별 단위 테스트를 진행하는 습관을 길러야 한다."
268,Web,Spring,JPA란?,"> Java Persistence API

<br>

```
개발자가 직접 SQL을 작성하지 않고, JPA API를 활용해 DB를 저장하고 관리할 수 있다.
```

<br>

JPA는 오늘날 스프링에서 많이 활용되고 있지만, 스프링이 제공하는 API가 아닌 **자바가 제공하는 API다.**

자바 ORM 기술에 대한 표준 명세로, 자바 어플리케이션에서 관계형 데이터베이스를 사용하는 방식을 정의한 인터페이스다.

<br>

#### ORM(Object Relational Mapping)

ORM 프레임워크는 자바 객체와 관계형 DB를 매핑한다. 즉, 객체가 DB 테이블이 되도록 만들어주는 것이다. ORM을 사용하면, SQL을 작성하지 않아도 직관적인 메소드로 데이터를 조작할 수 있다는 장점이 있다. ( 개발자에게 생산성을 향상시켜줄 수 있음 )

종류로는 Hibernate, EclipseLink, DataNucleus 등이 있다.

<br>

<img src=""https://media.vlpt.us/images/modsiw/post/99fef220-9062-4234-95f4-211eafa431d4/image.png"">

스프링 부트에서는 `spring-boot-starter-data-jpa`로 패키지를 가져와 사용하며, 이는 Hibernate 프레임워크를 활용한다.

<br> JPA는 애플리케이션과 JDBC 사이에서 동작하며, 개발자가 JPA를 활용했을 때 JDBC API를 통해 SQL을 호출하여 데이터베이스와 호출하는 전개가 이루어진다.

즉, 개발자는 JPA의 활용법만 익히면 DB 쿼리 구현없이 데이터베이스를 관리할 수 있다.

<br>

### JPA 특징

1. ##### 객체 중심 개발 가능

   SQL 중심 개발이 이루어진다면, CRUD 작업이 반복해서 이루어져야한다.

   하나의 테이블을 생성해야할 때 이에 해당하는 CRUD를 전부 만들어야 하며, 추후에 컬럼이 생성되면 관련 SQL을 모두 수정해야 하는 번거로움이 있다. 또한 개발 과정에서 실수할 가능성도 높아진다. 

   <br>

2. ##### 생산성 증가

   SQL 쿼리를 직접 생성하지 않고, 만들어진 객체에 JPA 메소드를 활용해 데이터베이스를 다루기 때문에 개발자에게 매우 편리성을 제공해준다.

   <br>

3. ##### 유지보수 용이

   쿼리 수정이 필요할 때, 이를 담아야 할 DTO 필드도 모두 변경해야 하는 작업이 필요하지만 JPA에서는 엔티티 클래스 정보만 변경하면 되므로 유지보수에 용이하다.

4. ##### 성능 증가

   사람이 직접 SQL을 짜는 것과 비교해서 JPA는 동일한 쿼리에 대한 캐시 기능을 지원해주기 때문에 비교적 높은 성능 효율을 경험할 수 있다.

<br>

#### 제약사항

JPA는 복잡한 쿼리보다는 실시간 쿼리에 최적화되어있다. 예를 들어 통계 처리와 같은 복잡한 작업이 필요한 경우에는 기존의 Mybatis와 같은 Mapper 방식이 더 효율적일 수 있다.

> Spring에서는 JPA와 Mybatis를 같이 사용할 수 있기 때문에, 상황에 맞는 방식을 택하여 개발하면 된다."
269,Web,Spring,JPA Dirty Checking란?,"```
트랜잭션 안에서 Entity의 변경이 일어났을 때
변경한 내용을 자동으로 DB에 반영하는 것
```

<br>

ORM 구현체 개발 시 더티 체킹이라는 말을 자주 볼 수 있다.

더티 체킹이 어떤 것을 뜻하는 지 간단히 살펴보자.

<br>

JPA로 개발하는 경우 구현한 한 가지 기능을 예로 들어보자

##### ex) 주문 취소 기능

```java
@Transactional  
public void cancelOrder(Long orderId) {  
    //주문 엔티티 조회  
    Order order = orderRepository.findOne(orderId);  

    //주문 취소  
    order.cancel();  
}
```

`orderId`를 통해 주문을 취소하는 메소드다. 데이터베이스에 반영하기 위해선, `update`와 같은 쿼리가 있어야할 것 같은데 존재하지 않는다.

하지만, 실제로 이 메소드를 실행하면 데이터베이스에 update가 잘 이루어진다.

- 트랜잭션 시작
- `orderId`로 주문 Entity 조회
- 해당 Entity 주문 취소 상태로 **Update**
- 트랜잭션 커밋

이를 가능하게 하는 것이 바로 '더티 체킹(Dirty Checking)'이라고 보면 된다.

<br>

그냥 더티 체킹의 단어만 간단히 해석하면  `변경 감지`로 볼 수 있다. 좀 더 자세히 말하면, Entity에서 변경이 일어난 걸 감지한 뒤, 데이터베이스에 반영시켜준다는 의미다. (변경은 최초 조회 상태가 기준이다)

> Dirty : 상태의 변화가 생김
>
> Checking : 검사

JPA에서는 트랜잭션이 끝나는 시점에 변화가 있던 모든 엔티티의 객체를 데이터베이스로 알아서 반영을 시켜준다. 즉, 트랜잭션의 마지막 시점에서 다른 점을 발견했을 때 데이터베이스로 update 쿼리를 날려주는 것이다.

- JPA에서 Entity를 조회
- 조회된 상태의 Entity에 대한 스냅샷 생성
- 트랜잭션 커밋 후 해당 스냅샷과 현재 Entity 상태의 다른 점을 체크
- 다른 점들을 update 쿼리로 데이터베이스에 전달

<br>

이때 더티 체킹을 검사하는 대상은 `영속성 컨텍스트`가 관리하는 Entity로만 대상으로 한다.

준영속, 비영속 Entity는 값을 변경할 지라도 데이터베이스에 반영시키지 않는다.

<br>

기본적으로 더티 체킹을 실행하면, SQL에서는 변경된 엔티티의 모든 내용을 update 쿼리로 만들어 전달하는데, 이때 필드가 많아지면 전체 필드를 update하는게 비효율적일 수도 있다.

이때는 `@DynamicUpdate`를 해당 Entity에 선언하여 변경 필드만 반영시키도록 만들어줄 수 있다.

```java
@Getter
@NoArgsConstructor
@Entity
@DynamicUpdate
public class Order {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String product;
```"
270,Web,Spring,Spring Security란?,"```
API에 권한 기능이 없으면, 아무나 회원 정보를 조회하고 수정하고 삭제할 수 있다. 따라서 이를 막기 위해 인증된 유저만 API를 사용할 수 있도록 해야하는데, 이때 사용할 수 있는 해결 책 중 하나가 Spring Security다.
```

<br>

스프링 프레임워크에서는 인증 및 권한 부여로 리소스 사용을 컨트롤 할 수 있는 `Spring Security`를 제공한다. 이 프레임워크를 사용하면, 보안 처리를 자체적으로 구현하지 않아도 쉽게 필요한 기능을 구현할 수 있다.

<br>

<img src=""https://bravenamme.github.io/files/posts/201908/spring_sec_authentication.png"">

<br>

Spring Security는 스프링의 `DispatcherServlet` 앞단에 Filter 형태로 위치한다. Dispatcher로 넘어가기 전에 이 Filter가 요청을 가로채서, 클라이언트의 리소스 접근 권한을 확인하고, 없는 경우에는 인증 요청 화면으로 자동 리다이렉트한다.

<br>

### Spring Security Filter

<img src=""https://t1.daumcdn.net/cfile/tistory/993341355B6B2A0A03"">

Filter의 종류는 상당히 많다. 위에서 예시로 든 클라이언트가 리소스에 대한 접근 권한이 없을 때 처리를 담당하는 필터는 `UsernamePasswordAuthenticationFilter`다.

인증 권한이 없을 때 오류를 JSON으로 내려주기 위해 해당 필터가 실행되기 전 처리가 필요할 것이다.

<br>

API 인증 및 권한 부여를 위한 작업 순서는 아래와 같이 구성할 수 있다.

1. 회원 가입, 로그인 API 구현
2. 리소스 접근 가능한 ROLE_USER 권한을 가입 회원에게 부여
3. Spring Security 설정에서 ROLE_USER 권한을 가지면 접근 가능하도록 세팅
4. 권한이 있는 회원이 로그인 성공하면 리소스 접근 가능한 JWT 토큰 발급
5. 해당 회원은 권한이 필요한 API 접근 시 JWT 보안 토큰을 사용

<br>

이처럼 접근 제한이 필요한 API에는 보안 토큰을 통해서 이 유저가 권한이 있는지 여부를 Spring Security를 통해 체크하고 리소스를 요청할 수 있도록 구성할 수 있다.

<br>

### Spring Security Configuration

서버에 보안을 설정하기 위해 Configuration을 만든다. 기존 예시처럼, USER에 대한 권한을 설정하기 위한 작업도 여기서 진행된다.

```JAVA
@Override
    protected void configure(HttpSecurity http) throws Exception {
        http
                .httpBasic().disable() // rest api 이므로 기본설정 사용안함. 기본설정은 비인증시 로그인폼 화면으로 리다이렉트
                .cors().configurationSource(corsConfigurationSource())
                .and()
                .csrf().disable() // rest api이므로 csrf 보안이 필요없으므로 disable처리.
                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) // jwt token으로 인증하므로 세션은 필요없으므로 생성안함.
                .and()
                .authorizeRequests() // 다음 리퀘스트에 대한 사용권한 체크
                .antMatchers(""/*/signin"", ""/*/signin/**"", ""/*/signup"", ""/*/signup/**"", ""/social/**"").permitAll() // 가입 및 인증 주소는 누구나 접근가능
                .antMatchers(HttpMethod.GET, ""home/**"").permitAll() // home으로 시작하는 GET요청 리소스는 누구나 접근가능
                .anyRequest().hasRole(""USER"") // 그외 나머지 요청은 모두 인증된 회원만 접근 가능
                .and()
                .addFilterBefore(new JwtAuthenticationFilter(jwtTokenProvider), UsernamePasswordAuthenticationFilter.class); // jwt token 필터를 id/password 인증 필터 전에 넣는다

    }
```"
271,Web,Vue.js,Vue.js Life Cycle란?,"Vue.js의 라이프사이클은 크게 4가지로 나누어진다.

> Creation, Mounting, Updating, Destruction

<br>

<img src=""https://miro.medium.com/max/700/1*tnSXRrpLBYmfHnIagITlcg.png"">

<br>

### Creation

> 컴포넌트 초기화 단계

Creation 단계에서 실행되는 훅(hook)들이 라이프사이클 중 가장 먼저 실행됨

아직 컴포넌트가 DOM에 추가되기 전이며 서버 렌더링에서도 지원되는 훅임

<br>

클라이언트와 서버 렌더링 모두에서 처리해야 할 일이 있으면, 이 단계에 적용하자

<br>

- beforeCreate

  > 가장 먼저 실행되는 훅
  >
  > 아직 데이터나 이벤트가 세팅되지 않은 시점이므로 접근 불가능

- created

  > 데이터, 이벤트가 활성화되어 접근이 가능함
  >
  > 하지만 아직 템플릿과 virtual DOM은 마운트 및 렌더링 되지 않은 상태임

<br>

<br>

### Mounting

> DOM 삽입 단계

초기 렌더링 직전 컴포넌트에 직접 접근이 가능하다.

컴포넌트 초기에 세팅되어야할 데이터들은 created에서 사용하는 것이 나음

<br>

- beforeMount

  > 템플릿이나 렌더 함수들이 컴파일된 후에 첫 렌더링이 일어나기 직전에 실행됨
  >
  > 많이 사용하지 않음

- mounted

  > 컴포넌트, 템플릿, 렌더링된 DOM에 접근이 가능함
  >
  > 모든 화면이 렌더링 된 후에 실행

<br>

##### 주의할 점

부모와 자식 관계의 컴포넌트에서 생각한 순서대로 mounted가 발생하지 않는다. 즉, 부모의 mounted가 자식의 mounted보다 먼저 실행되지 않음

> 부모는 자식의 mounted 훅이 끝날 때까지 기다림

<br>

### Updating

> 렌더링 단계

컴포넌트에서 사용되는 반응형 속성들이 변경되거나 다시 렌더링되면 실행됨

디버깅을 위해 컴포넌트가 다시 렌더링되는 시점을 알고 싶을때 사용 가능

<br>

- beforeUpdate

  > 컴포넌트의 데이터가 변하여 업데이트 사이클이 시작될 때 실행됨
  >
  > (돔이 재 렌더링되고 패치되기 직전 상태)

- updated

  > 컴포넌트의 데이터가 변하여 다시 렌더링된 이후에 실행됨
  >
  > 업데이트가 완료된 상태이므로, DOM 종속적인 연산이 가능

<br>

### Destruction

> 해체 단계

<br>

- beforeDestory

  > 해체되기 직전에 호출됨
  >
  > 이벤트 리스너를 제거하거나 reactive subscription을 제거하고자 할 때 유용함

- destroyed

  > 해체된 이후에 호출됨
  >
  > Vue 인스턴스의 모든 디렉티브가 바인딩 해제되고 모든 이벤트 리스너가 제거됨

<br>

<br>



#### 추가로 사용하는 속성들

---



- computed

  > 템플릿에 데이터 바인딩할 수 있음
  >
  > ```vue
  > <div id=""example"">
  >   <p>원본 메시지: ""{{ message }}""</p>
  >   <p>역순으로 표시한 메시지: ""{{ reversedMessage }}""</p>
  > </div>
  > 
  > <script>
  >     new Vue({
  >       el: '#example',
  >       data: {
  >         message: '안녕하세요'
  >       },
  >       computed: {
  >         // 계산된 getter
  >         reversedMessage: function () {
  >           // `this` 는 vm 인스턴스를 가리킵니다.
  >           return this.message.split('').reverse().join('')
  >         }
  >       }
  >     })
  > </script>
  > ```
  >
  > message의 값이 바뀌면, reversedMessage의 값도 따라 바뀜

  <br>

  `Date.now()`와 같이 의존할 곳이 없는 computed 속성은 업데이트 안됨

  ```
  computed: {
    now: function () {
      return Date.now() //업데이트 불가능
    }
  }
  ```

  호출할 때마다 변경된 시간을 이용하고 싶으면 methods 이용

  <br>

- watch

  > 데이터가 변경되었을 때 호출되는 콜백함수를 정의
  >
  > watch는 감시할 데이터를 지정하고, 그 데이터가 바뀌면 어떠한 함수를 실행하라는 방식으로 진행



##### computed와 watch로 진행한 코드

```vue
//computed
<script>
    new Vue({
      el: '#demo',
      data: {
        firstName: 'Foo',
        lastName: 'Bar'
      },
      computed: {
        fullName: function () {
          return this.firstName + ' ' + this.lastName
        }
      }
    })
</script>
```

<br>

```vue
//watch
<script>
    new Vue({
      el: '#demo',
      data: {
        firstName: 'Foo',
        lastName: 'Bar',
        fullName: 'Foo Bar'
      },
      watch: {
        firstName: function (val) {
          this.fullName = val + ' ' + this.lastName
        },
        lastName: function (val) {
          this.fullName = this.firstName + ' ' + val
        }
      }
    })
</script>
```

<br>

computed는 선언형, watch는 명령형 프로그래밍 방식

watch를 사용하면 API를 호출하고, 그 결과에 대한 응답을 받기 전 중간 상태를 설정할 수 있으나 computed는 불가능

<br>

대부분의 경우 선언형 방식인 computed 사용이 더 좋으나, 데이터 변경의 응답으로 비동기식 계산이 필요한 경우나 시간이 많이 소요되는 계산을 할 때는 watch를 사용하는 것이 좋다."
272,Web,Vue.js,Nuxt.js란?,"> vue.js를 서버에서 렌더링할 수 있도록 도와주는 오픈소스 프레임워크

서버, 클라이언트 코드의 배포를 축약시켜 SPA(싱글페이지 앱)을 간편하게 만들어준다.

Vue.js 프로젝트를 진행할 때, 서버 부분을 미리 구성하고 정적 페이지를 만들어내는 기능을 통해 UI 렌더링을 보다 신속하게 제공해주는 기능이 있다.

<br>

<br>

***들어가기에 앞서..***

- SSR(Server Side Rendering) : 서버 쪽에서 페이지 컨텐츠들이 렌더링된 상태로 응답해줌
- CSR(Client Side Rendering) : 클라이언트(웹브라우저) 쪽에서 컨텐츠들을 렌더링하는 것
- SPA(Single Page Application) : 하나의 페이지로 구성된 웹사이트. index.html안에 모든 웹페이지들이 javascript로 구현되어 있는 형태

> SPA는 보안 이슈나 검색 엔진 최적화에 있어서 단점이 존재. 이를 극복하기 위해 처음 불러오는 화면은 SSR로, 그 이후부터는 CSR로 진행하는 방식이 효율적이다.

<br>

***Nuxt.js는 왜 사용하나?***

vue.js를 서버에서 렌더링하려면 설정해야할 것들이 한두개가 아니다ㅠ

보통 babel과 같은 webpack을 통해 자바스크립트를 빌드하고 컴파일하는 과정을 거치게 된다. Node.js에서는 직접 빌드, 컴파일을 하지 않으므로, 이런 것들을 분리하여 SSR(서버 사이드 렌더링)이 가능하도록 미리 세팅해두는 것이 Nuxt.js다.

> Vue에서는 Nuxt를, React에서는 Next 프레임워크를 사용함

<br>

Nuxt CLI를 통해 쉽게 프로젝트를 만들고 진행할 수 있음

```
$ vue init nuxt/starter <project-name>
```

기본적으로 `vue-router`나 `vuex`를 이용할 수 있게 디렉토리가 준비되어 있기 때문에 Vue.js로 개발을 해본 사람들은 편하게 활용이 가능하다.

<br>

#### 장점

---

- 일반적인 SPA 개발은, 검색 엔진에서 노출되지 않아 조회가 힘들다. 하지만 Nuxt를 이용하게 되면 서버사이드렌더링으로 화면을 보여주기 때문에, 검색엔진 봇이 화면들을 잘 긁어갈 수 있다. 따라서 **SPA로 개발하더라도 SEO(검색 엔진 최적화)를 걱정하지 않아도 된다.**

  > 일반적으로 많은 회사들은 검색엔진에 적절히 노출되는 것이 매우 중요함. 따라서 **검색 엔진 최적화**는 개발 시 반드시 고려해야 할 부분

- SPA임에도 불구하고, Express가 서버로 뒤에서 돌고 있다. 이는 내가 원하는 API를 프로젝트에서 만들어서 사용할 수 있다는 뜻!



#### 단점

---

Nuxt를 사용할 때, 단순히 프론트/백엔드를 한 프로젝트에서 개발할 수 있지않을까로 접근하면 큰코 다칠 수 있다.

ex) API 요청시 에러가 발생하면, 프론트엔드에게 오류 발생 상태를 전달해줘야 예외처리를 진행할텐데 Nuxt에서 Express 에러까지 먹어버리고 리디렉션시킴

> API부분을 Nuxt로 활용하는 게 상당히 어렵다고함"
273,Web,React,React Fragment란?,"```
JSX 파일 규칙상 return 시 하나의 태그로 묶어야한다.
이런 상황에 Fragment를 사용하면 쉽게 그룹화가 가능하다.
```

<br>

아래와 같이 Table 컴포넌트에서 Columns를 불렀다고 가정해보자

```JSX
import { Component } from 'React'
import Columns from '../Components'

class Table extends Component {
  render() {
    return (
      <table>
        <tr>
          <Columns />
        </tr>
      </table>
    );
  }
}
```

<br>

Columns 컴포넌트에서는 `<td> ~~ </td>`와 같은 element를 반환해야 유효한 테이블 생성이 가능할 것이다.

```jsx
import { Component } from 'React'

class Columns extends Component {
  render() {
    return (
      <div>
        <td>Hello</td>
        <td>World</td>
      </div>
    );
  }
}
```

여러 td 태그를 작성하기 위해 div 태그로 묶었다. (JSX 파일 규칙상 return 시 하나의 태그로 묶어야한다.)

이제 Table 컴포넌트에서 DOM 트리를 그렸을 때 어떻게 결과가 나오는지 확인해보자

<br>

```html
<table>
  <tr>
    <div>
      <td>Hello</td>
      <td>World</td>
    </div>
  </tr>
</table>
```

Columns 컴포넌트에서 div 태그로 묶어서 Table 컴포넌트로 보냈기 때문에 문제가 발생한다. 따라서 JSX파일의 return문을 무조건 div 태그로 묶는 것이 바람직하지 않을 수 있다.

이때 사용할 수 있는 문법이 바로 `Fragment`다.

```jsx
import { Component } from 'React'

class Columns extends Component {
  render() {
    return (
      <Fragment>
        <td>Hello</td>
        <td>World</td>
      </Fragment>
    );
  }
}
```

div 태그 대신에 Fragment로 감싸주면 문제가 해결된다. Fragment는 DOM트리에 추가되지 않기 때문에 정상적으로 Table을 생성할 수 있다.

<br>

Fragment로 명시하지 않고, 빈 태그로도 가능하다.

```JSX
import { Component } from 'React'

class Columns extends Component {
  render() {
    return (
      <>
        <td>Hello</td>
        <td>World</td>
      </>
    );
  }
}
```

<br>

이 밖에도 부모, 자식과의 관계에서 flex, grid로 연결된 element가 있는 경우에는 div로 연결 시 레이아웃을 유지하는데 어려움을 겪을 수도 있다.

따라서 위와 같은 개발이 필요할 때는 Fragment를 적절한 상황에 사용하면 된다."
274,Web,Vue.js,React Hook란?,"> useState(), useEffect() 정의

<br>

리액트의 Component는 '클래스형'과 '함수형'으로 구성되어 있다.

기존의 클래스형 컴포넌트에서는 몇 가지 어려움이 존재한다.

1. 상태(State) 로직 재사용 어려움
2. 코드가 복잡해짐
3. 관련 없는 로직들이 함께 섞여 있어 이해가 힘듬

이와 같은 어려움을 해결하기 위해, 'Hook'이 도입되었다. (16.8 버전부터)

<br>

### Hook

- 함수형 컴포넌트에서 State와 Lifecycle 기능을 연동해주는 함수
- '클래스형'에서는 동작하지 않으며, '함수형'에서만 사용 가능

<br>

#### useState

기본적인 Hook으로 상태관리를 해야할 때 사용하면 된다.

상태를 변경할 때는, `set`으로 준 이름의 함수를 호출한다. 

```jsx
const [posts, setPosts] = useState([]); // 비구조화 할당 문법
```

`useState([]);`와 같이 `( )` 안에 초기화를 설정해줄 수 있다. 현재 예제는 빈 배열을 만들어 둔 상황인 것이다.

<br>

#### useEffect

컴포넌트가 렌더링 될 때마다 특정 작업을 수행하도록 설정할 수 있는 Hook

> '클래스' 컴포넌트의 componentDidMount()와 componentDidUpdate()의 역할을 동시에 한다고 봐도 된다.

```jsx
useEffect(() => {
    console.log(""렌더링 완료"");
    console.log(posts);
});
```

posts가 변경돼 리렌더링이 되면, useEffect가 실행된다."
275,Web,DevOps,시스템 규모 확장이란?,"```
시스템 사용자 수에 따라 설계해야 하는 규모가 달라진다.
수백만의 이용자가 존재하는 시스템을 개발해야 한다면, 어떤 것들을 고려해야 할 지 알아보자
```

<br>

1. #### 무상태(stateless) 웹 계층

   수평적으로 확장하기 위해 필요하다. 즉, 사용자 세션 정보와 같은 상태 정보를 데이터베이스와 같은 지속 가능한 저장소에 맡기고, 웹 계층에서는 필요할 때 가져다 사용하는 방식으로 만든다.

   웹 계층에서는 무상태를 유지하면서, 어떤 사용자가 http 요청을 하더라도 따로 분리한 공유 저장소에서 해당 데이터를 불러올 수 있도록 구성한다.

   수평적 확장은 여러 서버를 추가하여 Scale out하는 방식으로, 이처럼 웹 계층에서 상태를 지니고 있지 않으면, 트래픽이 늘어날 때 원활하게 서버를 추가할 수 있게 된다.

   <br>

2. #### 모든 계층 다중화 도입

   데이터베이스를 주-부로 나누어 운영하는 방식을 다중화라고 말한다. 다중화에 대한 장점은 아래와 같다.

   - 더 나은 성능 지원 : 모든 데이터 변경에 대한 연산은 주 데이터베이스 서버로 전달되는 반면, 읽기 연산은 부 데이터베이스 서버들로 분산된다. 병렬로 처리되는 쿼리 수가 늘어나 성능이 좋아지게 된다.
   - 안정성 : 데이터베이스 서버 가운데 일부분이 손상되더라도, 데이터를 보존할 수 있다.
   - 가용성 : 데이터를 여러 지역에 복제하여, 하나의 데이터베이스 서버에 장애가 발생해도 다른 서버에 있는 데이터를 가져와서 서비스를 유지시킬 수 있다.

   <br>

3. #### 가능한 많은 데이터 캐시

   캐시는 데이터베이스 호출을 최소화하고, 자주 참조되는 데이터를 메모리 안에 두면서 빠르게 요청을 처리할 수 있도록 지원해준다. 따라서 데이터 캐시를 활용하면, 시스템 성능이 개선되며 데이터베이스의 부하 또한 줄일 수 있다. 캐시 메모리가 너무 작으면, 액세스 패턴에 따라 데이터가 너무 자주 캐시에서 밀려나 성능이 떨어질 수 있다. 따라서 캐시 메모리를 과할당하여 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제를 방지할 수 있는 솔루션도 존재한다.

   <br>

4. #### 여러 데이터 센터를 지원

   데이터 센터에 장애가 나는 상황을 대비하기 위함이다. 실제 AWS를 이용할 때를 보더라도, 지역별로 다양하게 데이터 센터가 구축되어 있는 모습을 확인할 수 있다. 장애가 없는 상황에서 가장 가까운 데이터 센터로 사용자를 안내하는 절차를 보통 '지리적 라우팅'이라고 부른다. 만약 해당 데이터 센터에서 심각한 장애가 발생한다면, 모든 트래픽을 장애가 발생하지 않은 다른 데이터 센터로 전송하여 시스템이 다운되지 않도록 지원한다.

   <br>

5. #### 정적 콘텐츠는 CDN을 통해 서비스

   CDN은 정적 콘텐츠를 전송할 때 사용하는 지리적으로 분산된 서버의 네트워크다. 주로 시스템 내에서 변동성이 없는 이미지, 비디오, CSS, Javascript 파일 등을 캐시한다.

   시스템에 접속한 사용자의 가장 가까운 CDN 서버에서 정적 콘텐츠를 전달해주므로써 로딩 시간을 감소시켜준다. 즉, CDN 서버에서 사용자에게 필요한 데이터를 캐시처럼 먼저 찾고, 없으면 그때 서버에서 가져다가 전달하는 방식으로 좀 더 사이트 로딩 시간을 줄이고, 데이터베이스의 부하를 줄일 수 있는 장점이 있다.

   <br>

6. #### 데이터 계층은 샤딩을 통해 규모를 확장

   데이터베이스의 수평적 확장을 말한다. 샤딩은 대규모 데이터베이스를 shard라고 부르는 작은 단위로 분할하는 기술을 말한다. 모든 shard는 같은 스키마를 사용하지만, 보관하는 데이터 사이에 중복은 존재하지 않는다. 샤딩 키(파티션 키라고도 부름)을 적절히 정해서 데이터가 잘 분산될 수 있도록 전략을 짜는 것이 중요하다. 즉, 한 shard에 데이터가 몰려서 과부하가 걸리지 않도록 하는 것이 핵심이다.

   - 데이터의 재 샤딩 : 데이터가 너무 많아져서 일정 shard로 더이상 감당이 어려울 때 혹은 shard 간 데이터 분포가 균등하지 못하여 어떤 shard에 할당된 공간 소모가 다른 shard에 비해 빨리 진행될 때 시행해야 하는 것
   - 유명인사 문제 : 핫스팟 키라고도 부름. 특정 shard에 질의가 집중되어 과부하 되는 문제를 말한다.
   - 조인과 비 정규화 : 여러 shard로 쪼개고 나면, 조인하기 힘들어지는 문제가 있다. 이를 해결하기 위한 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행가능하도록 한다.

   <br>

7. #### 각 계층은 독립적 서비스로 분할

   마이크로 서비스라고 많이 부른다. 서비스 별로 독립적인 체계를 구축하면, 하나의 서비스가 다운이 되더라도 최대한 다른 서비스들에 영향을 가지 않도록 할 수 있다. 따라서 시스템 규모가 커질수록 계층마다 독립된 서비스로 구축하는 것이 필요해질 수 있다.

   <br>

8. #### 시스템에 대한 모니터링 및 자동화 도구 활용

   - 로그 : 에러 로그 모니터링. 시스템의 오류와 문제를 쉽게 찾아낼 수 있다.
   - 메트릭 : 사업 현황, 시스템 현재 상태 등에 대한 정보들을 수집할 수 있다.
   - 자동화 : CI/CD를 통해 빌드, 테스트, 배포 등의 검증 절차를 자동화하면 개발 생산성을 크게 향상시킨다."